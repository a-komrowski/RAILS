{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3df4de",
   "metadata": {},
   "source": [
    "# RAILS — Überwachtes CNN-Training für Schienenuntergrund-Klassifikation\n",
    "\n",
    "**Ziel:** Training und Evaluation eines überwachten CNN (Transfer Learning mit ResNet50V2) zur präzisen Klassifikation von Eisenbahn-Gleisbettbildern. Aufbauend auf der unüberwachten Clustering-Analyse implementiert dieses Notebook eine **vollständige, eigenständige ML-Pipeline**:\n",
    "\n",
    "1. **Daten-I/O** aus TFRecord-Format (Parsing, Dekodierung, Normalisierung)\n",
    "2. **Modelldefinition** (vortrainiertes ResNet50V2-Backbone + leichter Klassifikationskopf)\n",
    "3. **Training** mit der _besten Konfiguration_ (siehe unten)\n",
    "4. **Evaluation** mit detaillierten Metriken (Confusion Matrix, klassenweise Precision/Recall/F1, Macro/Weighted Scores)\n",
    "5. **Visualisierung** (Trainingskurven, Confusion Matrix, klassenweise Balkendiagramme, Klassenverteilung)\n",
    "6. **Artefakte** (gespeichertes Modell + CSV/JSON-Ergebnisse)\n",
    "\n",
    "Das Notebook basiert auf den Erkenntnissen der vorhergehenden Clustering-Phase und nutzt die beste, durch systematische Hyperparameter-Optimierung ermittelte Konfiguration für das finale Training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95295a66",
   "metadata": {},
   "source": [
    "## Schnellstart & Konfiguration\n",
    "\n",
    "**Was:**  \n",
    "- Setzt die Pfade zu den **TFRecord**-Dateien für Training und Evaluation.  \n",
    "- Definiert **Ausgabeverzeichnis** und **Modellnamen** für Trainingsartefakte.  \n",
    "- Legt **Klassenliste** und **Bildabmessungen** (224×224×3) fest, passend zum verwendeten Backbone.  \n",
    "- Bündelt die feste **Best-Configuration** (Lernrate, Batchgröße, Epochen, Val-Anteil, Early-Stopping-Patience).\n",
    "\n",
    "**Warum:**  \n",
    "- Zentrale Konfiguration ermöglicht **reproduzierbare** Läufe ohne Parameter-Sweeps.  \n",
    "- TFRecords als einheitliches Eingabeformat erleichtern **schnelles Laden** via `tf.data`.  \n",
    "- Feste Hyperparameter sichern **Vergleichbarkeit** und verhindern „Experiment Creep“.  \n",
    "- Ein Val-Anteil und Early Stopping unterstützen **stabiles Trainieren** und vermeiden Über-/Unteranpassung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5689c5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFRecord inputs\n",
    "TRAIN_TFRECORD_PATH = \"/media/andi/ssd2/dev/code/Overseer2/data/inputs/MultiLabel_TB_small_08-25.tfrecord\"   # <-- EDIT\n",
    "EVAL_TFRECORD_PATH  = \"/media/andi/ssd2/dev/code/Overseer2/data/inputs/MultiLabel_TB_Evaluation_08-25.tfrecord\"    # <-- EDIT\n",
    "\n",
    "# Output directory + model name\n",
    "OUTPUT_DIR = \"./outputs_trackbed\"\n",
    "MODEL_NAME = \"PT_MultiClassResNet50_Trackbed\"\n",
    "\n",
    "# Label mapping and image shape (matches our ResNet50V2 setup)\n",
    "CLASSES = [\"ASPHALT\", \"BALLAST\", \"GRAS\", \"STONE\", \"ERROR\"]\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH  = 224\n",
    "IMG_DEPTH  = 3\n",
    "\n",
    "# \"Best\" training configuration (as agreed/established externally)\n",
    "BEST_CONFIG = {\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_epochs\": 30,\n",
    "    # You can tweak these without changing the core \"best\" idea\n",
    "    \"val_fraction\": 0.2,         # reserve a small fraction of TRAIN for validation\n",
    "    \"early_stopping_patience\": 5 # be gentle to avoid over/under-fitting\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b069115",
   "metadata": {},
   "source": [
    "## 1. Setup: Umgebung & Reproduzierbarkeit\n",
    "\n",
    "**Was:**\n",
    "- Initialisierung von TensorFlow und Import der erforderlichen Bibliotheken\n",
    "- Setzen von Seeds für Determinismus (soweit auf GPU praktikabel)\n",
    "- Aktivierung des GPU-Memory-Growth zur Vermeidung von OOM-Fehlern\n",
    "\n",
    "**Warum:**\n",
    "- **Reproduzierbarkeit:** Konsistente Ergebnisse über mehrere Trainingsläufe hinweg\n",
    "- **GPU-Optimierung:** Effiziente Speichernutzung verhindert Speicherüberläufe\n",
    "- **Zentralisierte Konfiguration:** Alle Seeds und Umgebungseinstellungen an einem Ort\n",
    "\n",
    "**Outputs:**\n",
    "- Konfigurierte TensorFlow-Umgebung mit aktiviertem Memory-Growth\n",
    "- Erstellung des Output-Verzeichnisses für Modell-Artefakte\n",
    "- Ausgabe der TensorFlow-Version und des absoluten Output-Pfads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e633b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, random, math, itertools\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Reproducibility (best-effort on GPU)\n",
    "SEED = 123\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# GPU memory growth (optional but recommended)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Enabled memory growth for {len(gpus)} GPU(s).\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not set memory growth: {e}\")\n",
    "\n",
    "# Create output dir\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Output dir:\", os.path.abspath(OUTPUT_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a8d657",
   "metadata": {},
   "source": [
    "## 2. Daten-Pipeline: TFRecord → `tf.data.Dataset`\n",
    "\n",
    "**Was:**\n",
    "- Implementierung der Daten-Pipeline mit dem Schema aus `create_trackbed_tfrecord.ipynb`\n",
    "- Mehrstufige Verarbeitung: Parsing, Dekodierung, Normalisierung und Batching\n",
    "\n",
    "**Verarbeitungsschritte:**\n",
    "\n",
    "1. **Feature-Parsing** aus jedem TFRecord-Beispiel\n",
    "2. **Dekodierung** Raw Bytes → Bildtensor; Sicherstellung 3 Kanäle; **Resize auf 224×224**\n",
    "3. **One-Hot-Encoding** der Labels (5 Klassen)\n",
    "4. **Normalisierung** auf `[0,1]`-Bereich\n",
    "5. **Shuffle + Split** von `TRAIN` in **Train/Validation** (nach `val_fraction`)\n",
    "   Der `EVAL` TFRecord wird unverändert für die finale Evaluation geladen\n",
    "\n",
    "**Warum:**\n",
    "- **Konsistenz:** Identisches Schema wie bei der TFRecord-Erstellung gewährleistet fehlerfreie Datenverarbeitung\n",
    "- **Effizienz:** `tf.data.AUTOTUNE` und Prefetching optimieren die Datenlade-Performance\n",
    "- **Flexibilität:** Separate Funktionen für Training (mit Shuffling) und Evaluation (deterministisch)\n",
    "\n",
    "**Besonderheiten:**\n",
    "- Automatische Grayscale→RGB-Konvertierung für Kompatibilität mit vortrainierten Modellen\n",
    "- Deterministische Train/Val-Aufteilung durch `take/skip` (reproduzierbar bei unveränderter Dateireihenfolge)\n",
    "- Rückgabe von Dateinamen bei Evaluation für detaillierte Fehleranalyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature schema (must match TFRecord writer)\n",
    "FEATURE_DESC = {\n",
    "    'image_filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw':      tf.io.FixedLenFeature([], tf.string),\n",
    "    'height':         tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width':          tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth':          tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label':          tf.io.FixedLenFeature([], tf.int64),\n",
    "    'class_name':     tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_tfrecord(proto):\n",
    "    \"\"\"Parse a single Example proto.\"\"\"\n",
    "    return tf.io.parse_single_example(proto, FEATURE_DESC)\n",
    "\n",
    "def _decode_and_preprocess(feat_dict):\n",
    "    \"\"\"Decode bytes → image; enforce 3 channels; resize to 224x224; one‑hot label.\"\"\"\n",
    "    img = tf.io.decode_raw(feat_dict['image_raw'], tf.uint8)\n",
    "    h   = tf.cast(feat_dict['height'], tf.int32)\n",
    "    w   = tf.cast(feat_dict['width'],  tf.int32)\n",
    "    d   = tf.cast(feat_dict['depth'],  tf.int32)\n",
    "    img = tf.reshape(img, [h, w, d])\n",
    "\n",
    "    # If single-channel, convert to RGB for pretrained models\n",
    "    def to_rgb(x):\n",
    "        return tf.image.grayscale_to_rgb(x)\n",
    "\n",
    "    img = tf.cond(tf.equal(d, 1), lambda: to_rgb(img), lambda: img)\n",
    "\n",
    "    # Resize to model input\n",
    "    img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    img = tf.cast(img, tf.float32) / 255.0  # normalize\n",
    "\n",
    "    label_index = tf.cast(feat_dict['label'], tf.int32)\n",
    "    label_1h    = tf.one_hot(label_index, depth=NUM_CLASSES)\n",
    "    return img, label_1h\n",
    "\n",
    "def _decode_with_filename(feat_dict):\n",
    "    \"\"\"Variant that also returns the original filename for evaluation/analysis.\"\"\"\n",
    "    img, label_1h = _decode_and_preprocess(feat_dict)\n",
    "    return img, label_1h, feat_dict['image_filename']\n",
    "\n",
    "def _count_records(tfrecord_path):\n",
    "    \"\"\"Count number of examples in a single-file TFRecord.\"\"\"\n",
    "    return sum(1 for _ in tf.data.TFRecordDataset(tfrecord_path))\n",
    "\n",
    "def load_train_val_ds(tfrecord_path, batch_size, val_fraction=0.1, shuffle_multiplier=20):\n",
    "    \"\"\"Create train/val datasets from a single TFRecord file by a deterministic split.\"\"\"\n",
    "    n_total = _count_records(tfrecord_path)\n",
    "    n_val   = max(1, int(round(n_total * float(val_fraction))))\n",
    "    n_train = max(1, n_total - n_val)\n",
    "    print(f\"Found {n_total} samples → train: {n_train}, val: {n_val}\")\n",
    "\n",
    "    raw = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    raw = raw.map(_parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # We perform a simple split by 'take/skip' (repeatable as long as the file order doesn't change).\n",
    "    # For stronger randomness across epochs, you could shuffle before splitting,\n",
    "    # but then report the exact split seed in your paper.\n",
    "    train_raw = raw.take(n_train)\n",
    "    val_raw   = raw.skip(n_train)\n",
    "\n",
    "    # Build train ds\n",
    "    train_ds = (train_raw\n",
    "                .shuffle(buffer_size=batch_size*shuffle_multiplier, seed=SEED, reshuffle_each_iteration=True)\n",
    "                .map(_decode_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                .batch(batch_size)\n",
    "                .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "    # Build val ds\n",
    "    val_ds = (val_raw\n",
    "              .map(_decode_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "              .batch(batch_size)\n",
    "              .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "    return train_ds, val_ds, n_train, n_val\n",
    "\n",
    "def load_eval_ds(tfrecord_path, batch_size):\n",
    "    raw = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    raw = raw.map(_parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds  = (raw\n",
    "           .map(_decode_with_filename, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "           .batch(batch_size)\n",
    "           .prefetch(tf.data.AUTOTUNE))\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4497d7d",
   "metadata": {},
   "source": [
    "## 3. Modellarchitektur: ResNet50V2 + Klassifikationskopf\n",
    "\n",
    "**Was:**\n",
    "- Wiederverwendung der bewährten Architektur aus vorhergehenden Experimenten (vgl. [Report](https://wandb.ai/a-komrowski-nordakademie/multilabel-trackbed/reports/MultiClass-Trackbed-Detection--VmlldzoxNDE5Mjk2Nw?accessToken=ey801pz851tmsag3z39y5d10rkljuxcnzq4bcal3lwc0xiaog6qfj2o2i6r9de1n))\n",
    "- **ResNet50V2** (ImageNet vortrainiert, eingefroren) + leichter MLP-Klassifikationskopf\n",
    "- Loss-Funktion: **Categorical Cross-Entropy** (Single-Label, 5-Wege-Softmax)\n",
    "\n",
    "**Warum:**\n",
    "- **Transfer Learning:** Vortrainierte Features von ImageNet bieten robuste Basis für Bildklassifikation\n",
    "- **Eingefrorenes Backbone:** Verhindert Overfitting bei begrenzten Trainingsdaten und reduziert Trainingszeit\n",
    "- **Kategoriale Accuracy:** Passende Metrik für Multi-Class Single-Label-Klassifikation\n",
    "\n",
    "**Architektur-Details:**\n",
    "- **Input:** 224×224×3 (RGB-Bilder)\n",
    "- **Backbone:** ResNet50V2 mit Global Average Pooling\n",
    "- **Classifier:** Flatten → Dropout(0.3) → Dense(64) → Dense(32) → Dense(16) → Dense(5, softmax)\n",
    "- **Optimizer:** Adam mit exponentieller Learning Rate Decay (initial_lr=1e-4, decay_rate=0.9)\n",
    "\n",
    "**Outputs:**\n",
    "- Kompiliertes Keras-Modell mit konfigurierten Optimizer und Metriken\n",
    "- Modell-Summary zur Architektur-Verifikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "def build_pt_multilabel_resnets_trackbed(initial_lr=1e-4, loss_fn='categorical_crossentropy'):\n",
    "    # Input\n",
    "    inp = Input(shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH))\n",
    "\n",
    "    # Pretrained backbone (frozen)\n",
    "    base = ResNet50V2(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH), pooling='avg')\n",
    "    base.trainable = False\n",
    "\n",
    "    x = base(inp)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    x = Dense(16, activation='relu')(x)\n",
    "    out = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "\n",
    "    # Exponential decay on LR (as in our reference)\n",
    "    lr_sched = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=float(initial_lr),\n",
    "        decay_steps=10_000,\n",
    "        decay_rate=0.9\n",
    "    )\n",
    "\n",
    "    opt = Adam(learning_rate=lr_sched)\n",
    "    model.compile(optimizer=opt, loss=loss_fn, metrics=[tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')])\n",
    "    return model\n",
    "\n",
    "model = build_pt_multilabel_resnets_trackbed(initial_lr=BEST_CONFIG[\"learning_rate\"], loss_fn='categorical_crossentropy')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd7313c",
   "metadata": {},
   "source": [
    "## 4. Training: Beste Konfiguration (Single Run)\n",
    "\n",
    "**Was:**\n",
    "- Training **ausschließlich** mit der zuvor als optimal identifizierten Konfiguration:\n",
    "  `learning_rate=1e-4`, `batch_size=32`, `num_epochs=30`\n",
    "- Reservation von `val_fraction` (Standard 20%) des Trainingsdatensatzes für Validation\n",
    "\n",
    "**Warum:**\n",
    "- **Fokussierte Analyse:** Konzentration auf die beste Konfiguration statt erneuter Hyperparameter-Suche\n",
    "- **Effizienz:** Direktes Training mit bewährten Parametern spart Rechenzeit\n",
    "- **Vergleichbarkeit:** Konsistente Basis für Evaluation und Dokumentation\n",
    "\n",
    "**Callbacks & Monitoring:**\n",
    "- **ModelCheckpoint:** Speichert bestes Modell basierend auf `val_loss`  \n",
    "  - *Warum sinnvoll?*  \n",
    "    - `val_loss` ist die optimierte Zielgröße und reagiert sensitiver als Accuracy.  \n",
    "    - `save_best_only=True` verhindert Modell-Wildwuchs und hält genau **ein** bestes Artefakt bereit.  \n",
    "    - Garantiert ein reproduzierbares Referenzmodell für Auswertung/Deployment.\n",
    "- **EarlyStopping:** Verhindert Overfitting mit konfigurierbarer Patience (Standard: 6 Epochen)  \n",
    "  - *Warum sinnvoll?*  \n",
    "    - Bricht stagnierende Läufe früh ab → spart Rechenzeit/Ressourcen.  \n",
    "    - `restore_best_weights=True` stellt direkt den besten Gewichtsstand für die Auswertung bereit.\n",
    "- **CSVLogger:** Persistiert Trainingsmetriken für spätere Analyse\n",
    "\n",
    "**Outputs:**\n",
    "- Trainiertes Modell gespeichert als `.keras`-Datei\n",
    "- Training-Logs als CSV mit Verlauf von Loss und Accuracy\n",
    "- Konfigurationsdateien (JSON) für Reproduzierbarkeit\n",
    "- Konsolen-Ausgabe der finalen Pfade und Datensatzgrößen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e39d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "BATCH_SIZE = int(BEST_CONFIG[\"batch_size\"])\n",
    "EPOCHS     = int(BEST_CONFIG[\"num_epochs\"])\n",
    "VAL_FRAC   = float(BEST_CONFIG[\"val_fraction\"])\n",
    "\n",
    "# Load datasets\n",
    "train_ds, val_ds, n_train, n_val = load_train_val_ds(TRAIN_TFRECORD_PATH, batch_size=BATCH_SIZE, val_fraction=VAL_FRAC)\n",
    "eval_ds = load_eval_ds(EVAL_TFRECORD_PATH, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Callbacks & paths\n",
    "timestamp   = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "run_dir     = Path(OUTPUT_DIR) / f\"{MODEL_NAME}__{timestamp}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_PATH  = str(run_dir / f\"{MODEL_NAME}.keras\")\n",
    "LOG_CSV     = str(run_dir / \"training_log.csv\")\n",
    "CFG_JSON    = str(run_dir / \"config.json\")\n",
    "CLASSES_JSON= str(run_dir / \"classes.json\")\n",
    "\n",
    "# Save config & classes for reproducibility\n",
    "with open(CFG_JSON, \"w\") as f:\n",
    "    json.dump(BEST_CONFIG, f, indent=2)\n",
    "with open(CLASSES_JSON, \"w\") as f:\n",
    "    json.dump(CLASSES, f, indent=2)\n",
    "\n",
    "cbs = [\n",
    "    ModelCheckpoint(MODEL_PATH, monitor='val_loss', save_best_only=True, save_weights_only=False, verbose=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=int(BEST_CONFIG[\"early_stopping_patience\"]), restore_best_weights=True, verbose=1),\n",
    "    CSVLogger(LOG_CSV) #eig raus\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nBest model saved to:\", MODEL_PATH)\n",
    "print(\"Logs saved to:\", LOG_CSV)\n",
    "print(\"Train/Val sizes:\", n_train, n_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d228ab",
   "metadata": {},
   "source": [
    "## 5. Trainingskurven: Verlaufsanalyse\n",
    "\n",
    "**Was:**\n",
    "- Visualisierung von Loss und Categorical Accuracy über alle Epochen\n",
    "- Separate Kurven für Training und Validation zur Overfitting-Erkennung\n",
    "\n",
    "**Warum:**\n",
    "- **Konvergenz-Analyse:** Überprüfung ob das Training erfolgreich konvergiert ist\n",
    "- **Overfitting-Detektion:** Auseinanderlaufende Train/Val-Kurven zeigen Überanpassung\n",
    "- **Model-Validierung:** Visueller Nachweis einer stabilen und erfolgreichen Optimierung\n",
    "\n",
    "**Interpretation:**\n",
    "- **Idealer Verlauf:** Beide Kurven sinken (Loss) bzw. steigen (Accuracy) und konvergieren\n",
    "- **Overfitting:** Training-Metrik verbessert sich weiter, während Validation stagniert oder schlechter wird\n",
    "- **Underfitting:** Beide Kurven haben noch nicht konvergiert und zeigen weiteres Verbesserungspotential\n",
    "\n",
    "**Outputs:**\n",
    "- Zwei Matplotlib-Plots: Loss-Verlauf und Accuracy-Verlauf\n",
    "- Visuelle Dokumentation der Trainingsqualität"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ebc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot: Loss\n",
    "plt.figure()\n",
    "plt.plot(history.history.get('loss', []), label='train_loss')\n",
    "plt.plot(history.history.get('val_loss', []), label='val_loss')\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot: Categorical Accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history.get('categorical_accuracy', []), label='train_cat_acc')\n",
    "plt.plot(history.history.get('val_categorical_accuracy', []), label='val_cat_acc')\n",
    "plt.title('Categorical Accuracy over epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Categorical Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56236f01",
   "metadata": {},
   "source": [
    "## 6. Evaluation: Detaillierte Leistungsanalyse auf Hold-out-Datensatz\n",
    "\n",
    "**Was:**\n",
    "- Umfassende Evaluation des besten Modells auf dem separaten EVAL-Datensatz\n",
    "- Berechnung aller relevanten Klassifikationsmetriken und detaillierte Fehleranalyse\n",
    "\n",
    "**Berechnete Metriken:**\n",
    "- **Confusion Matrix** (Gesamt-Übersicht der Klassifikationsergebnisse)\n",
    "- **Pro Klasse:** Precision, Recall (Sensitivity), Specificity, F1-Score, Accuracy\n",
    "- **Fehlerraten:** Type I/II Error Rates\n",
    "- **Aggregate Metriken:** Macro (ungewichtet) und Weighted (gewichtet) Averages\n",
    "\n",
    "**Gespeicherte Artefakte:**\n",
    "- `evaluation_summary_*.csv` — Vollständige Metrik-Tabelle\n",
    "- `confusion_matrix_*.csv` — Raw Counts der Confusion Matrix\n",
    "- `false_inferences_*.json` — Dateinamen aller FP/FN + Fehlklassifikationen (mit Vorhersage vs. wahre Klasse)\n",
    "\n",
    "**Warum:**\n",
    "- **Objektive Bewertung:** Hold-out-Set war nie in Training/Validation involviert\n",
    "- **Detaillierte Analyse:** Pro-Klassen-Metriken decken klassenspezifische Schwächen auf\n",
    "- **Fehleranalyse:** Identifikation problematischer Bilder für weitere Untersuchungen\n",
    "- **Reproduzierbarkeit:** Alle Metriken und Fehler werden persistent gespeichert\n",
    "\n",
    "**Visualisierungen:**\n",
    "- **Confusion Matrix Heatmap** mit Zahlenwerten\n",
    "- **F1-Score Balkendiagramm** pro Klasse\n",
    "- **Klassenverteilung** des Evaluationsdatensatzes\n",
    "- **False Positives vs. False Negatives** Vergleich pro Klasse\n",
    "\n",
    "**Outputs:**\n",
    "- CSV/JSON-Dateien mit allen Metriken und Fehlern\n",
    "- Vier Visualisierungen zur Ergebnisinterpretation\n",
    "- Konsolen-Summary mit Kernmetriken (Overall Accuracy, Macro F1, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure we load the best-saved model from disk (even if EarlyStopping restored in-memory weights)\n",
    "best_model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "\n",
    "# Predict across the eval set\n",
    "all_true_idx = []\n",
    "all_pred_idx = []\n",
    "false_dict = {\n",
    "    'false_positive': {c: [] for c in CLASSES},\n",
    "    'false_negative': {c: [] for c in CLASSES},\n",
    "    'misclassified': []\n",
    "}\n",
    "\n",
    "for batch_imgs, batch_trues, batch_fns in eval_ds:\n",
    "    probs = best_model.predict(batch_imgs, verbose=0)\n",
    "    pred_idx = np.argmax(probs, axis=1)\n",
    "    true_idx = np.argmax(batch_trues.numpy(), axis=1)\n",
    "\n",
    "    all_pred_idx.extend(list(pred_idx))\n",
    "    all_true_idx.extend(list(true_idx))\n",
    "\n",
    "    # Track errors with filenames + confidence\n",
    "    for ti, pi, fn, p in zip(true_idx, pred_idx, batch_fns.numpy(), probs):\n",
    "        filename = fn.decode('utf-8') if isinstance(fn, (bytes, bytearray)) else str(fn)\n",
    "        conf = float(np.max(p))\n",
    "        if ti != pi:\n",
    "            false_dict['misclassified'].append({\n",
    "                'filename': filename,\n",
    "                'true_class': CLASSES[int(ti)],\n",
    "                'predicted_class': CLASSES[int(pi)],\n",
    "                'confidence': conf\n",
    "            })\n",
    "        # Per-class FP/FN views\n",
    "        for ci in range(NUM_CLASSES):\n",
    "            # Binary view for class ci\n",
    "            true_bin = (ti == ci)\n",
    "            pred_bin = (pi == ci)\n",
    "            if (not true_bin) and pred_bin:\n",
    "                false_dict['false_positive'][CLASSES[ci]].append(f\"{filename}_{conf:.3f}\")\n",
    "            if true_bin and (not pred_bin):\n",
    "                false_dict['false_negative'][CLASSES[ci]].append(f\"{filename}_{conf:.3f}\")\n",
    "\n",
    "all_true_idx = np.array(all_true_idx, dtype=int)\n",
    "all_pred_idx = np.array(all_pred_idx, dtype=int)\n",
    "\n",
    "# Overall confusion matrix (NUM_CLASSES x NUM_CLASSES)\n",
    "overall_conf = confusion_matrix(all_true_idx, all_pred_idx, labels=list(range(NUM_CLASSES)))\n",
    "\n",
    "# Build per-class binary TP/FP/FN/TN\n",
    "binary_conf = np.zeros((NUM_CLASSES, 4), dtype=float)  # TP, FP, FN, TN\n",
    "for ci in range(NUM_CLASSES):\n",
    "    # For class ci: positive if true==ci / predicted==ci\n",
    "    tp = np.sum((all_true_idx == ci) & (all_pred_idx == ci))\n",
    "    fp = np.sum((all_true_idx != ci) & (all_pred_idx == ci))\n",
    "    fn = np.sum((all_true_idx == ci) & (all_pred_idx != ci))\n",
    "    tn = np.sum((all_true_idx != ci) & (all_pred_idx != ci))\n",
    "    binary_conf[ci] = [tp, fp, fn, tn]\n",
    "\n",
    "def _safe_div(a, b):\n",
    "    return (a / b) if b != 0 else 0.0\n",
    "\n",
    "# Compute metrics\n",
    "tps, fps, fns, tns = binary_conf[:,0], binary_conf[:,1], binary_conf[:,2], binary_conf[:,3]\n",
    "accuracies   = np.array([_safe_div(tp+tn, tp+fp+fn+tn) for tp,fp,fn,tn in binary_conf])\n",
    "recalls      = np.array([_safe_div(tp, tp+fn) for tp,fn in zip(tps,fns)])              # aka sensitivity\n",
    "specificity  = np.array([_safe_div(tn, tn+fp) for tn,fp in zip(tns,fps)])\n",
    "typeI_err    = np.array([_safe_div(fp, fp+tn) for fp,tn in zip(fps,tns)])\n",
    "typeII_err   = np.array([_safe_div(fn, tp+fn) for tp,fn in zip(tps,fns)])\n",
    "precisions   = np.array([_safe_div(tp, tp+fp) for tp,fp in zip(tps,fps)])\n",
    "f1_scores    = np.array([_safe_div(2*p*r, p+r) for p,r in zip(precisions,recalls)])\n",
    "\n",
    "overall_acc  = _safe_div(np.trace(overall_conf), np.sum(overall_conf))\n",
    "\n",
    "macro_precision = float(np.mean(precisions)) if len(precisions) else 0.0\n",
    "macro_recall    = float(np.mean(recalls))    if len(recalls)    else 0.0\n",
    "macro_f1        = float(np.mean(f1_scores))  if len(f1_scores)  else 0.0\n",
    "\n",
    "supports = tps + fns\n",
    "total    = np.sum(supports) if np.sum(supports) > 0 else 1.0\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": list(map(float, accuracies)) + [float(overall_acc)],\n",
    "    \"Precision\": list(map(float, precisions)) + [float(macro_precision)],\n",
    "    \"Recall\": list(map(float, recalls)) + [float(macro_recall)],\n",
    "    \"Specificity\": list(map(float, specificity)) + [float(np.mean(specificity) if len(specificity) else 0.0)],\n",
    "    \"F1-Score\": list(map(float, f1_scores)) + [float(macro_f1)],\n",
    "    \"Type I Error\": list(map(float, typeI_err)) + [float(np.mean(typeI_err) if len(typeI_err) else 0.0)],\n",
    "    \"Type II Error\": list(map(float, typeII_err)) + [float(np.mean(typeII_err) if len(typeII_err) else 0.0)]\n",
    "}\n",
    "\n",
    "# Save CSV metrics and confusion matrix + false inferences JSON\n",
    "eval_csv = str(Path(run_dir) / f\"evaluation_summary_{MODEL_NAME}.csv\")\n",
    "conf_csv = str(Path(run_dir) / f\"confusion_matrix_{MODEL_NAME}.csv\")\n",
    "false_json = str(Path(run_dir) / f\"false_inferences_{MODEL_NAME}.json\")\n",
    "\n",
    "with open(eval_csv, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Metric\", \"Class\", \"Value\"])\n",
    "    # per-class\n",
    "    for name, vals in metrics.items():\n",
    "        if name.startswith(\"Weighted\"):\n",
    "            continue\n",
    "        for idx, v in enumerate(vals[:-1]):\n",
    "            writer.writerow([name, CLASSES[idx], v])\n",
    "    # macro/overall\n",
    "    writer.writerow([])\n",
    "    writer.writerow([\"Metric\", \"Overall/Average\", \"Value\"])\n",
    "    for name, vals in metrics.items():\n",
    "        if name.startswith(\"Weighted\"):\n",
    "            writer.writerow([name, \"Weighted\", vals[0]])\n",
    "        else:\n",
    "            writer.writerow([name, \"Macro Average\", vals[-1]])\n",
    "\n",
    "np.savetxt(conf_csv, overall_conf, delimiter=',', fmt='%d', header=','.join(CLASSES), comments='')\n",
    "\n",
    "with open(false_json, 'w') as jf:\n",
    "    json.dump(false_dict, jf, indent=2)\n",
    "\n",
    "print(\"Saved:\", eval_csv)\n",
    "print(\"Saved:\", conf_csv)\n",
    "print(\"Saved:\", false_json)\n",
    "\n",
    "# --- Visualizations -----------------------------------------------------------\n",
    "\n",
    "# (1) Confusion matrix heatmap with better color scheme\n",
    "plt.figure(figsize=(8, 6))\n",
    "im = plt.imshow(overall_conf, cmap='Blues', interpolation='nearest')\n",
    "plt.title('Confusion Matrix (counts)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(ticks=range(NUM_CLASSES), labels=CLASSES, rotation=45, ha='right')\n",
    "plt.yticks(ticks=range(NUM_CLASSES), labels=CLASSES)\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('True', fontsize=12)\n",
    "\n",
    "# Add text annotations with good contrast\n",
    "for i in range(NUM_CLASSES):\n",
    "    for j in range(NUM_CLASSES):\n",
    "        text_color = 'white' if overall_conf[i, j] > overall_conf.max() / 2 else 'black'\n",
    "        plt.text(j, i, str(overall_conf[i, j]), ha='center', va='center', \n",
    "                color=text_color, fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.colorbar(im, shrink=0.8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (2) Comprehensive Metrics Bar Chart\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Prepare data for visualization\n",
    "metric_names = ['Precision', 'Recall', 'Specificity', 'F1-Score']\n",
    "x = np.arange(len(CLASSES))\n",
    "width = 0.2\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#d62728', '#2ca02c']\n",
    "\n",
    "for i, metric in enumerate(metric_names):\n",
    "    values = metrics[metric][:-1]  # Exclude macro average\n",
    "    bars = ax.bar(x + i*width, values, width, label=metric, color=colors[i], alpha=0.8)\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for j, (bar, val) in enumerate(zip(bars, values)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{val:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Classes', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Metric Values', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Per-Class Performance Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x + width * 1.5)\n",
    "ax.set_xticklabels(CLASSES, rotation=30, ha='right')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (3) Alternative Suggestion: Radar Chart for Macro Metrics\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(projection='polar'))\n",
    "\n",
    "# Macro metrics for radar chart\n",
    "radar_metrics = ['Precision', 'Recall', 'F1-Score', 'Specificity']\n",
    "radar_values = [metrics[m][-1] for m in radar_metrics]  # Get macro averages\n",
    "\n",
    "# Number of variables\n",
    "N = len(radar_metrics)\n",
    "\n",
    "# Compute angle for each axis\n",
    "angles = [n / float(N) * 2 * np.pi for n in range(N)]\n",
    "angles += angles[:1]  # Complete the circle\n",
    "\n",
    "# Add values\n",
    "radar_values += radar_values[:1]  # Complete the circle\n",
    "\n",
    "# Plot\n",
    "ax.plot(angles, radar_values, 'o-', linewidth=2, label='Macro Average', color='#1f77b4')\n",
    "ax.fill(angles, radar_values, alpha=0.25, color='#1f77b4')\n",
    "\n",
    "# Add labels\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(radar_metrics, fontsize=11)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], fontsize=9)\n",
    "ax.grid(True)\n",
    "\n",
    "# Add value labels\n",
    "for angle, value, metric in zip(angles[:-1], radar_values[:-1], radar_metrics):\n",
    "    ax.text(angle, value + 0.05, f'{value:.3f}', ha='center', va='center', \n",
    "            fontsize=10, fontweight='bold', \n",
    "            bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "ax.set_title('Overall Model Performance\\n(Macro Averages)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (4) False Positives vs False Negatives per class\n",
    "fp_counts = [len(false_dict['false_positive'][c]) for c in CLASSES]\n",
    "fn_counts = [len(false_dict['false_negative'][c]) for c in CLASSES]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "x = np.arange(NUM_CLASSES)\n",
    "plt.bar(x - 0.2, fp_counts, width=0.4, label='False Positives', color='#ff7f0e', alpha=0.8)\n",
    "plt.bar(x + 0.2, fn_counts, width=0.4, label='False Negatives', color='#d62728', alpha=0.8)\n",
    "plt.xticks(x, CLASSES, rotation=30, ha='right')\n",
    "plt.title('False Positives vs False Negatives per Class', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n=== EVAL SUMMARY ===\")\n",
    "print(f\"Overall accuracy: {overall_acc:.4f}\")\n",
    "print(f\"Macro F1-Score:  {macro_f1:.4f}\")\n",
    "print(f\"Total samples:    {int(np.sum(overall_conf))}\")\n",
    "print(f\"Total misclass.:  {len(false_dict['misclassified'])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ddc136",
   "metadata": {},
   "source": [
    "## 7. Qualitative Stichprobe: Vorhersage-Visualisierung\n",
    "\n",
    "**Was:**\n",
    "- Visualisierung einiger Vorhersagen mit wahren Labels und Konfidenzwerten\n",
    "- Direkte Anzeige aus `eval_ds` Tensoren (nicht von Festplatte)\n",
    "\n",
    "**Warum:**\n",
    "- **Qualitative Kontrolle:** Visueller Eindruck der Modell-Performance auf echten Bildern\n",
    "- **Fehlerverständnis:** Erkennung von Mustern bei Fehlklassifikationen\n",
    "- **Konfidenz-Analyse:** Bewertung der Modell-Sicherheit bei verschiedenen Vorhersagen\n",
    "\n",
    "**Interpretation:**\n",
    "- **Korrekte Vorhersagen:** Hohe Konfidenz bei richtigen Klassifikationen ist wünschenswert\n",
    "- **Fehlklassifikationen:** Niedrige Konfidenz kann auf schwierige/mehrdeutige Bilder hinweisen\n",
    "- **Systematische Fehler:** Wiederholte Verwechslungen zwischen bestimmten Klassen\n",
    "\n",
    "**Outputs:**\n",
    "- Grid-Anzeige mit 6 Beispielbildern\n",
    "- Je Bild: Vorhersage, Konfidenz, wahre Klasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e4fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_eval_samples(ds, model, k=6):\n",
    "    imgs_shown = 0\n",
    "    for imgs, labels, fns in ds:\n",
    "        probs = model.predict(imgs, verbose=0)\n",
    "        pred_idx = np.argmax(probs, axis=1)\n",
    "        true_idx = np.argmax(labels.numpy(), axis=1)\n",
    "\n",
    "        b = imgs.shape[0]\n",
    "        rows = int(math.ceil(min(k, b) / 3))\n",
    "        cols = 3 if k >= 3 else min(k, b)\n",
    "\n",
    "        plt.figure(figsize=(cols*3, rows*3))\n",
    "        for i in range(min(k, b)):\n",
    "            ax = plt.subplot(rows, cols, i+1)\n",
    "            ax.imshow(imgs[i].numpy())\n",
    "            pidx = int(pred_idx[i])\n",
    "            tidx = int(true_idx[i])\n",
    "            conf = float(np.max(probs[i]))\n",
    "            ax.set_title(f\"pred: {CLASSES[pidx]} ({conf:.2f})\\ntrue: {CLASSES[tidx]}\")\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        imgs_shown += min(k, b)\n",
    "        if imgs_shown >= k:\n",
    "            break\n",
    "\n",
    "# Uncomment to preview a few eval samples (set k as needed)\n",
    "show_eval_samples(eval_ds, best_model, k=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7834cb1",
   "metadata": {},
   "source": [
    "## 8. Dokumentation & Reproduzierbarkeit\n",
    "\n",
    "**Ergebnis:**\n",
    "Dieses Notebook liefert ein vollständig trainiertes und evaluiertes CNN-Modell für die Schienenuntergrund-Klassifikation mit umfassender Dokumentation aller Parameter, Metriken und Ergebnisse. Die systematische Herangehensweise und detaillierte Evaluation bilden eine solide Grundlage für den praktischen Einsatz in der Gleisbett-Analyse.\n",
    "\n",
    "**Gespeicherte Artefakte:**\n",
    "- **Hyperparameter** und **Klassennamen** werden neben dem trainierten Modell im Run-Ordner gespeichert\n",
    "- **Bestes Modell** (nach `val_loss`) wird im Keras-Format gespeichert: `<OUTPUT_DIR>/<MODEL_NAME>__<timestamp>/<MODEL_NAME>.keras`\n",
    "- **Metriken und Confusion Matrix** sind als CSV-Dateien verfügbar\n",
    "- **Fehlklassifikationen** werden als JSON gespeichert (mit Dateinamen und Konfidenzwerten)\n",
    "\n",
    "**Nächste Schritte (optional):**\n",
    "- **Fine-Tuning:** Einfrieren der oberen ResNet-Schichten aufheben (mit kleiner Learning Rate)\n",
    "- **Klassenbalancierung:** Class-balanced Sampling / Focal Loss bei unbalancierten Datensätzen\n",
    "- **Cross-Validation:** Integration verschiedener TFRecord-Shards (falls verfügbar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
