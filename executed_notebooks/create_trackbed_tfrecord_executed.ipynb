{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21991c2",
   "metadata": {},
   "source": [
    "## Einleitung: Trackbed Classification ‚Üí TFRecord\n",
    "\n",
    "**Was:**  \n",
    "- Konvertiert Gleisbett-Klassifikationsdatens√§tze in **TFRecord**-Dateien f√ºr effizientes Training.  \n",
    "- Erwartet: Datensatzordner mit **Bildern** (`imgs/`) und zugeh√∂rigem **Label-Studio-JSON**.  \n",
    "- Klassen (5): **ASPHALT, BALLAST, GRAS, STONE, ERROR**.  \n",
    "- Ablauf: **Labels laden** ‚Üí **Bilder lesen/resize/RGB** ‚Üí **TensorFlow Examples serialisieren** ‚Üí **TFRecord schreiben**.\n",
    "\n",
    "**Warum:**  \n",
    "- **TFRecord** + `tf.data` erm√∂glicht schnelles sequenzielles Laden, Shuffling, Caching und Vorverarbeitung in Trainingspipelines.  \n",
    "- Einheitliches, bin√§res Format reduziert IO-Overhead und erleichtert **reproduzierbare**, skalierbare Trainingsl√§ufe √ºber mehrere Datens√§tze/Gr√∂√üen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd160f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "**Was:**  \n",
    "- Import grundlegender Module f√ºr Datei-IO (`os`, `pathlib.Path`), Serialisierung (`json`), Bildverarbeitung (`cv2`) und Deep Learning (`tensorflow`).  \n",
    "- Bereitstellung von Utilities f√ºr Parallelisierung (`multiprocessing.Pool`, `cpu_count`) und einfache Z√§hlstatistiken (`collections.Counter`).  \n",
    "- Ausgabe von Umgebungsinformationen (TensorFlow-Version, verf√ºgbare CPU-Kerne).\n",
    "\n",
    "**Warum:**  \n",
    "- Zentrale Verf√ºgbarkeit aller ben√∂tigten Funktionen f√ºr robuste Daten- und Modellpipelines.  \n",
    "- Transparenz √ºber die Laufzeitumgebung und Absch√§tzung der verf√ºgbaren Rechenressourcen.  \n",
    "- Effiziente Verarbeitung durch parallele Workloads sowie einfache Aggregationen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a742944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 15:18:47.044592: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-09-07 15:18:47.059225: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-09-07 15:18:47.063423: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-07 15:18:47.073662: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-07 15:18:47.759670: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.1\n",
      "Available CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Available CPU cores: {cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d324f",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**Was:**  \n",
    "- Setzt Basis-Pfade f√ºr die Datens√§tze sowie die zu verarbeitenden Teilmengen (`evaluation`, `train_small`, `train_medium`, `train_large`).  \n",
    "- Definiert die Klasseliste (`trackbed_classes`) passend zur Label-Studio-Konfiguration.  \n",
    "- Legt Bild-Parameter fest (Zielaufl√∂sung) und Parallelisierungsgrad (`num_workers`).  \n",
    "- Bestimmt zul√§ssige Bild-Endungen zur Filterung der Eingabedateien.  \n",
    "- Gibt die wichtigsten Einstellungen zur Kontrolle in der Konsole aus.\n",
    "\n",
    "**Warum:**  \n",
    "- Zentrale Konfiguration erm√∂glicht reproduzierbare und leicht anpassbare Pipelines (Pfade, Umfang, Klassen).  \n",
    "- Konsistente Klassenbezeichnungen gew√§hrleisten korrekte Zuordnung/Validierung gegen√ºber den Labels.  \n",
    "- Vorab definierte Bildgr√∂√üe und Parallelisierung verbessern Laufzeit und Speicherplanung.  \n",
    "- Dateiendungsfilter verhindern Fehler durch ungeeignete oder unerwartete Eingabedateien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "181a81ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /media/andi/ssd2/dev/datasets/multilabel_tb_ds\n",
      "Datasets to process: ['evaluation', 'train_small', 'train_medium', 'train_large']\n",
      "Classes: ['ASPHALT', 'BALLAST', 'GRAS', 'STONE', 'ERROR']\n",
      "Target image size: (224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Base dataset directory (contains evaluation, train_small, train_medium, train_large folders)\n",
    "base_dataset_dir = \"/media/andi/ssd2/dev/datasets/multilabel_tb_ds\"\n",
    "\n",
    "# Datasets to process\n",
    "datasets_to_process = [\n",
    "    \"evaluation\",\n",
    "    \"train_small\",\n",
    "    \"train_medium\",\n",
    "    \"train_large\"\n",
    "]\n",
    "\n",
    "# Trackbed surface classes (should match your Label Studio configuration)\n",
    "trackbed_classes = [\n",
    "    \"ASPHALT\",\n",
    "    \"BALLAST\",\n",
    "    \"GRAS\",\n",
    "    \"STONE\", \n",
    "    \"ERROR\"\n",
    "]\n",
    "\n",
    "# Image processing parameters\n",
    "target_image_size = (224, 224)  # (width, height)\n",
    "num_workers = cpu_count()  # Use all available CPU cores\n",
    "\n",
    "# Image extensions to consider\n",
    "image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "\n",
    "print(f\"Base directory: {base_dataset_dir}\")\n",
    "print(f\"Datasets to process: {datasets_to_process}\")\n",
    "print(f\"Classes: {trackbed_classes}\")\n",
    "print(f\"Target image size: {target_image_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0b4ce",
   "metadata": {},
   "source": [
    "## 3. Debug: Label Studio JSON Structure\n",
    "\n",
    "**Was:**  \n",
    "- L√§dt die Label-Studio-JSON und inspiziert exemplarisch die ersten Eintr√§ge.  \n",
    "- Pr√ºft, ob Labels in `annotations[*].result[*].value.choices` oder in `meta.class` abgelegt sind, und z√§hlt die Vorkommensmuster.  \n",
    "- Gibt eine kurze Strukturbeispiel-Ansicht f√ºr einen Eintrag mit Annotation-Label aus, um den exakten Zugriffspfad zu verifizieren.\n",
    "\n",
    "**Warum:**  \n",
    "- Label-Studio-Exporte k√∂nnen Labels an unterschiedlichen Stellen speichern; die robuste Parser-Logik h√§ngt vom tats√§chlichen Schema ab.  \n",
    "- Die Vorab-Analyse verhindert Fehlzuordnungen und stellt sicher, dass nachfolgende Schritte (Parsing, Auswertung) auf die richtige Quelle zugreifen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1634559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç DEBUGGING LABEL STUDIO JSON STRUCTURE\n",
      "============================================================\n",
      "Total entries in JSON: 1250\n",
      "\n",
      "Analyzing label storage patterns:\n",
      "   1. bvb_1095_0000015900_C.png: ‚úÖ Annotations -> 'ERROR'\n",
      "   2. gent_66_0000001620_C.png: ‚úÖ Annotations -> 'STONE'\n",
      "   3. gvb_1769_0000001020_C.png: ‚úÖ Annotations -> 'STONE'\n",
      "   4. gent_50_0000022440_C.png: ‚úÖ Annotations -> 'STONE'\n",
      "   5. cts_22_0000024090_C.png: ‚úÖ Annotations -> 'ASPHALT'\n",
      "   6. bernmobil_127_0000006450_C.png: ‚úÖ Annotations -> 'BALLAST'\n",
      "   7. gvb_1769_0000000900_C.png: ‚úÖ Annotations -> 'STONE'\n",
      "   8. bernmobil_127_0000003600_C.png: ‚úÖ Annotations -> 'BALLAST'\n",
      "   9. gvb_1818_0000011040_C.png: ‚úÖ Annotations -> 'GRAS'\n",
      "  10. gvb_1819_0000027180_C.png: ‚úÖ Annotations -> 'ERROR'\n",
      "\n",
      "üìä Label storage summary (first 10 entries):\n",
      "  Labels in annotations.result.value.choices: 10\n",
      "  Labels in meta.class: 0\n",
      "  No labels found: 0\n",
      "\n",
      "üìã Example entry with annotation label:\n",
      "File: bvb_1095_0000015900_C.png\n",
      "Label path: annotations[0].result[0].value.choices = ['ERROR']\n",
      "Meta class: error\n"
     ]
    }
   ],
   "source": [
    "# Debug: Examine the JSON structure\n",
    "debug_label_file = \"/media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation_labels.json\"\n",
    "\n",
    "print(\"üîç DEBUGGING LABEL STUDIO JSON STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and examine the first few entries\n",
    "with open(debug_label_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total entries in JSON: {len(data)}\")\n",
    "\n",
    "# Check different label storage patterns\n",
    "annotations_labels = 0\n",
    "meta_labels = 0\n",
    "no_labels = 0\n",
    "\n",
    "print(\"\\nAnalyzing label storage patterns:\")\n",
    "for i, entry in enumerate(data[:10]):  # Check first 10 entries\n",
    "    filename = entry.get('file_upload', 'unknown')\n",
    "    \n",
    "    # Method 1: Check annotations.result.value.choices\n",
    "    annotation_label = None\n",
    "    for annotation in entry.get('annotations', []):\n",
    "        for result in annotation.get('result', []):\n",
    "            choices = result.get('value', {}).get('choices', [])\n",
    "            if choices:\n",
    "                annotation_label = choices[0].upper()\n",
    "                break\n",
    "        if annotation_label:\n",
    "            break\n",
    "    \n",
    "    # Method 2: Check meta.class\n",
    "    meta_label = entry.get('meta', {}).get('class', '')\n",
    "    if meta_label:\n",
    "        meta_label = meta_label.upper()\n",
    "    \n",
    "    # Count patterns\n",
    "    if annotation_label:\n",
    "        annotations_labels += 1\n",
    "        status = \"‚úÖ Annotations\"\n",
    "        label = annotation_label\n",
    "    elif meta_label:\n",
    "        meta_labels += 1\n",
    "        status = \"üîß Meta\"\n",
    "        label = meta_label\n",
    "    else:\n",
    "        no_labels += 1\n",
    "        status = \"‚ùå No label\"\n",
    "        label = \"None\"\n",
    "    \n",
    "    print(f\"  {i+1:2d}. {filename}: {status} -> '{label}'\")    \n",
    "\n",
    "print(f\"\\nüìä Label storage summary (first 10 entries):\")\n",
    "print(f\"  Labels in annotations.result.value.choices: {annotations_labels}\")\n",
    "print(f\"  Labels in meta.class: {meta_labels}\")\n",
    "print(f\"  No labels found: {no_labels}\")\n",
    "\n",
    "# Show detailed structure of first entry with annotation label\n",
    "for entry in data[:5]:\n",
    "    if entry.get('annotations', []) and entry['annotations'][0].get('result', []):\n",
    "        print(f\"\\nüìã Example entry with annotation label:\")\n",
    "        print(f\"File: {entry.get('file_upload', 'unknown')}\")\n",
    "        result = entry['annotations'][0]['result'][0]\n",
    "        print(f\"Label path: annotations[0].result[0].value.choices = {result.get('value', {}).get('choices', [])}\")\n",
    "        print(f\"Meta class: {entry.get('meta', {}).get('class', 'N/A')}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a2dc9",
   "metadata": {},
   "source": [
    "## 4. Helper Functions: TensorFlow Feature Creation\n",
    "\n",
    "**Was:**  \n",
    "- Definiert Hilfsfunktionen zur Erstellung von **`tf.train.Feature`**-Feldern:  \n",
    "  - `_bytes_feature` f√ºr Byte-/String-Daten  \n",
    "  - `_int64_feature` f√ºr Ganzzahlen  \n",
    "- Diese Bausteine werden beim Serialisieren von Beispielen zu **`tf.train.Example`**/**TFRecord** verwendet.\n",
    "\n",
    "**Warum:**  \n",
    "- Vereinfachen das Erstellen konsistenter **TFRecord**-Schemas und reduzieren Boilerplate-Code.  \n",
    "- Stellen sicher, dass Datentypen korrekt verpackt werden und sp√§tere Deserialisierung/Parsing in TensorFlow zuverl√§ssig funktioniert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0880383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Create a bytes feature for TensorFlow Examples\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Create an int64 feature for TensorFlow Examples\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eee661",
   "metadata": {},
   "source": [
    "## 5. Laden der Labels\n",
    "\n",
    "**Was:**  \n",
    "- L√§dt den Label-Studio-Export und extrahiert Gleisbett-Klassen aus zwei m√∂glichen Quellen:  \n",
    "  1) `annotations[*].result[*].value.choices`  \n",
    "  2) `meta.class`  \n",
    "- Gibt ein Mapping **Dateiname ‚Üí Klassenindex** sowie **Klassenname ‚Üí Index** zur√ºck.\n",
    "\n",
    "**Warum:**  \n",
    "- Label-Studio kann Labels je nach Export/Workflow an unterschiedlichen Stellen speichern; die Funktion unterst√ºtzt beide Formate robust.  \n",
    "- Ein konsistentes Klassenindex-Mapping ist Grundlage f√ºr nachgelagerte Schritte (Statistiken, Datensatzaufbereitung, Training).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1df5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trackbed_labels(label_studio_path, class_list):\n",
    "    \"\"\"\n",
    "    Load and parse Label Studio JSON file for trackbed surface classification.\n",
    "    \n",
    "    This function handles multiple label storage formats:\n",
    "    1. Labels in annotations.result.value.choices (standard Label Studio)\n",
    "    2. Labels in meta.class field (from your balanced dataset generation)\n",
    "    \n",
    "    Args:\n",
    "        label_studio_path (str): Path to Label Studio JSON export\n",
    "        class_list (list): List of valid class names\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (labels_dict, class_to_index)\n",
    "            - labels_dict: Mapping from filename to class_index\n",
    "            - class_to_index: Mapping from class_name to index\n",
    "    \"\"\"\n",
    "    with open(label_studio_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    labels = {}\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(class_list)}\n",
    "    \n",
    "    print(f\"üîç Processing {len(data)} entries from Label Studio JSON...\")\n",
    "    \n",
    "    annotations_count = 0\n",
    "    meta_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        # Extract filename from image URI or file_upload field\n",
    "        filename = None\n",
    "        if 'file_upload' in entry:\n",
    "            filename = entry['file_upload']\n",
    "        \n",
    "        if not filename:\n",
    "            print(f\"Warning: Could not extract filename from entry {i+1}\")\n",
    "            continue\n",
    "        \n",
    "        class_label = None\n",
    "        label_source = \"none\"\n",
    "        \n",
    "        # Method 1: Try to get class from annotations.result.value.choices (standard Label Studio)\n",
    "        for annotation in entry.get('annotations', []):\n",
    "            for result in annotation.get('result', []):\n",
    "                choices = result.get('value', {}).get('choices', [])\n",
    "                if choices:\n",
    "                    # Take the first choice (should be only one for single-class)\n",
    "                    choice = choices[0].upper()  # Normalize to uppercase\n",
    "                    if choice in class_to_index:\n",
    "                        class_label = class_to_index[choice]\n",
    "                        label_source = \"annotations\"\n",
    "                        annotations_count += 1\n",
    "                        if i < 5:  # Debug first few entries\n",
    "                            print(f\"  Entry {i+1}: {filename} -> {choice} (from annotations.result.value.choices)\")\n",
    "                        break\n",
    "            if class_label is not None:\n",
    "                break\n",
    "        \n",
    "        # Method 2: Try to get class from meta field (from balanced dataset generation)\n",
    "        if class_label is None:\n",
    "            meta = entry.get('meta', {})\n",
    "            if 'class' in meta:\n",
    "                meta_class = meta['class'].upper()  # Normalize to uppercase\n",
    "                if meta_class in class_to_index:\n",
    "                    class_label = class_to_index[meta_class]\n",
    "                    label_source = \"meta\"\n",
    "                    meta_count += 1\n",
    "                    if i < 5:  # Debug first few entries\n",
    "                        print(f\"  Entry {i+1}: {filename} -> {meta_class} (from meta.class)\")\n",
    "        \n",
    "        # Store the label if found\n",
    "        if class_label is not None:\n",
    "            labels[filename] = class_label\n",
    "        else:\n",
    "            missing_count += 1\n",
    "            if i < 10:  # Show first few missing labels for debugging\n",
    "                print(f\"  Entry {i+1}: {filename} -> NO LABEL FOUND\")\n",
    "\n",
    "    print(f\"\\nüìä Label extraction summary:\")\n",
    "    print(f\"  Successfully loaded: {len(labels)} labels\")\n",
    "    print(f\"  From annotations.result.value.choices: {annotations_count}\")\n",
    "    print(f\"  From meta.class: {meta_count}\")\n",
    "    print(f\"  Missing labels: {missing_count}\")\n",
    "    print(f\"  Total entries processed: {len(data)}\")\n",
    "    \n",
    "    return labels, class_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503b645",
   "metadata": {},
   "source": [
    "## 6. Bildverarbeitungsfunktion\n",
    "\n",
    "**Was:**  \n",
    "- L√§dt eine einzelne Bilddatei, validiert Dateiendung und Existenz, liest das Bild als **Graustufen**, konvertiert nach **RGB** und skaliert auf die Zielgr√∂√üe.  \n",
    "- Gibt bei Erfolg `(filename, resized_img)` zur√ºck, andernfalls `None` (geeignet f√ºr parallele Verarbeitung mit `Pool.map`).\n",
    "\n",
    "**Warum:**  \n",
    "- Einheitliche **Eingabeformate** (3 Kan√§le, feste Aufl√∂sung) sind Voraussetzung. \n",
    "- Fr√ºhe Validierungen verhindern Laufzeitfehler durch fehlende/inkompatible Dateien und beschleunigen robuste Batch-Pipelines.  \n",
    "- Die RGB-Konvertierung stellt Kompatibilit√§t zu Modellen sicher, die **3-Kanal-Eingaben** erwarten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9246f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(args):\n",
    "    \"\"\"Process a single image: load, convert to RGB, and resize.\"\"\"\n",
    "    filename, input_dir, size = args\n",
    "    \n",
    "    if not filename.lower().endswith(image_extensions):\n",
    "        return None\n",
    "    \n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: Image file not found: {file_path}\")\n",
    "        return None\n",
    "        \n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not load image {filename}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert grayscale to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, size)\n",
    "    return filename, resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f3583",
   "metadata": {},
   "source": [
    "## 7. TensorFlow Example-Serialisierung\n",
    "\n",
    "**Was:**  \n",
    "- Serialisiert ein einzelnes Beispiel (Bild + Label) zu einem **`tf.train.Example`**.  \n",
    "- Verpackt Dateiname, Rohbilddaten (`image_raw`), Dimensionen (`height`, `width`, `depth`) sowie Label-Informationen (`label`, `class_name`) als **Features**.\n",
    "\n",
    "**Warum:**  \n",
    "- Einheitliches, modellunabh√§ngiges **TFRecord**-Format erm√∂glicht effizientes Laden, Caching und Shuffling in TensorFlow-Pipelines.  \n",
    "- Korrekte Typisierung der Felder (Bytes/Int64) stellt zuverl√§ssiges Parsen im Trainings-/Inference-Input-Graphen sicher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7277deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_trackbed_example(filename, image, class_index, class_name):\n",
    "    \"\"\"Create a TensorFlow Example from image and class label.\"\"\"\n",
    "    features = {\n",
    "        'image_filename': _bytes_feature(filename.encode('utf-8')),\n",
    "        'image_raw': _bytes_feature(image.tobytes()),\n",
    "        'height': _int64_feature(image.shape[0]),\n",
    "        'width': _int64_feature(image.shape[1]),\n",
    "        'depth': _int64_feature(image.shape[2]),\n",
    "        'label': _int64_feature(class_index),\n",
    "        'class_name': _bytes_feature(class_name.encode('utf-8'))\n",
    "    }\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f684ec2",
   "metadata": {},
   "source": [
    "## 8. Hauptverarbeitungsschleife\n",
    "\n",
    "**Was:**  \n",
    "- Iteriert √ºber die ausgew√§hlten Datens√§tze, setzt Pfade (Bilder, Labels, TFRecord-Ziel) und pr√ºft deren Existenz.  \n",
    "- L√§dt Labels via `load_trackbed_labels`, erstellt eine Klassenverteilungs√ºbersicht und filtert nur die **gelabelten** Bilder.  \n",
    "- Verarbeitet Bilder **parallel** (Resize/Format) und serialisiert sie als `tf.train.Example` in eine **TFRecord**-Datei.  \n",
    "- H√§lt Laufstatistiken √ºber alle Datens√§tze hinweg (Anzahl verarbeiteter Datens√§tze/Bilder, erzeugte TFRecords).\n",
    "\n",
    "**Warum:**  \n",
    "- Strukturierter End-to-End-Ablauf von der Label-Zuordnung √ºber Bildvorbereitung bis zur effizienten Speicherung erm√∂glicht reproduzierbare, skalierbare Datenpipelines.  \n",
    "- Vorab-Pr√ºfungen und Filtern vermeiden Fehlerl√§ufe, Parallelisierung reduziert Laufzeit, TFRecord-Format optimiert das sp√§tere Laden in TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88aac439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing dataset: evaluation\n",
      "============================================================\n",
      "üìÅ Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation\n",
      "üñºÔ∏è  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/imgs\n",
      "üè∑Ô∏è  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation_labels.json\n",
      "üíæ Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation.tfrecord\n",
      "\n",
      "üîç Loading labels from evaluation_labels.json...\n",
      "üîç Processing 1250 entries from Label Studio JSON...\n",
      "  Entry 1: bvb_1095_0000015900_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 2: gent_66_0000001620_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 3: gvb_1769_0000001020_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 4: gent_50_0000022440_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 5: cts_22_0000024090_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "\n",
      "üìä Label extraction summary:\n",
      "  Successfully loaded: 1250 labels\n",
      "  From annotations.result.value.choices: 1250\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 1250\n",
      "üìä Loaded labels for 1250 images\n",
      "\n",
      "üìà Class distribution:\n",
      "  ASPHALT: 250 images (20.0%)\n",
      "  BALLAST: 250 images (20.0%)\n",
      "  GRAS: 250 images (20.0%)\n",
      "  STONE: 250 images (20.0%)\n",
      "  ERROR: 250 images (20.0%)\n",
      "\n",
      "üñºÔ∏è  Scanning images folder...\n",
      "üì∏ Found 1250 image files\n",
      "üè∑Ô∏è  Images with labels: 1250\n",
      "\n",
      "‚öôÔ∏è  Processing 1250 images...\n",
      "‚úÖ Successfully processed 1250 images\n",
      "\n",
      "üíæ Creating TFRecord: evaluation.tfrecord\n",
      "üíæ Wrote 1250 records to TFRecord\n",
      "‚úÖ Completed evaluation\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_small\n",
      "============================================================\n",
      "üìÅ Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small\n",
      "üñºÔ∏è  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/imgs\n",
      "üè∑Ô∏è  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/train_small_labels.json\n",
      "üíæ Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/train_small.tfrecord\n",
      "\n",
      "üîç Loading labels from train_small_labels.json...\n",
      "üîç Processing 1000 entries from Label Studio JSON...\n",
      "  Entry 1: vbz_3284_0000002460_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 2: retm_142_0000021390_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3349_0000001260_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 4: gent_49_0000005070_C.png -> GRAS (from annotations.result.value.choices)\n",
      "  Entry 5: gvb_1830_0000016950_C.png -> GRAS (from annotations.result.value.choices)\n",
      "\n",
      "üìä Label extraction summary:\n",
      "  Successfully loaded: 1000 labels\n",
      "  From annotations.result.value.choices: 1000\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 1000\n",
      "üìä Loaded labels for 1000 images\n",
      "\n",
      "üìà Class distribution:\n",
      "  ASPHALT: 200 images (20.0%)\n",
      "  BALLAST: 200 images (20.0%)\n",
      "  GRAS: 200 images (20.0%)\n",
      "  STONE: 200 images (20.0%)\n",
      "  ERROR: 200 images (20.0%)\n",
      "\n",
      "üñºÔ∏è  Scanning images folder...\n",
      "üì∏ Found 1000 image files\n",
      "üè∑Ô∏è  Images with labels: 1000\n",
      "\n",
      "‚öôÔ∏è  Processing 1000 images...\n",
      "‚úÖ Successfully processed 1000 images\n",
      "\n",
      "üíæ Creating TFRecord: train_small.tfrecord\n",
      "üíæ Wrote 1000 records to TFRecord\n",
      "‚úÖ Completed train_small\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_medium\n",
      "============================================================\n",
      "üìÅ Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium\n",
      "üñºÔ∏è  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/imgs\n",
      "üè∑Ô∏è  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/train_medium_labels.json\n",
      "üíæ Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/train_medium.tfrecord\n",
      "\n",
      "üîç Loading labels from train_medium_labels.json...\n",
      "üîç Processing 2500 entries from Label Studio JSON...\n",
      "  Entry 1: cts_16_0000022830_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 2: cts_1_0000002760_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3313_0000025500_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 4: ava_122_0000014940_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 5: ava_129_0000019890_C.png -> ERROR (from annotations.result.value.choices)\n",
      "\n",
      "üìä Label extraction summary:\n",
      "  Successfully loaded: 2500 labels\n",
      "  From annotations.result.value.choices: 2500\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 2500\n",
      "üìä Loaded labels for 2500 images\n",
      "\n",
      "üìà Class distribution:\n",
      "  ASPHALT: 500 images (20.0%)\n",
      "  BALLAST: 500 images (20.0%)\n",
      "  GRAS: 500 images (20.0%)\n",
      "  STONE: 500 images (20.0%)\n",
      "  ERROR: 500 images (20.0%)\n",
      "\n",
      "üñºÔ∏è  Scanning images folder...\n",
      "üì∏ Found 2500 image files\n",
      "üè∑Ô∏è  Images with labels: 2500\n",
      "\n",
      "‚öôÔ∏è  Processing 2500 images...\n",
      "‚úÖ Successfully processed 2500 images\n",
      "\n",
      "üíæ Creating TFRecord: train_medium.tfrecord\n",
      "üíæ Wrote 2500 records to TFRecord\n",
      "‚úÖ Completed train_medium\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_large\n",
      "============================================================\n",
      "üìÅ Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large\n",
      "üñºÔ∏è  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/imgs\n",
      "üè∑Ô∏è  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/train_large_labels.json\n",
      "üíæ Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/train_large.tfrecord\n",
      "\n",
      "üîç Loading labels from train_large_labels.json...\n",
      "üîç Processing 5040 entries from Label Studio JSON...\n",
      "  Entry 1: retm_140_0000012090_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 2: ava_110_0000001230_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3532_0000009060_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 4: bvb_1117_0000008910_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 5: gent_54_0000000540_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "\n",
      "üìä Label extraction summary:\n",
      "  Successfully loaded: 5040 labels\n",
      "  From annotations.result.value.choices: 5040\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 5040\n",
      "üìä Loaded labels for 5040 images\n",
      "\n",
      "üìà Class distribution:\n",
      "  ASPHALT: 1008 images (20.0%)\n",
      "  BALLAST: 1008 images (20.0%)\n",
      "  GRAS: 1008 images (20.0%)\n",
      "  STONE: 1008 images (20.0%)\n",
      "  ERROR: 1008 images (20.0%)\n",
      "\n",
      "üñºÔ∏è  Scanning images folder...\n",
      "üì∏ Found 5040 image files\n",
      "üè∑Ô∏è  Images with labels: 5040\n",
      "\n",
      "‚öôÔ∏è  Processing 5040 images...\n",
      "‚úÖ Successfully processed 5040 images\n",
      "\n",
      "üíæ Creating TFRecord: train_large.tfrecord\n",
      "üíæ Wrote 5040 records to TFRecord\n",
      "‚úÖ Completed train_large\n"
     ]
    }
   ],
   "source": [
    "# Track overall statistics\n",
    "overall_stats = {\n",
    "    'datasets_processed': 0,\n",
    "    'total_images': 0,\n",
    "    'tfrecord_files_created': []\n",
    "}\n",
    "\n",
    "for dataset_name in datasets_to_process:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing dataset: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Define paths\n",
    "    dataset_folder = os.path.join(base_dataset_dir, dataset_name)\n",
    "    images_folder = os.path.join(dataset_folder, 'imgs')\n",
    "    label_file = os.path.join(dataset_folder, f\"{dataset_name}_labels.json\")\n",
    "    output_tfrecord = os.path.join(dataset_folder, f\"{dataset_name}.tfrecord\")\n",
    "    \n",
    "    # Check if dataset folder exists\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        print(f\"‚ùå Dataset folder not found: {dataset_folder}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if images folder exists\n",
    "    if not os.path.exists(images_folder):\n",
    "        print(f\"‚ùå Images folder not found: {images_folder}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if label file exists\n",
    "    if not os.path.exists(label_file):\n",
    "        print(f\"‚ùå Label file not found: {label_file}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"üìÅ Dataset folder: {dataset_folder}\")\n",
    "    print(f\"üñºÔ∏è  Images folder: {images_folder}\")\n",
    "    print(f\"üè∑Ô∏è  Label file: {label_file}\")\n",
    "    print(f\"üíæ Output TFRecord: {output_tfrecord}\")\n",
    "    \n",
    "    # Step 1: Load labels\n",
    "    print(f\"\\nüîç Loading labels from {os.path.basename(label_file)}...\")\n",
    "    labels_dict, class_to_index = load_trackbed_labels(label_file, trackbed_classes)\n",
    "    print(f\"üìä Loaded labels for {len(labels_dict)} images\")\n",
    "    \n",
    "    # Analyze label distribution\n",
    "    label_distribution = Counter(labels_dict.values())\n",
    "    print(f\"\\nüìà Class distribution:\")\n",
    "    for class_name, class_idx in class_to_index.items():\n",
    "        count = label_distribution.get(class_idx, 0)\n",
    "        percentage = (count / len(labels_dict) * 100) if labels_dict else 0\n",
    "        print(f\"  {class_name}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Step 2: Get all image files\n",
    "    print(f\"\\nüñºÔ∏è  Scanning images folder...\")\n",
    "    all_image_files = [f for f in os.listdir(images_folder) \n",
    "                      if f.lower().endswith(image_extensions)]\n",
    "    print(f\"üì∏ Found {len(all_image_files)} image files\")\n",
    "    \n",
    "    # Filter images that have labels\n",
    "    labeled_images = [img for img in all_image_files if img in labels_dict]\n",
    "    print(f\"üè∑Ô∏è  Images with labels: {len(labeled_images)}\")\n",
    "    \n",
    "    if len(labeled_images) == 0:\n",
    "        print(f\"‚ùå No labeled images found for {dataset_name}\")\n",
    "        print(f\"First 5 image files: {all_image_files[:5]}\")\n",
    "        print(f\"First 5 label keys: {list(labels_dict.keys())[:5]}\")\n",
    "        continue\n",
    "    \n",
    "    # Step 3: Process images in parallel\n",
    "    print(f\"\\n‚öôÔ∏è  Processing {len(labeled_images)} images...\")\n",
    "    tasks = [(filename, images_folder, target_image_size) for filename in labeled_images]\n",
    "    processed_images = []\n",
    "    \n",
    "    with Pool(num_workers) as pool:\n",
    "        for result in pool.imap_unordered(process_image, tasks):\n",
    "            if result is not None:\n",
    "                processed_images.append(result)\n",
    "    \n",
    "    print(f\"‚úÖ Successfully processed {len(processed_images)} images\")\n",
    "    \n",
    "    # Step 4: Create TFRecord\n",
    "    print(f\"\\nüíæ Creating TFRecord: {os.path.basename(output_tfrecord)}\")\n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_tfrecord) as writer:\n",
    "        for filename, image in processed_images:\n",
    "            class_index = labels_dict[filename]\n",
    "            class_name = trackbed_classes[class_index]\n",
    "            example = serialize_trackbed_example(filename, image, class_index, class_name)\n",
    "            writer.write(example)\n",
    "    \n",
    "    print(f\"üíæ Wrote {len(processed_images)} records to TFRecord\")\n",
    "    \n",
    "    # Update overall statistics\n",
    "    overall_stats['datasets_processed'] += 1\n",
    "    overall_stats['total_images'] += len(processed_images)\n",
    "    overall_stats['tfrecord_files_created'].append(output_tfrecord)\n",
    "    \n",
    "    print(f\"‚úÖ Completed {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91963f5d",
   "metadata": {},
   "source": [
    "## 9. Validierung\n",
    "\n",
    "**Was:**  \n",
    "- Liest die erzeugten TFRecord-Dateien ein, parst Beispiele anhand eines definierten Feature-Schemas, zeigt Stichproben (erste Records) und ermittelt Gesamtanzahl sowie Klassenverteilung je TFRecord.\n",
    "\n",
    "**Warum:**  \n",
    "- Pr√ºft die korrekte Serialisierung (Feldnamen/-typen, Dimensionen, Labels) und stellt sicher, dass Umfang und Verteilung der Daten den Erwartungen entsprechen ‚Äî um Pipelinefehler fr√ºhzeitig zu erkennen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079ad5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîç VALIDATION\n",
      "============================================================\n",
      "\n",
      "üìÅ Validating evaluation...\n",
      "üìä First 3 records:\n",
      "  ava_116_0000001470_C.png: class=ERROR (label=4), size=224x224\n",
      "  retm_103_0000023430_C.png: class=ASPHALT (label=0), size=224x224\n",
      "  gent_50_0000010530_C.png: class=GRAS (label=2), size=224x224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1757251139.520161  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1757251139.556120  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1757251139.559938  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1757251139.565947  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1757251139.570766  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1757251139.574416  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1757251139.735828  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1757251139.737829  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1757251139.739510  158577 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-09-07 15:18:59.741081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 201 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2025-09-07 15:18:59.754915: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 201.38MiB (211156992 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-09-07 15:18:59.755008: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 181.24MiB (190041344 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-09-07 15:18:59.755086: I external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:1578] failed to allocate 163.11MiB (171037440 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2025-09-07 15:18:59.812986: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-09-07 15:19:00.825077: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Total records: 1250\n",
      "üìä Class distribution: {'ERROR': 250, 'ASPHALT': 250, 'GRAS': 250, 'STONE': 250, 'BALLAST': 250}\n",
      "‚úÖ Validation successful\n",
      "\n",
      "üìÅ Validating train_small...\n",
      "üìä First 3 records:\n",
      "  gvb_1833_0000007890_C.png: class=ERROR (label=4), size=224x224\n",
      "  gent_71_0000005550_C.png: class=ASPHALT (label=0), size=224x224\n",
      "  cts_9_0000030930_C.png: class=STONE (label=3), size=224x224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 15:19:01.634437: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Total records: 1000\n",
      "üìä Class distribution: {'ERROR': 200, 'ASPHALT': 200, 'STONE': 200, 'BALLAST': 200, 'GRAS': 200}\n",
      "‚úÖ Validation successful\n",
      "\n",
      "üìÅ Validating train_medium...\n",
      "üìä First 3 records:\n",
      "  bvb_1168_0000003750_C.png: class=ERROR (label=4), size=224x224\n",
      "  gent_60_0000008430_C.png: class=GRAS (label=2), size=224x224\n",
      "  gent_64_0000000810_C.png: class=STONE (label=3), size=224x224\n",
      "üìà Total records: 2500\n",
      "üìä Class distribution: {'ERROR': 500, 'GRAS': 500, 'STONE': 500, 'BALLAST': 500, 'ASPHALT': 500}\n",
      "‚úÖ Validation successful\n",
      "\n",
      "üìÅ Validating train_large...\n",
      "üìä First 3 records:\n",
      "  bvb_1169_0000011670_C.png: class=ERROR (label=4), size=224x224\n",
      "  ava_104_0000017490_C.png: class=ERROR (label=4), size=224x224\n",
      "  cts_28_0000010710_C.png: class=GRAS (label=2), size=224x224\n",
      "üìà Total records: 5040\n",
      "üìä Class distribution: {'ERROR': 1008, 'GRAS': 1008, 'BALLAST': 1008, 'ASPHALT': 1008, 'STONE': 1008}\n",
      "‚úÖ Validation successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 15:19:07.894708: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üîç VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Feature description for parsing\n",
    "feature_description = {\n",
    "    'image_filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'class_name': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "for tfrecord_path in overall_stats['tfrecord_files_created']:\n",
    "    dataset_name = os.path.basename(tfrecord_path).replace('.tfrecord', '')\n",
    "    print(f\"\\nüìÅ Validating {dataset_name}...\")\n",
    "    \n",
    "    if not os.path.exists(tfrecord_path):\n",
    "        print(f\"‚ùå TFRecord file not found: {tfrecord_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "        record_count = 0\n",
    "        class_distribution = Counter()\n",
    "        \n",
    "        print(\"üìä First 3 records:\")\n",
    "        for i, raw_record in enumerate(dataset.take(3)):\n",
    "            example = tf.io.parse_single_example(raw_record, feature_description)\n",
    "            filename = example['image_filename'].numpy().decode('utf-8')\n",
    "            label = example['label'].numpy()\n",
    "            class_name = example['class_name'].numpy().decode('utf-8')\n",
    "            height = example['height'].numpy()\n",
    "            width = example['width'].numpy()\n",
    "            print(f\"  {filename}: class={class_name} (label={label}), size={width}x{height}\")\n",
    "        \n",
    "        # Count total records and class distribution\n",
    "        for raw_record in dataset:\n",
    "            example = tf.io.parse_single_example(raw_record, feature_description)\n",
    "            class_name = example['class_name'].numpy().decode('utf-8')\n",
    "            class_distribution[class_name] += 1\n",
    "            record_count += 1\n",
    "        \n",
    "        print(f\"üìà Total records: {record_count}\")\n",
    "        print(f\"üìä Class distribution: {dict(class_distribution)}\")\n",
    "        print(f\"‚úÖ Validation successful\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5361abd",
   "metadata": {},
   "source": [
    "## 10. Zusammenfassung & Nutzungsbeispiel\n",
    "\n",
    "**Was:**  \n",
    "- Gibt eine kompakte Zusammenfassung der Verarbeitung aus (Basisverzeichnis, Zielbildgr√∂√üe, Klassen, Anzahl verarbeiteter Datens√§tze/Bilder).  \n",
    "- Listet alle erzeugten TFRecord-Dateien mit Dateigr√∂√üe auf.  \n",
    "- Erzeugt ein kurzes Codebeispiel, wie die TFRecords mit `tf.data.TFRecordDataset` geladen, geparst und gebatcht werden k√∂nnen.\n",
    "\n",
    "**Warum:**  \n",
    "- Bietet einen schnellen √úberblick √ºber das Ergebnis der Pipeline und erleichtert die Nachvollziehbarkeit.  \n",
    "- Das Nutzungsbeispiel dient als direkter Einstieg f√ºr nachgelagerte Trainings-Pipelines in TensorFlow und reduziert Einrichtungsaufwand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d2252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìã SUMMARY REPORT\n",
      "============================================================\n",
      "üìÅ Base directory: /media/andi/ssd2/dev/datasets/multilabel_tb_ds\n",
      "üéØ Target image size: (224, 224)\n",
      "üè∑Ô∏è  Classes: ['ASPHALT', 'BALLAST', 'GRAS', 'STONE', 'ERROR']\n",
      "üìä Datasets processed: 4\n",
      "üñºÔ∏è  Total images processed: 9790\n",
      "\n",
      "üíæ TFRecord files created:\n",
      "  üìÑ /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation.tfrecord (179.7 MB)\n",
      "  üìÑ /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/train_small.tfrecord (143.7 MB)\n",
      "  üìÑ /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/train_medium.tfrecord (359.3 MB)\n",
      "  üìÑ /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/train_large.tfrecord (724.4 MB)\n",
      "\n",
      "üéâ TFRecord creation complete!\n",
      "üìù All files are ready for TensorFlow training.\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üìã SUMMARY REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"üìÅ Base directory: {base_dataset_dir}\")\n",
    "print(f\"üéØ Target image size: {target_image_size}\")\n",
    "print(f\"üè∑Ô∏è  Classes: {trackbed_classes}\")\n",
    "print(f\"üìä Datasets processed: {overall_stats['datasets_processed']}\")\n",
    "print(f\"üñºÔ∏è  Total images processed: {overall_stats['total_images']}\")\n",
    "\n",
    "print(f\"\\nüíæ TFRecord files created:\")\n",
    "for tfrecord_path in overall_stats['tfrecord_files_created']:\n",
    "    file_size = os.path.getsize(tfrecord_path) / (1024 * 1024)  # MB\n",
    "    print(f\"  üìÑ {tfrecord_path} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\nüéâ TFRecord creation complete!\")\n",
    "print(f\"üìù All files are ready for TensorFlow training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
