{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21991c2",
   "metadata": {},
   "source": [
    "# Trackbed Classification Dataset to TFRecord\n",
    "\n",
    "This notebook converts trackbed classification datasets to TFRecord format for efficient training.\n",
    "\n",
    "## Overview\n",
    "- **Input**: Dataset folder with organized images and Label Studio JSON files\n",
    "- **Output**: TFRecord files for trackbed classification (asphalt, ballast, gras, stone, error)\n",
    "- **Classes**: Multi-class classification with 5 trackbed surface types\n",
    "\n",
    "## Dataset Structure Expected\n",
    "```\n",
    "dataset_folder/\n",
    "├── imgs/           # All images\n",
    "└── labels.json     # Label Studio JSON with classifications\n",
    "```\n",
    "\n",
    "## Process Steps\n",
    "1. **Load Labels**: Parse Label Studio JSON to extract trackbed surface classifications\n",
    "2. **Process Images**: Read, resize, and convert to RGB\n",
    "3. **Serialize**: Create TensorFlow Examples with image data and class labels\n",
    "4. **Write TFRecord**: Save all examples to .tfrecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd160f",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a742944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "Available CPU cores: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Available CPU cores: {cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d324f",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your dataset paths and parameters here. This notebook can process multiple datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "181a81ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /media/andi/ssd2/dev/datasets/multilabel_tb_ds\n",
      "Datasets to process: ['evaluation', 'train_small', 'train_medium', 'train_large']\n",
      "Classes: ['ASPHALT', 'BALLAST', 'GRAS', 'STONE', 'ERROR']\n",
      "Target image size: (224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Base dataset directory (contains evaluation, train_small, train_medium, train_large folders)\n",
    "base_dataset_dir = \"/media/andi/ssd2/dev/datasets/multilabel_tb_ds\"\n",
    "\n",
    "# Datasets to process\n",
    "datasets_to_process = [\n",
    "    \"evaluation\",\n",
    "    \"train_small\",\n",
    "    \"train_medium\",\n",
    "    \"train_large\"\n",
    "]\n",
    "\n",
    "# Trackbed surface classes (should match your Label Studio configuration)\n",
    "trackbed_classes = [\n",
    "    \"ASPHALT\",\n",
    "    \"BALLAST\",\n",
    "    \"GRAS\",\n",
    "    \"STONE\", \n",
    "    \"ERROR\"\n",
    "]\n",
    "\n",
    "# Image processing parameters\n",
    "target_image_size = (224, 224)  # (width, height)\n",
    "num_workers = cpu_count()  # Use all available CPU cores\n",
    "\n",
    "# Image extensions to consider\n",
    "image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "\n",
    "print(f\"Base directory: {base_dataset_dir}\")\n",
    "print(f\"Datasets to process: {datasets_to_process}\")\n",
    "print(f\"Classes: {trackbed_classes}\")\n",
    "print(f\"Target image size: {target_image_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0b4ce",
   "metadata": {},
   "source": [
    "## Debug: Examine Label Studio JSON Structure\n",
    "\n",
    "Let's examine the actual structure of your Label Studio JSON to understand how labels are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1634559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 DEBUGGING LABEL STUDIO JSON STRUCTURE\n",
      "============================================================\n",
      "Total entries in JSON: 1250\n",
      "\n",
      "Analyzing label storage patterns:\n",
      "   1. bvb_1095_0000015900_C.png: ✅ Annotations -> 'ERROR'\n",
      "   2. gent_66_0000001620_C.png: ✅ Annotations -> 'STONE'\n",
      "   3. gvb_1769_0000001020_C.png: ✅ Annotations -> 'STONE'\n",
      "   4. gent_50_0000022440_C.png: ✅ Annotations -> 'STONE'\n",
      "   5. cts_22_0000024090_C.png: ✅ Annotations -> 'ASPHALT'\n",
      "   6. bernmobil_127_0000006450_C.png: ✅ Annotations -> 'BALLAST'\n",
      "   7. gvb_1769_0000000900_C.png: ✅ Annotations -> 'STONE'\n",
      "   8. bernmobil_127_0000003600_C.png: ✅ Annotations -> 'BALLAST'\n",
      "   9. gvb_1818_0000011040_C.png: ✅ Annotations -> 'GRAS'\n",
      "  10. gvb_1819_0000027180_C.png: ✅ Annotations -> 'ERROR'\n",
      "\n",
      "📊 Label storage summary (first 10 entries):\n",
      "  Labels in annotations.result.value.choices: 10\n",
      "  Labels in meta.class: 0\n",
      "  No labels found: 0\n",
      "\n",
      "📋 Example entry with annotation label:\n",
      "File: bvb_1095_0000015900_C.png\n",
      "Label path: annotations[0].result[0].value.choices = ['ERROR']\n",
      "Meta class: error\n"
     ]
    }
   ],
   "source": [
    "# Debug: Examine the JSON structure\n",
    "debug_label_file = \"/media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation_labels.json\"\n",
    "\n",
    "print(\"🔍 DEBUGGING LABEL STUDIO JSON STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and examine the first few entries\n",
    "with open(debug_label_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total entries in JSON: {len(data)}\")\n",
    "\n",
    "# Check different label storage patterns\n",
    "annotations_labels = 0\n",
    "meta_labels = 0\n",
    "no_labels = 0\n",
    "\n",
    "print(\"\\nAnalyzing label storage patterns:\")\n",
    "for i, entry in enumerate(data[:10]):  # Check first 10 entries\n",
    "    filename = entry.get('file_upload', 'unknown')\n",
    "    \n",
    "    # Method 1: Check annotations.result.value.choices\n",
    "    annotation_label = None\n",
    "    for annotation in entry.get('annotations', []):\n",
    "        for result in annotation.get('result', []):\n",
    "            choices = result.get('value', {}).get('choices', [])\n",
    "            if choices:\n",
    "                annotation_label = choices[0].upper()\n",
    "                break\n",
    "        if annotation_label:\n",
    "            break\n",
    "    \n",
    "    # Method 2: Check meta.class\n",
    "    meta_label = entry.get('meta', {}).get('class', '')\n",
    "    if meta_label:\n",
    "        meta_label = meta_label.upper()\n",
    "    \n",
    "    # Count patterns\n",
    "    if annotation_label:\n",
    "        annotations_labels += 1\n",
    "        status = \"✅ Annotations\"\n",
    "        label = annotation_label\n",
    "    elif meta_label:\n",
    "        meta_labels += 1\n",
    "        status = \"🔧 Meta\"\n",
    "        label = meta_label\n",
    "    else:\n",
    "        no_labels += 1\n",
    "        status = \"❌ No label\"\n",
    "        label = \"None\"\n",
    "    \n",
    "    print(f\"  {i+1:2d}. {filename}: {status} -> '{label}'\")    \n",
    "\n",
    "print(f\"\\n📊 Label storage summary (first 10 entries):\")\n",
    "print(f\"  Labels in annotations.result.value.choices: {annotations_labels}\")\n",
    "print(f\"  Labels in meta.class: {meta_labels}\")\n",
    "print(f\"  No labels found: {no_labels}\")\n",
    "\n",
    "# Show detailed structure of first entry with annotation label\n",
    "for entry in data[:5]:\n",
    "    if entry.get('annotations', []) and entry['annotations'][0].get('result', []):\n",
    "        print(f\"\\n📋 Example entry with annotation label:\")\n",
    "        print(f\"File: {entry.get('file_upload', 'unknown')}\")\n",
    "        result = entry['annotations'][0]['result'][0]\n",
    "        print(f\"Label path: annotations[0].result[0].value.choices = {result.get('value', {}).get('choices', [])}\")\n",
    "        print(f\"Meta class: {entry.get('meta', {}).get('class', 'N/A')}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a2dc9",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "### TensorFlow Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0880383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Create a bytes feature for TensorFlow Examples\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Create an int64 feature for TensorFlow Examples\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eee661",
   "metadata": {},
   "source": [
    "### Label Loading Function (FIXED)\n",
    "\n",
    "Parse Label Studio JSON and extract trackbed surface classifications.\n",
    "**Updated to handle labels stored in both annotations.result.value.choices and meta.class field**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b1df5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trackbed_labels(label_studio_path, class_list):\n",
    "    \"\"\"\n",
    "    Load and parse Label Studio JSON file for trackbed surface classification.\n",
    "    \n",
    "    This function handles multiple label storage formats:\n",
    "    1. Labels in annotations.result.value.choices (standard Label Studio)\n",
    "    2. Labels in meta.class field (from your balanced dataset generation)\n",
    "    \n",
    "    Args:\n",
    "        label_studio_path (str): Path to Label Studio JSON export\n",
    "        class_list (list): List of valid class names\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (labels_dict, class_to_index)\n",
    "            - labels_dict: Mapping from filename to class_index\n",
    "            - class_to_index: Mapping from class_name to index\n",
    "    \"\"\"\n",
    "    with open(label_studio_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    labels = {}\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(class_list)}\n",
    "    \n",
    "    print(f\"🔍 Processing {len(data)} entries from Label Studio JSON...\")\n",
    "    \n",
    "    annotations_count = 0\n",
    "    meta_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        # Extract filename from image URI or file_upload field\n",
    "        filename = None\n",
    "        if 'file_upload' in entry:\n",
    "            filename = entry['file_upload']\n",
    "        \n",
    "        if not filename:\n",
    "            print(f\"Warning: Could not extract filename from entry {i+1}\")\n",
    "            continue\n",
    "        \n",
    "        class_label = None\n",
    "        label_source = \"none\"\n",
    "        \n",
    "        # Method 1: Try to get class from annotations.result.value.choices (standard Label Studio)\n",
    "        for annotation in entry.get('annotations', []):\n",
    "            for result in annotation.get('result', []):\n",
    "                choices = result.get('value', {}).get('choices', [])\n",
    "                if choices:\n",
    "                    # Take the first choice (should be only one for single-class)\n",
    "                    choice = choices[0].upper()  # Normalize to uppercase\n",
    "                    if choice in class_to_index:\n",
    "                        class_label = class_to_index[choice]\n",
    "                        label_source = \"annotations\"\n",
    "                        annotations_count += 1\n",
    "                        if i < 5:  # Debug first few entries\n",
    "                            print(f\"  Entry {i+1}: {filename} -> {choice} (from annotations.result.value.choices)\")\n",
    "                        break\n",
    "            if class_label is not None:\n",
    "                break\n",
    "        \n",
    "        # Method 2: Try to get class from meta field (from balanced dataset generation)\n",
    "        if class_label is None:\n",
    "            meta = entry.get('meta', {})\n",
    "            if 'class' in meta:\n",
    "                meta_class = meta['class'].upper()  # Normalize to uppercase\n",
    "                if meta_class in class_to_index:\n",
    "                    class_label = class_to_index[meta_class]\n",
    "                    label_source = \"meta\"\n",
    "                    meta_count += 1\n",
    "                    if i < 5:  # Debug first few entries\n",
    "                        print(f\"  Entry {i+1}: {filename} -> {meta_class} (from meta.class)\")\n",
    "        \n",
    "        # Store the label if found\n",
    "        if class_label is not None:\n",
    "            labels[filename] = class_label\n",
    "        else:\n",
    "            missing_count += 1\n",
    "            if i < 10:  # Show first few missing labels for debugging\n",
    "                print(f\"  Entry {i+1}: {filename} -> NO LABEL FOUND\")\n",
    "\n",
    "    print(f\"\\n📊 Label extraction summary:\")\n",
    "    print(f\"  Successfully loaded: {len(labels)} labels\")\n",
    "    print(f\"  From annotations.result.value.choices: {annotations_count}\")\n",
    "    print(f\"  From meta.class: {meta_count}\")\n",
    "    print(f\"  Missing labels: {missing_count}\")\n",
    "    print(f\"  Total entries processed: {len(data)}\")\n",
    "    \n",
    "    return labels, class_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503b645",
   "metadata": {},
   "source": [
    "### Image Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9246f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(args):\n",
    "    \"\"\"Process a single image: load, convert to RGB, and resize.\"\"\"\n",
    "    filename, input_dir, size = args\n",
    "    \n",
    "    if not filename.lower().endswith(image_extensions):\n",
    "        return None\n",
    "    \n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: Image file not found: {file_path}\")\n",
    "        return None\n",
    "        \n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not load image {filename}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert grayscale to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, size)\n",
    "    return filename, resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f3583",
   "metadata": {},
   "source": [
    "### TensorFlow Example Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7277deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_trackbed_example(filename, image, class_index, class_name):\n",
    "    \"\"\"Create a TensorFlow Example from image and class label.\"\"\"\n",
    "    features = {\n",
    "        'image_filename': _bytes_feature(filename.encode('utf-8')),\n",
    "        'image_raw': _bytes_feature(image.tobytes()),\n",
    "        'height': _int64_feature(image.shape[0]),\n",
    "        'width': _int64_feature(image.shape[1]),\n",
    "        'depth': _int64_feature(image.shape[2]),\n",
    "        'label': _int64_feature(class_index),\n",
    "        'class_name': _bytes_feature(class_name.encode('utf-8'))\n",
    "    }\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f684ec2",
   "metadata": {},
   "source": [
    "## Main Processing Loop\n",
    "\n",
    "Process each dataset and create TFRecord files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "88aac439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing dataset: evaluation\n",
      "============================================================\n",
      "📁 Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation\n",
      "🖼️  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/imgs\n",
      "🏷️  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation_labels.json\n",
      "💾 Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation.tfrecord\n",
      "\n",
      "🔍 Loading labels from evaluation_labels.json...\n",
      "🔍 Processing 1250 entries from Label Studio JSON...\n",
      "  Entry 1: bvb_1095_0000015900_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 2: gent_66_0000001620_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 3: gvb_1769_0000001020_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 4: gent_50_0000022440_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 5: cts_22_0000024090_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "\n",
      "📊 Label extraction summary:\n",
      "  Successfully loaded: 1250 labels\n",
      "  From annotations.result.value.choices: 1250\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 1250\n",
      "📊 Loaded labels for 1250 images\n",
      "\n",
      "📈 Class distribution:\n",
      "  ASPHALT: 250 images (20.0%)\n",
      "  BALLAST: 250 images (20.0%)\n",
      "  GRAS: 250 images (20.0%)\n",
      "  STONE: 250 images (20.0%)\n",
      "  ERROR: 250 images (20.0%)\n",
      "\n",
      "🖼️  Scanning images folder...\n",
      "📸 Found 1250 image files\n",
      "🏷️  Images with labels: 1250\n",
      "\n",
      "⚙️  Processing 1250 images...\n",
      "✅ Successfully processed 1250 images\n",
      "\n",
      "💾 Creating TFRecord: evaluation.tfrecord\n",
      "✅ Successfully processed 1250 images\n",
      "\n",
      "💾 Creating TFRecord: evaluation.tfrecord\n",
      "💾 Wrote 1250 records to TFRecord\n",
      "✅ Completed evaluation\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_small\n",
      "============================================================\n",
      "📁 Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small\n",
      "🖼️  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/imgs\n",
      "🏷️  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/train_small_labels.json\n",
      "💾 Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/train_small.tfrecord\n",
      "\n",
      "🔍 Loading labels from train_small_labels.json...\n",
      "🔍 Processing 1000 entries from Label Studio JSON...\n",
      "  Entry 1: vbz_3284_0000002460_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 2: retm_142_0000021390_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3349_0000001260_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 4: gent_49_0000005070_C.png -> GRAS (from annotations.result.value.choices)\n",
      "  Entry 5: gvb_1830_0000016950_C.png -> GRAS (from annotations.result.value.choices)\n",
      "\n",
      "📊 Label extraction summary:\n",
      "  Successfully loaded: 1000 labels\n",
      "  From annotations.result.value.choices: 1000\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 1000\n",
      "📊 Loaded labels for 1000 images\n",
      "\n",
      "📈 Class distribution:\n",
      "  ASPHALT: 200 images (20.0%)\n",
      "  BALLAST: 200 images (20.0%)\n",
      "  GRAS: 200 images (20.0%)\n",
      "  STONE: 200 images (20.0%)\n",
      "  ERROR: 200 images (20.0%)\n",
      "\n",
      "🖼️  Scanning images folder...\n",
      "📸 Found 1000 image files\n",
      "🏷️  Images with labels: 1000\n",
      "\n",
      "⚙️  Processing 1000 images...\n",
      "💾 Wrote 1250 records to TFRecord\n",
      "✅ Completed evaluation\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_small\n",
      "============================================================\n",
      "📁 Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small\n",
      "🖼️  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/imgs\n",
      "🏷️  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/train_small_labels.json\n",
      "💾 Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/train_small.tfrecord\n",
      "\n",
      "🔍 Loading labels from train_small_labels.json...\n",
      "🔍 Processing 1000 entries from Label Studio JSON...\n",
      "  Entry 1: vbz_3284_0000002460_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 2: retm_142_0000021390_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3349_0000001260_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 4: gent_49_0000005070_C.png -> GRAS (from annotations.result.value.choices)\n",
      "  Entry 5: gvb_1830_0000016950_C.png -> GRAS (from annotations.result.value.choices)\n",
      "\n",
      "📊 Label extraction summary:\n",
      "  Successfully loaded: 1000 labels\n",
      "  From annotations.result.value.choices: 1000\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 1000\n",
      "📊 Loaded labels for 1000 images\n",
      "\n",
      "📈 Class distribution:\n",
      "  ASPHALT: 200 images (20.0%)\n",
      "  BALLAST: 200 images (20.0%)\n",
      "  GRAS: 200 images (20.0%)\n",
      "  STONE: 200 images (20.0%)\n",
      "  ERROR: 200 images (20.0%)\n",
      "\n",
      "🖼️  Scanning images folder...\n",
      "📸 Found 1000 image files\n",
      "🏷️  Images with labels: 1000\n",
      "\n",
      "⚙️  Processing 1000 images...\n",
      "✅ Successfully processed 1000 images\n",
      "\n",
      "💾 Creating TFRecord: train_small.tfrecord\n",
      "✅ Successfully processed 1000 images\n",
      "\n",
      "💾 Creating TFRecord: train_small.tfrecord\n",
      "💾 Wrote 1000 records to TFRecord\n",
      "✅ Completed train_small\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_medium\n",
      "============================================================\n",
      "📁 Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium\n",
      "🖼️  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/imgs\n",
      "🏷️  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/train_medium_labels.json\n",
      "💾 Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/train_medium.tfrecord\n",
      "\n",
      "🔍 Loading labels from train_medium_labels.json...\n",
      "🔍 Processing 2500 entries from Label Studio JSON...\n",
      "  Entry 1: cts_16_0000022830_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 2: cts_1_0000002760_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3313_0000025500_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 4: ava_122_0000014940_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 5: ava_129_0000019890_C.png -> ERROR (from annotations.result.value.choices)\n",
      "\n",
      "📊 Label extraction summary:\n",
      "  Successfully loaded: 2500 labels\n",
      "  From annotations.result.value.choices: 2500\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 2500\n",
      "📊 Loaded labels for 2500 images\n",
      "\n",
      "📈 Class distribution:\n",
      "  ASPHALT: 500 images (20.0%)\n",
      "  BALLAST: 500 images (20.0%)\n",
      "  GRAS: 500 images (20.0%)\n",
      "  STONE: 500 images (20.0%)\n",
      "  ERROR: 500 images (20.0%)\n",
      "\n",
      "🖼️  Scanning images folder...\n",
      "📸 Found 2500 image files\n",
      "🏷️  Images with labels: 2500\n",
      "\n",
      "⚙️  Processing 2500 images...\n",
      "💾 Wrote 1000 records to TFRecord\n",
      "✅ Completed train_small\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_medium\n",
      "============================================================\n",
      "📁 Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium\n",
      "🖼️  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/imgs\n",
      "🏷️  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/train_medium_labels.json\n",
      "💾 Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/train_medium.tfrecord\n",
      "\n",
      "🔍 Loading labels from train_medium_labels.json...\n",
      "🔍 Processing 2500 entries from Label Studio JSON...\n",
      "  Entry 1: cts_16_0000022830_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 2: cts_1_0000002760_C.png -> STONE (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3313_0000025500_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "  Entry 4: ava_122_0000014940_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 5: ava_129_0000019890_C.png -> ERROR (from annotations.result.value.choices)\n",
      "\n",
      "📊 Label extraction summary:\n",
      "  Successfully loaded: 2500 labels\n",
      "  From annotations.result.value.choices: 2500\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 2500\n",
      "📊 Loaded labels for 2500 images\n",
      "\n",
      "📈 Class distribution:\n",
      "  ASPHALT: 500 images (20.0%)\n",
      "  BALLAST: 500 images (20.0%)\n",
      "  GRAS: 500 images (20.0%)\n",
      "  STONE: 500 images (20.0%)\n",
      "  ERROR: 500 images (20.0%)\n",
      "\n",
      "🖼️  Scanning images folder...\n",
      "📸 Found 2500 image files\n",
      "🏷️  Images with labels: 2500\n",
      "\n",
      "⚙️  Processing 2500 images...\n",
      "✅ Successfully processed 2500 images\n",
      "\n",
      "💾 Creating TFRecord: train_medium.tfrecord\n",
      "✅ Successfully processed 2500 images\n",
      "\n",
      "💾 Creating TFRecord: train_medium.tfrecord\n",
      "💾 Wrote 2500 records to TFRecord\n",
      "✅ Completed train_medium\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_large\n",
      "============================================================\n",
      "📁 Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large\n",
      "🖼️  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/imgs\n",
      "🏷️  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/train_large_labels.json\n",
      "💾 Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/train_large.tfrecord\n",
      "\n",
      "🔍 Loading labels from train_large_labels.json...\n",
      "🔍 Processing 5040 entries from Label Studio JSON...\n",
      "  Entry 1: retm_140_0000012090_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 2: ava_110_0000001230_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3532_0000009060_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 4: bvb_1117_0000008910_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 5: gent_54_0000000540_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "\n",
      "📊 Label extraction summary:\n",
      "  Successfully loaded: 5040 labels\n",
      "  From annotations.result.value.choices: 5040\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 5040\n",
      "📊 Loaded labels for 5040 images\n",
      "\n",
      "📈 Class distribution:\n",
      "  ASPHALT: 1008 images (20.0%)\n",
      "  BALLAST: 1008 images (20.0%)\n",
      "  GRAS: 1008 images (20.0%)\n",
      "  STONE: 1008 images (20.0%)\n",
      "  ERROR: 1008 images (20.0%)\n",
      "\n",
      "🖼️  Scanning images folder...\n",
      "📸 Found 5040 image files\n",
      "🏷️  Images with labels: 5040\n",
      "\n",
      "⚙️  Processing 5040 images...\n",
      "💾 Wrote 2500 records to TFRecord\n",
      "✅ Completed train_medium\n",
      "\n",
      "============================================================\n",
      "Processing dataset: train_large\n",
      "============================================================\n",
      "📁 Dataset folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large\n",
      "🖼️  Images folder: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/imgs\n",
      "🏷️  Label file: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/train_large_labels.json\n",
      "💾 Output TFRecord: /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/train_large.tfrecord\n",
      "\n",
      "🔍 Loading labels from train_large_labels.json...\n",
      "🔍 Processing 5040 entries from Label Studio JSON...\n",
      "  Entry 1: retm_140_0000012090_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 2: ava_110_0000001230_C.png -> BALLAST (from annotations.result.value.choices)\n",
      "  Entry 3: vbz_3532_0000009060_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 4: bvb_1117_0000008910_C.png -> ERROR (from annotations.result.value.choices)\n",
      "  Entry 5: gent_54_0000000540_C.png -> ASPHALT (from annotations.result.value.choices)\n",
      "\n",
      "📊 Label extraction summary:\n",
      "  Successfully loaded: 5040 labels\n",
      "  From annotations.result.value.choices: 5040\n",
      "  From meta.class: 0\n",
      "  Missing labels: 0\n",
      "  Total entries processed: 5040\n",
      "📊 Loaded labels for 5040 images\n",
      "\n",
      "📈 Class distribution:\n",
      "  ASPHALT: 1008 images (20.0%)\n",
      "  BALLAST: 1008 images (20.0%)\n",
      "  GRAS: 1008 images (20.0%)\n",
      "  STONE: 1008 images (20.0%)\n",
      "  ERROR: 1008 images (20.0%)\n",
      "\n",
      "🖼️  Scanning images folder...\n",
      "📸 Found 5040 image files\n",
      "🏷️  Images with labels: 5040\n",
      "\n",
      "⚙️  Processing 5040 images...\n",
      "✅ Successfully processed 5040 images\n",
      "\n",
      "💾 Creating TFRecord: train_large.tfrecord\n",
      "✅ Successfully processed 5040 images\n",
      "\n",
      "💾 Creating TFRecord: train_large.tfrecord\n",
      "💾 Wrote 5040 records to TFRecord\n",
      "✅ Completed train_large\n",
      "💾 Wrote 5040 records to TFRecord\n",
      "✅ Completed train_large\n"
     ]
    }
   ],
   "source": [
    "# Track overall statistics\n",
    "overall_stats = {\n",
    "    'datasets_processed': 0,\n",
    "    'total_images': 0,\n",
    "    'tfrecord_files_created': []\n",
    "}\n",
    "\n",
    "for dataset_name in datasets_to_process:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing dataset: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Define paths\n",
    "    dataset_folder = os.path.join(base_dataset_dir, dataset_name)\n",
    "    images_folder = os.path.join(dataset_folder, 'imgs')\n",
    "    label_file = os.path.join(dataset_folder, f\"{dataset_name}_labels.json\")\n",
    "    output_tfrecord = os.path.join(dataset_folder, f\"{dataset_name}.tfrecord\")\n",
    "    \n",
    "    # Check if dataset folder exists\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        print(f\"❌ Dataset folder not found: {dataset_folder}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if images folder exists\n",
    "    if not os.path.exists(images_folder):\n",
    "        print(f\"❌ Images folder not found: {images_folder}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if label file exists\n",
    "    if not os.path.exists(label_file):\n",
    "        print(f\"❌ Label file not found: {label_file}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"📁 Dataset folder: {dataset_folder}\")\n",
    "    print(f\"🖼️  Images folder: {images_folder}\")\n",
    "    print(f\"🏷️  Label file: {label_file}\")\n",
    "    print(f\"💾 Output TFRecord: {output_tfrecord}\")\n",
    "    \n",
    "    # Step 1: Load labels\n",
    "    print(f\"\\n🔍 Loading labels from {os.path.basename(label_file)}...\")\n",
    "    labels_dict, class_to_index = load_trackbed_labels(label_file, trackbed_classes)\n",
    "    print(f\"📊 Loaded labels for {len(labels_dict)} images\")\n",
    "    \n",
    "    # Analyze label distribution\n",
    "    label_distribution = Counter(labels_dict.values())\n",
    "    print(f\"\\n📈 Class distribution:\")\n",
    "    for class_name, class_idx in class_to_index.items():\n",
    "        count = label_distribution.get(class_idx, 0)\n",
    "        percentage = (count / len(labels_dict) * 100) if labels_dict else 0\n",
    "        print(f\"  {class_name}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Step 2: Get all image files\n",
    "    print(f\"\\n🖼️  Scanning images folder...\")\n",
    "    all_image_files = [f for f in os.listdir(images_folder) \n",
    "                      if f.lower().endswith(image_extensions)]\n",
    "    print(f\"📸 Found {len(all_image_files)} image files\")\n",
    "    \n",
    "    # Filter images that have labels\n",
    "    labeled_images = [img for img in all_image_files if img in labels_dict]\n",
    "    print(f\"🏷️  Images with labels: {len(labeled_images)}\")\n",
    "    \n",
    "    if len(labeled_images) == 0:\n",
    "        print(f\"❌ No labeled images found for {dataset_name}\")\n",
    "        print(f\"First 5 image files: {all_image_files[:5]}\")\n",
    "        print(f\"First 5 label keys: {list(labels_dict.keys())[:5]}\")\n",
    "        continue\n",
    "    \n",
    "    # Step 3: Process images in parallel\n",
    "    print(f\"\\n⚙️  Processing {len(labeled_images)} images...\")\n",
    "    tasks = [(filename, images_folder, target_image_size) for filename in labeled_images]\n",
    "    processed_images = []\n",
    "    \n",
    "    with Pool(num_workers) as pool:\n",
    "        for result in pool.imap_unordered(process_image, tasks):\n",
    "            if result is not None:\n",
    "                processed_images.append(result)\n",
    "    \n",
    "    print(f\"✅ Successfully processed {len(processed_images)} images\")\n",
    "    \n",
    "    # Step 4: Create TFRecord\n",
    "    print(f\"\\n💾 Creating TFRecord: {os.path.basename(output_tfrecord)}\")\n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_tfrecord) as writer:\n",
    "        for filename, image in processed_images:\n",
    "            class_index = labels_dict[filename]\n",
    "            class_name = trackbed_classes[class_index]\n",
    "            example = serialize_trackbed_example(filename, image, class_index, class_name)\n",
    "            writer.write(example)\n",
    "    \n",
    "    print(f\"💾 Wrote {len(processed_images)} records to TFRecord\")\n",
    "    \n",
    "    # Update overall statistics\n",
    "    overall_stats['datasets_processed'] += 1\n",
    "    overall_stats['total_images'] += len(processed_images)\n",
    "    overall_stats['tfrecord_files_created'].append(output_tfrecord)\n",
    "    \n",
    "    print(f\"✅ Completed {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91963f5d",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "Validate the created TFRecord files by reading and parsing a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "079ad5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🔍 VALIDATION\n",
      "============================================================\n",
      "\n",
      "📁 Validating evaluation...\n",
      "📊 First 3 records:\n",
      "  ava_110_0000003840_C.png: class=BALLAST (label=1), size=224x224\n",
      "  bvb_1170_0000005100_C.png: class=ASPHALT (label=0), size=224x224\n",
      "  gent_50_0000010530_C.png: class=GRAS (label=2), size=224x224\n",
      "📊 First 3 records:\n",
      "  ava_110_0000003840_C.png: class=BALLAST (label=1), size=224x224\n",
      "  bvb_1170_0000005100_C.png: class=ASPHALT (label=0), size=224x224\n",
      "  gent_50_0000010530_C.png: class=GRAS (label=2), size=224x224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1756506394.643073  867236 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2025-08-30 00:26:34.692655: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:381] TFRecordDataset `buffer_size` is unspecified, default to 262144\n",
      "2025-08-30 00:26:34.699804: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-08-30 00:26:35.478721: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2025-08-30 00:26:35.478721: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Total records: 1250\n",
      "📊 Class distribution: {'BALLAST': 250, 'ASPHALT': 250, 'GRAS': 250, 'STONE': 250, 'ERROR': 250}\n",
      "✅ Validation successful\n",
      "\n",
      "📁 Validating train_small...\n",
      "📊 First 3 records:\n",
      "  gvb_1830_0000015300_C.png: class=GRAS (label=2), size=224x224\n",
      "  gvb_1814_0000024360_C.png: class=STONE (label=3), size=224x224\n",
      "  retm_120_0000031080_C.png: class=ASPHALT (label=0), size=224x224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 00:26:36.177565: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📈 Total records: 1000\n",
      "📊 Class distribution: {'GRAS': 200, 'STONE': 200, 'ASPHALT': 200, 'ERROR': 200, 'BALLAST': 200}\n",
      "✅ Validation successful\n",
      "\n",
      "📁 Validating train_medium...\n",
      "📊 First 3 records:\n",
      "  ava_104_0000017490_C.png: class=ERROR (label=4), size=224x224\n",
      "  bvb_1168_0000003750_C.png: class=ERROR (label=4), size=224x224\n",
      "  gvb_1814_0000024360_C.png: class=STONE (label=3), size=224x224\n",
      "📈 Total records: 2500\n",
      "📊 Class distribution: {'ERROR': 500, 'STONE': 500, 'BALLAST': 500, 'GRAS': 500, 'ASPHALT': 500}\n",
      "✅ Validation successful\n",
      "\n",
      "📁 Validating train_large...\n",
      "📊 First 3 records:\n",
      "  cts_28_0000010710_C.png: class=GRAS (label=2), size=224x224\n",
      "  retm_116_0000013650_C.png: class=BALLAST (label=1), size=224x224\n",
      "  cts_9_0000000540_C.png: class=STONE (label=3), size=224x224\n",
      "📈 Total records: 2500\n",
      "📊 Class distribution: {'ERROR': 500, 'STONE': 500, 'BALLAST': 500, 'GRAS': 500, 'ASPHALT': 500}\n",
      "✅ Validation successful\n",
      "\n",
      "📁 Validating train_large...\n",
      "📊 First 3 records:\n",
      "  cts_28_0000010710_C.png: class=GRAS (label=2), size=224x224\n",
      "  retm_116_0000013650_C.png: class=BALLAST (label=1), size=224x224\n",
      "  cts_9_0000000540_C.png: class=STONE (label=3), size=224x224\n",
      "📈 Total records: 5040\n",
      "📊 Class distribution: {'GRAS': 1008, 'BALLAST': 1008, 'STONE': 1008, 'ASPHALT': 1008, 'ERROR': 1008}\n",
      "✅ Validation successful\n",
      "📈 Total records: 5040\n",
      "📊 Class distribution: {'GRAS': 1008, 'BALLAST': 1008, 'STONE': 1008, 'ASPHALT': 1008, 'ERROR': 1008}\n",
      "✅ Validation successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-30 00:26:41.350137: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🔍 VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Feature description for parsing\n",
    "feature_description = {\n",
    "    'image_filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'class_name': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "for tfrecord_path in overall_stats['tfrecord_files_created']:\n",
    "    dataset_name = os.path.basename(tfrecord_path).replace('.tfrecord', '')\n",
    "    print(f\"\\n📁 Validating {dataset_name}...\")\n",
    "    \n",
    "    if not os.path.exists(tfrecord_path):\n",
    "        print(f\"❌ TFRecord file not found: {tfrecord_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "        record_count = 0\n",
    "        class_distribution = Counter()\n",
    "        \n",
    "        print(\"📊 First 3 records:\")\n",
    "        for i, raw_record in enumerate(dataset.take(3)):\n",
    "            example = tf.io.parse_single_example(raw_record, feature_description)\n",
    "            filename = example['image_filename'].numpy().decode('utf-8')\n",
    "            label = example['label'].numpy()\n",
    "            class_name = example['class_name'].numpy().decode('utf-8')\n",
    "            height = example['height'].numpy()\n",
    "            width = example['width'].numpy()\n",
    "            print(f\"  {filename}: class={class_name} (label={label}), size={width}x{height}\")\n",
    "        \n",
    "        # Count total records and class distribution\n",
    "        for raw_record in dataset:\n",
    "            example = tf.io.parse_single_example(raw_record, feature_description)\n",
    "            class_name = example['class_name'].numpy().decode('utf-8')\n",
    "            class_distribution[class_name] += 1\n",
    "            record_count += 1\n",
    "        \n",
    "        print(f\"📈 Total records: {record_count}\")\n",
    "        print(f\"📊 Class distribution: {dict(class_distribution)}\")\n",
    "        print(f\"✅ Validation successful\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5361abd",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9d2252a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "📋 SUMMARY REPORT\n",
      "============================================================\n",
      "📁 Base directory: /media/andi/ssd2/dev/datasets/multilabel_tb_ds\n",
      "🎯 Target image size: (224, 224)\n",
      "🏷️  Classes: ['ASPHALT', 'BALLAST', 'GRAS', 'STONE', 'ERROR']\n",
      "📊 Datasets processed: 4\n",
      "🖼️  Total images processed: 9790\n",
      "\n",
      "💾 TFRecord files created:\n",
      "  📄 /media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation.tfrecord (179.7 MB)\n",
      "  📄 /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_small/train_small.tfrecord (143.7 MB)\n",
      "  📄 /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_medium/train_medium.tfrecord (359.3 MB)\n",
      "  📄 /media/andi/ssd2/dev/datasets/multilabel_tb_ds/train_large/train_large.tfrecord (724.4 MB)\n",
      "\n",
      "🎉 TFRecord creation complete!\n",
      "📝 All files are ready for TensorFlow training.\n",
      "\n",
      "📖 Usage Example:\n",
      "```python\n",
      "import tensorflow as tf\n",
      "\n",
      "# Load dataset\n",
      "dataset = tf.data.TFRecordDataset('/media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation.tfrecord')\n",
      "\n",
      "# Parse function\n",
      "def parse_example(example):\n",
      "    features = {\n",
      "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
      "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
      "    }\n",
      "    parsed = tf.io.parse_single_example(example, features)\n",
      "    image = tf.io.decode_raw(parsed['image_raw'], tf.uint8)\n",
      "    image = tf.reshape(image, [224, 224, 3])\n",
      "    image = tf.cast(image, tf.float32) / 255.0\n",
      "    return image, parsed['label']\n",
      "\n",
      "# Apply parsing and batching\n",
      "dataset = dataset.map(parse_example).batch(32)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"📋 SUMMARY REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"📁 Base directory: {base_dataset_dir}\")\n",
    "print(f\"🎯 Target image size: {target_image_size}\")\n",
    "print(f\"🏷️  Classes: {trackbed_classes}\")\n",
    "print(f\"📊 Datasets processed: {overall_stats['datasets_processed']}\")\n",
    "print(f\"🖼️  Total images processed: {overall_stats['total_images']}\")\n",
    "\n",
    "print(f\"\\n💾 TFRecord files created:\")\n",
    "for tfrecord_path in overall_stats['tfrecord_files_created']:\n",
    "    file_size = os.path.getsize(tfrecord_path) / (1024 * 1024)  # MB\n",
    "    print(f\"  📄 {tfrecord_path} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\n🎉 TFRecord creation complete!\")\n",
    "print(f\"📝 All files are ready for TensorFlow training.\")\n",
    "\n",
    "# Create a simple usage example\n",
    "print(f\"\\n📖 Usage Example:\")\n",
    "print(f\"```python\")\n",
    "print(f\"import tensorflow as tf\")\n",
    "print(f\"\")\n",
    "print(f\"# Load dataset\")\n",
    "if overall_stats['tfrecord_files_created']:\n",
    "    example_path = overall_stats['tfrecord_files_created'][0]\n",
    "    print(f\"dataset = tf.data.TFRecordDataset('{example_path}')\")\n",
    "print(f\"\")\n",
    "print(f\"# Parse function\")\n",
    "print(f\"def parse_example(example):\")\n",
    "print(f\"    features = {{\")\n",
    "print(f\"        'image_raw': tf.io.FixedLenFeature([], tf.string),\")\n",
    "print(f\"        'label': tf.io.FixedLenFeature([], tf.int64),\")\n",
    "print(f\"    }}\")\n",
    "print(f\"    parsed = tf.io.parse_single_example(example, features)\")\n",
    "print(f\"    image = tf.io.decode_raw(parsed['image_raw'], tf.uint8)\")\n",
    "print(f\"    image = tf.reshape(image, [{target_image_size[1]}, {target_image_size[0]}, 3])\")\n",
    "print(f\"    image = tf.cast(image, tf.float32) / 255.0\")\n",
    "print(f\"    return image, parsed['label']\")\n",
    "print(f\"\")\n",
    "print(f\"# Apply parsing and batching\")\n",
    "print(f\"dataset = dataset.map(parse_example).batch(32)\")\n",
    "print(f\"```\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
