{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e21991c2",
   "metadata": {},
   "source": [
    "## Einleitung: Trackbed Classification → TFRecord\n",
    "\n",
    "**Was:**  \n",
    "- Konvertiert Gleisbett-Klassifikationsdatensätze in **TFRecord**-Dateien für effizientes Training.  \n",
    "- Erwartet: Datensatzordner mit **Bildern** (`imgs/`) und zugehörigem **Label-Studio-JSON**.  \n",
    "- Klassen (5): **ASPHALT, BALLAST, GRAS, STONE, ERROR**.  \n",
    "- Ablauf: **Labels laden** → **Bilder lesen/resize/RGB** → **TensorFlow Examples serialisieren** → **TFRecord schreiben**.\n",
    "\n",
    "**Warum:**  \n",
    "- **TFRecord** + `tf.data` ermöglicht schnelles sequenzielles Laden, Shuffling, Caching und Vorverarbeitung in Trainingspipelines.  \n",
    "- Einheitliches, binäres Format reduziert IO-Overhead und erleichtert **reproduzierbare**, skalierbare Trainingsläufe über mehrere Datensätze/Größen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bd160f",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "**Was:**  \n",
    "- Import grundlegender Module für Datei-IO (`os`, `pathlib.Path`), Serialisierung (`json`), Bildverarbeitung (`cv2`) und Deep Learning (`tensorflow`).  \n",
    "- Bereitstellung von Utilities für Parallelisierung (`multiprocessing.Pool`, `cpu_count`) und einfache Zählstatistiken (`collections.Counter`).  \n",
    "- Ausgabe von Umgebungsinformationen (TensorFlow-Version, verfügbare CPU-Kerne).\n",
    "\n",
    "**Warum:**  \n",
    "- Zentrale Verfügbarkeit aller benötigten Funktionen für robuste Daten- und Modellpipelines.  \n",
    "- Transparenz über die Laufzeitumgebung und Abschätzung der verfügbaren Rechenressourcen.  \n",
    "- Effiziente Verarbeitung durch parallele Workloads sowie einfache Aggregationen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Available CPU cores: {cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d324f",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "\n",
    "**Was:**  \n",
    "- Setzt Basis-Pfade für die Datensätze sowie die zu verarbeitenden Teilmengen (`evaluation`, `train_small`, `train_medium`, `train_large`).  \n",
    "- Definiert die Klasseliste (`trackbed_classes`) passend zur Label-Studio-Konfiguration.  \n",
    "- Legt Bild-Parameter fest (Zielauflösung) und Parallelisierungsgrad (`num_workers`).  \n",
    "- Bestimmt zulässige Bild-Endungen zur Filterung der Eingabedateien.  \n",
    "- Gibt die wichtigsten Einstellungen zur Kontrolle in der Konsole aus.\n",
    "\n",
    "**Warum:**  \n",
    "- Zentrale Konfiguration ermöglicht reproduzierbare und leicht anpassbare Pipelines (Pfade, Umfang, Klassen).  \n",
    "- Konsistente Klassenbezeichnungen gewährleisten korrekte Zuordnung/Validierung gegenüber den Labels.  \n",
    "- Vorab definierte Bildgröße und Parallelisierung verbessern Laufzeit und Speicherplanung.  \n",
    "- Dateiendungsfilter verhindern Fehler durch ungeeignete oder unerwartete Eingabedateien.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base dataset directory (contains evaluation, train_small, train_medium, train_large folders)\n",
    "base_dataset_dir = \"/media/andi/ssd2/dev/datasets/multilabel_tb_ds\"\n",
    "\n",
    "# Datasets to process\n",
    "datasets_to_process = [\n",
    "    \"evaluation\",\n",
    "    \"train_small\",\n",
    "    \"train_medium\",\n",
    "    \"train_large\"\n",
    "]\n",
    "\n",
    "# Trackbed surface classes (should match your Label Studio configuration)\n",
    "trackbed_classes = [\n",
    "    \"ASPHALT\",\n",
    "    \"BALLAST\",\n",
    "    \"GRAS\",\n",
    "    \"STONE\", \n",
    "    \"ERROR\"\n",
    "]\n",
    "\n",
    "# Image processing parameters\n",
    "target_image_size = (224, 224)  # (width, height)\n",
    "num_workers = cpu_count()  # Use all available CPU cores\n",
    "\n",
    "# Image extensions to consider\n",
    "image_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff')\n",
    "\n",
    "print(f\"Base directory: {base_dataset_dir}\")\n",
    "print(f\"Datasets to process: {datasets_to_process}\")\n",
    "print(f\"Classes: {trackbed_classes}\")\n",
    "print(f\"Target image size: {target_image_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f0b4ce",
   "metadata": {},
   "source": [
    "## 3. Debug: Label Studio JSON Structure\n",
    "\n",
    "**Was:**  \n",
    "- Lädt die Label-Studio-JSON und inspiziert exemplarisch die ersten Einträge.  \n",
    "- Prüft, ob Labels in `annotations[*].result[*].value.choices` oder in `meta.class` abgelegt sind, und zählt die Vorkommensmuster.  \n",
    "- Gibt eine kurze Strukturbeispiel-Ansicht für einen Eintrag mit Annotation-Label aus, um den exakten Zugriffspfad zu verifizieren.\n",
    "\n",
    "**Warum:**  \n",
    "- Label-Studio-Exporte können Labels an unterschiedlichen Stellen speichern; die robuste Parser-Logik hängt vom tatsächlichen Schema ab.  \n",
    "- Die Vorab-Analyse verhindert Fehlzuordnungen und stellt sicher, dass nachfolgende Schritte (Parsing, Auswertung) auf die richtige Quelle zugreifen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1634559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Examine the JSON structure\n",
    "debug_label_file = \"/media/andi/ssd2/dev/datasets/multilabel_tb_ds/evaluation/evaluation_labels.json\"\n",
    "\n",
    "print(\"🔍 DEBUGGING LABEL STUDIO JSON STRUCTURE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load and examine the first few entries\n",
    "with open(debug_label_file, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total entries in JSON: {len(data)}\")\n",
    "\n",
    "# Check different label storage patterns\n",
    "annotations_labels = 0\n",
    "meta_labels = 0\n",
    "no_labels = 0\n",
    "\n",
    "print(\"\\nAnalyzing label storage patterns:\")\n",
    "for i, entry in enumerate(data[:10]):  # Check first 10 entries\n",
    "    filename = entry.get('file_upload', 'unknown')\n",
    "    \n",
    "    # Method 1: Check annotations.result.value.choices\n",
    "    annotation_label = None\n",
    "    for annotation in entry.get('annotations', []):\n",
    "        for result in annotation.get('result', []):\n",
    "            choices = result.get('value', {}).get('choices', [])\n",
    "            if choices:\n",
    "                annotation_label = choices[0].upper()\n",
    "                break\n",
    "        if annotation_label:\n",
    "            break\n",
    "    \n",
    "    # Method 2: Check meta.class\n",
    "    meta_label = entry.get('meta', {}).get('class', '')\n",
    "    if meta_label:\n",
    "        meta_label = meta_label.upper()\n",
    "    \n",
    "    # Count patterns\n",
    "    if annotation_label:\n",
    "        annotations_labels += 1\n",
    "        status = \"✅ Annotations\"\n",
    "        label = annotation_label\n",
    "    elif meta_label:\n",
    "        meta_labels += 1\n",
    "        status = \"🔧 Meta\"\n",
    "        label = meta_label\n",
    "    else:\n",
    "        no_labels += 1\n",
    "        status = \"❌ No label\"\n",
    "        label = \"None\"\n",
    "    \n",
    "    print(f\"  {i+1:2d}. {filename}: {status} -> '{label}'\")    \n",
    "\n",
    "print(f\"\\n📊 Label storage summary (first 10 entries):\")\n",
    "print(f\"  Labels in annotations.result.value.choices: {annotations_labels}\")\n",
    "print(f\"  Labels in meta.class: {meta_labels}\")\n",
    "print(f\"  No labels found: {no_labels}\")\n",
    "\n",
    "# Show detailed structure of first entry with annotation label\n",
    "for entry in data[:5]:\n",
    "    if entry.get('annotations', []) and entry['annotations'][0].get('result', []):\n",
    "        print(f\"\\n📋 Example entry with annotation label:\")\n",
    "        print(f\"File: {entry.get('file_upload', 'unknown')}\")\n",
    "        result = entry['annotations'][0]['result'][0]\n",
    "        print(f\"Label path: annotations[0].result[0].value.choices = {result.get('value', {}).get('choices', [])}\")\n",
    "        print(f\"Meta class: {entry.get('meta', {}).get('class', 'N/A')}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808a2dc9",
   "metadata": {},
   "source": [
    "## 4. Helper Functions: TensorFlow Feature Creation\n",
    "\n",
    "**Was:**  \n",
    "- Definiert Hilfsfunktionen zur Erstellung von **`tf.train.Feature`**-Feldern:  \n",
    "  - `_bytes_feature` für Byte-/String-Daten  \n",
    "  - `_int64_feature` für Ganzzahlen  \n",
    "- Diese Bausteine werden beim Serialisieren von Beispielen zu **`tf.train.Example`**/**TFRecord** verwendet.\n",
    "\n",
    "**Warum:**  \n",
    "- Vereinfachen das Erstellen konsistenter **TFRecord**-Schemas und reduzieren Boilerplate-Code.  \n",
    "- Stellen sicher, dass Datentypen korrekt verpackt werden und spätere Deserialisierung/Parsing in TensorFlow zuverlässig funktioniert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0880383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Create a bytes feature for TensorFlow Examples\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Create an int64 feature for TensorFlow Examples\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eee661",
   "metadata": {},
   "source": [
    "## 5. Laden der Labels\n",
    "\n",
    "**Was:**  \n",
    "- Lädt den Label-Studio-Export und extrahiert Gleisbett-Klassen aus zwei möglichen Quellen:  \n",
    "  1) `annotations[*].result[*].value.choices`  \n",
    "  2) `meta.class`  \n",
    "- Gibt ein Mapping **Dateiname → Klassenindex** sowie **Klassenname → Index** zurück.\n",
    "\n",
    "**Warum:**  \n",
    "- Label-Studio kann Labels je nach Export/Workflow an unterschiedlichen Stellen speichern; die Funktion unterstützt beide Formate robust.  \n",
    "- Ein konsistentes Klassenindex-Mapping ist Grundlage für nachgelagerte Schritte (Statistiken, Datensatzaufbereitung, Training).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1df5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trackbed_labels(label_studio_path, class_list):\n",
    "    \"\"\"\n",
    "    Load and parse Label Studio JSON file for trackbed surface classification.\n",
    "    \n",
    "    This function handles multiple label storage formats:\n",
    "    1. Labels in annotations.result.value.choices (standard Label Studio)\n",
    "    2. Labels in meta.class field (from your balanced dataset generation)\n",
    "    \n",
    "    Args:\n",
    "        label_studio_path (str): Path to Label Studio JSON export\n",
    "        class_list (list): List of valid class names\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (labels_dict, class_to_index)\n",
    "            - labels_dict: Mapping from filename to class_index\n",
    "            - class_to_index: Mapping from class_name to index\n",
    "    \"\"\"\n",
    "    with open(label_studio_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    labels = {}\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(class_list)}\n",
    "    \n",
    "    print(f\"🔍 Processing {len(data)} entries from Label Studio JSON...\")\n",
    "    \n",
    "    annotations_count = 0\n",
    "    meta_count = 0\n",
    "    missing_count = 0\n",
    "    \n",
    "    for i, entry in enumerate(data):\n",
    "        # Extract filename from image URI or file_upload field\n",
    "        filename = None\n",
    "        if 'file_upload' in entry:\n",
    "            filename = entry['file_upload']\n",
    "        \n",
    "        if not filename:\n",
    "            print(f\"Warning: Could not extract filename from entry {i+1}\")\n",
    "            continue\n",
    "        \n",
    "        class_label = None\n",
    "        label_source = \"none\"\n",
    "        \n",
    "        # Method 1: Try to get class from annotations.result.value.choices (standard Label Studio)\n",
    "        for annotation in entry.get('annotations', []):\n",
    "            for result in annotation.get('result', []):\n",
    "                choices = result.get('value', {}).get('choices', [])\n",
    "                if choices:\n",
    "                    # Take the first choice (should be only one for single-class)\n",
    "                    choice = choices[0].upper()  # Normalize to uppercase\n",
    "                    if choice in class_to_index:\n",
    "                        class_label = class_to_index[choice]\n",
    "                        label_source = \"annotations\"\n",
    "                        annotations_count += 1\n",
    "                        if i < 5:  # Debug first few entries\n",
    "                            print(f\"  Entry {i+1}: {filename} -> {choice} (from annotations.result.value.choices)\")\n",
    "                        break\n",
    "            if class_label is not None:\n",
    "                break\n",
    "        \n",
    "        # Method 2: Try to get class from meta field (from balanced dataset generation)\n",
    "        if class_label is None:\n",
    "            meta = entry.get('meta', {})\n",
    "            if 'class' in meta:\n",
    "                meta_class = meta['class'].upper()  # Normalize to uppercase\n",
    "                if meta_class in class_to_index:\n",
    "                    class_label = class_to_index[meta_class]\n",
    "                    label_source = \"meta\"\n",
    "                    meta_count += 1\n",
    "                    if i < 5:  # Debug first few entries\n",
    "                        print(f\"  Entry {i+1}: {filename} -> {meta_class} (from meta.class)\")\n",
    "        \n",
    "        # Store the label if found\n",
    "        if class_label is not None:\n",
    "            labels[filename] = class_label\n",
    "        else:\n",
    "            missing_count += 1\n",
    "            if i < 10:  # Show first few missing labels for debugging\n",
    "                print(f\"  Entry {i+1}: {filename} -> NO LABEL FOUND\")\n",
    "\n",
    "    print(f\"\\n📊 Label extraction summary:\")\n",
    "    print(f\"  Successfully loaded: {len(labels)} labels\")\n",
    "    print(f\"  From annotations.result.value.choices: {annotations_count}\")\n",
    "    print(f\"  From meta.class: {meta_count}\")\n",
    "    print(f\"  Missing labels: {missing_count}\")\n",
    "    print(f\"  Total entries processed: {len(data)}\")\n",
    "    \n",
    "    return labels, class_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503b645",
   "metadata": {},
   "source": [
    "## 6. Bildverarbeitungsfunktion\n",
    "\n",
    "**Was:**  \n",
    "- Lädt eine einzelne Bilddatei, validiert Dateiendung und Existenz, liest das Bild als **Graustufen**, konvertiert nach **RGB** und skaliert auf die Zielgröße.  \n",
    "- Gibt bei Erfolg `(filename, resized_img)` zurück, andernfalls `None` (geeignet für parallele Verarbeitung mit `Pool.map`).\n",
    "\n",
    "**Warum:**  \n",
    "- Einheitliche **Eingabeformate** (3 Kanäle, feste Auflösung) sind Voraussetzung. \n",
    "- Frühe Validierungen verhindern Laufzeitfehler durch fehlende/inkompatible Dateien und beschleunigen robuste Batch-Pipelines.  \n",
    "- Die RGB-Konvertierung stellt Kompatibilität zu Modellen sicher, die **3-Kanal-Eingaben** erwarten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9246f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(args):\n",
    "    \"\"\"Process a single image: load, convert to RGB, and resize.\"\"\"\n",
    "    filename, input_dir, size = args\n",
    "    \n",
    "    if not filename.lower().endswith(image_extensions):\n",
    "        return None\n",
    "    \n",
    "    file_path = os.path.join(input_dir, filename)\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: Image file not found: {file_path}\")\n",
    "        return None\n",
    "        \n",
    "    img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(f\"Warning: Could not load image {filename}\")\n",
    "        return None\n",
    "    \n",
    "    # Convert grayscale to RGB\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "    # Resize image\n",
    "    resized_img = cv2.resize(img, size)\n",
    "    return filename, resized_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f3583",
   "metadata": {},
   "source": [
    "## 7. TensorFlow Example-Serialisierung\n",
    "\n",
    "**Was:**  \n",
    "- Serialisiert ein einzelnes Beispiel (Bild + Label) zu einem **`tf.train.Example`**.  \n",
    "- Verpackt Dateiname, Rohbilddaten (`image_raw`), Dimensionen (`height`, `width`, `depth`) sowie Label-Informationen (`label`, `class_name`) als **Features**.\n",
    "\n",
    "**Warum:**  \n",
    "- Einheitliches, modellunabhängiges **TFRecord**-Format ermöglicht effizientes Laden, Caching und Shuffling in TensorFlow-Pipelines.  \n",
    "- Korrekte Typisierung der Felder (Bytes/Int64) stellt zuverlässiges Parsen im Trainings-/Inference-Input-Graphen sicher.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7277deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_trackbed_example(filename, image, class_index, class_name):\n",
    "    \"\"\"Create a TensorFlow Example from image and class label.\"\"\"\n",
    "    features = {\n",
    "        'image_filename': _bytes_feature(filename.encode('utf-8')),\n",
    "        'image_raw': _bytes_feature(image.tobytes()),\n",
    "        'height': _int64_feature(image.shape[0]),\n",
    "        'width': _int64_feature(image.shape[1]),\n",
    "        'depth': _int64_feature(image.shape[2]),\n",
    "        'label': _int64_feature(class_index),\n",
    "        'class_name': _bytes_feature(class_name.encode('utf-8'))\n",
    "    }\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return example.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f684ec2",
   "metadata": {},
   "source": [
    "## 8. Hauptverarbeitungsschleife\n",
    "\n",
    "**Was:**  \n",
    "- Iteriert über die ausgewählten Datensätze, setzt Pfade (Bilder, Labels, TFRecord-Ziel) und prüft deren Existenz.  \n",
    "- Lädt Labels via `load_trackbed_labels`, erstellt eine Klassenverteilungsübersicht und filtert nur die **gelabelten** Bilder.  \n",
    "- Verarbeitet Bilder **parallel** (Resize/Format) und serialisiert sie als `tf.train.Example` in eine **TFRecord**-Datei.  \n",
    "- Hält Laufstatistiken über alle Datensätze hinweg (Anzahl verarbeiteter Datensätze/Bilder, erzeugte TFRecords).\n",
    "\n",
    "**Warum:**  \n",
    "- Strukturierter End-to-End-Ablauf von der Label-Zuordnung über Bildvorbereitung bis zur effizienten Speicherung ermöglicht reproduzierbare, skalierbare Datenpipelines.  \n",
    "- Vorab-Prüfungen und Filtern vermeiden Fehlerläufe, Parallelisierung reduziert Laufzeit, TFRecord-Format optimiert das spätere Laden in TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aac439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track overall statistics\n",
    "overall_stats = {\n",
    "    'datasets_processed': 0,\n",
    "    'total_images': 0,\n",
    "    'tfrecord_files_created': []\n",
    "}\n",
    "\n",
    "for dataset_name in datasets_to_process:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing dataset: {dataset_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Define paths\n",
    "    dataset_folder = os.path.join(base_dataset_dir, dataset_name)\n",
    "    images_folder = os.path.join(dataset_folder, 'imgs')\n",
    "    label_file = os.path.join(dataset_folder, f\"{dataset_name}_labels.json\")\n",
    "    output_tfrecord = os.path.join(dataset_folder, f\"{dataset_name}.tfrecord\")\n",
    "    \n",
    "    # Check if dataset folder exists\n",
    "    if not os.path.exists(dataset_folder):\n",
    "        print(f\"❌ Dataset folder not found: {dataset_folder}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if images folder exists\n",
    "    if not os.path.exists(images_folder):\n",
    "        print(f\"❌ Images folder not found: {images_folder}\")\n",
    "        continue\n",
    "    \n",
    "    # Check if label file exists\n",
    "    if not os.path.exists(label_file):\n",
    "        print(f\"❌ Label file not found: {label_file}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"📁 Dataset folder: {dataset_folder}\")\n",
    "    print(f\"🖼️  Images folder: {images_folder}\")\n",
    "    print(f\"🏷️  Label file: {label_file}\")\n",
    "    print(f\"💾 Output TFRecord: {output_tfrecord}\")\n",
    "    \n",
    "    # Step 1: Load labels\n",
    "    print(f\"\\n🔍 Loading labels from {os.path.basename(label_file)}...\")\n",
    "    labels_dict, class_to_index = load_trackbed_labels(label_file, trackbed_classes)\n",
    "    print(f\"📊 Loaded labels for {len(labels_dict)} images\")\n",
    "    \n",
    "    # Analyze label distribution\n",
    "    label_distribution = Counter(labels_dict.values())\n",
    "    print(f\"\\n📈 Class distribution:\")\n",
    "    for class_name, class_idx in class_to_index.items():\n",
    "        count = label_distribution.get(class_idx, 0)\n",
    "        percentage = (count / len(labels_dict) * 100) if labels_dict else 0\n",
    "        print(f\"  {class_name}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Step 2: Get all image files\n",
    "    print(f\"\\n🖼️  Scanning images folder...\")\n",
    "    all_image_files = [f for f in os.listdir(images_folder) \n",
    "                      if f.lower().endswith(image_extensions)]\n",
    "    print(f\"📸 Found {len(all_image_files)} image files\")\n",
    "    \n",
    "    # Filter images that have labels\n",
    "    labeled_images = [img for img in all_image_files if img in labels_dict]\n",
    "    print(f\"🏷️  Images with labels: {len(labeled_images)}\")\n",
    "    \n",
    "    if len(labeled_images) == 0:\n",
    "        print(f\"❌ No labeled images found for {dataset_name}\")\n",
    "        print(f\"First 5 image files: {all_image_files[:5]}\")\n",
    "        print(f\"First 5 label keys: {list(labels_dict.keys())[:5]}\")\n",
    "        continue\n",
    "    \n",
    "    # Step 3: Process images in parallel\n",
    "    print(f\"\\n⚙️  Processing {len(labeled_images)} images...\")\n",
    "    tasks = [(filename, images_folder, target_image_size) for filename in labeled_images]\n",
    "    processed_images = []\n",
    "    \n",
    "    with Pool(num_workers) as pool:\n",
    "        for result in pool.imap_unordered(process_image, tasks):\n",
    "            if result is not None:\n",
    "                processed_images.append(result)\n",
    "    \n",
    "    print(f\"✅ Successfully processed {len(processed_images)} images\")\n",
    "    \n",
    "    # Step 4: Create TFRecord\n",
    "    print(f\"\\n💾 Creating TFRecord: {os.path.basename(output_tfrecord)}\")\n",
    "    \n",
    "    with tf.io.TFRecordWriter(output_tfrecord) as writer:\n",
    "        for filename, image in processed_images:\n",
    "            class_index = labels_dict[filename]\n",
    "            class_name = trackbed_classes[class_index]\n",
    "            example = serialize_trackbed_example(filename, image, class_index, class_name)\n",
    "            writer.write(example)\n",
    "    \n",
    "    print(f\"💾 Wrote {len(processed_images)} records to TFRecord\")\n",
    "    \n",
    "    # Update overall statistics\n",
    "    overall_stats['datasets_processed'] += 1\n",
    "    overall_stats['total_images'] += len(processed_images)\n",
    "    overall_stats['tfrecord_files_created'].append(output_tfrecord)\n",
    "    \n",
    "    print(f\"✅ Completed {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91963f5d",
   "metadata": {},
   "source": [
    "## 9. Validierung\n",
    "\n",
    "**Was:**  \n",
    "- Liest die erzeugten TFRecord-Dateien ein, parst Beispiele anhand eines definierten Feature-Schemas, zeigt Stichproben (erste Records) und ermittelt Gesamtanzahl sowie Klassenverteilung je TFRecord.\n",
    "\n",
    "**Warum:**  \n",
    "- Prüft die korrekte Serialisierung (Feldnamen/-typen, Dimensionen, Labels) und stellt sicher, dass Umfang und Verteilung der Daten den Erwartungen entsprechen — um Pipelinefehler frühzeitig zu erkennen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ad5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🔍 VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Feature description for parsing\n",
    "feature_description = {\n",
    "    'image_filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'class_name': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "for tfrecord_path in overall_stats['tfrecord_files_created']:\n",
    "    dataset_name = os.path.basename(tfrecord_path).replace('.tfrecord', '')\n",
    "    print(f\"\\n📁 Validating {dataset_name}...\")\n",
    "    \n",
    "    if not os.path.exists(tfrecord_path):\n",
    "        print(f\"❌ TFRecord file not found: {tfrecord_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "        record_count = 0\n",
    "        class_distribution = Counter()\n",
    "        \n",
    "        print(\"📊 First 3 records:\")\n",
    "        for i, raw_record in enumerate(dataset.take(3)):\n",
    "            example = tf.io.parse_single_example(raw_record, feature_description)\n",
    "            filename = example['image_filename'].numpy().decode('utf-8')\n",
    "            label = example['label'].numpy()\n",
    "            class_name = example['class_name'].numpy().decode('utf-8')\n",
    "            height = example['height'].numpy()\n",
    "            width = example['width'].numpy()\n",
    "            print(f\"  {filename}: class={class_name} (label={label}), size={width}x{height}\")\n",
    "        \n",
    "        # Count total records and class distribution\n",
    "        for raw_record in dataset:\n",
    "            example = tf.io.parse_single_example(raw_record, feature_description)\n",
    "            class_name = example['class_name'].numpy().decode('utf-8')\n",
    "            class_distribution[class_name] += 1\n",
    "            record_count += 1\n",
    "        \n",
    "        print(f\"📈 Total records: {record_count}\")\n",
    "        print(f\"📊 Class distribution: {dict(class_distribution)}\")\n",
    "        print(f\"✅ Validation successful\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Validation failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5361abd",
   "metadata": {},
   "source": [
    "## 10. Zusammenfassung & Nutzungsbeispiel\n",
    "\n",
    "**Was:**  \n",
    "- Gibt eine kompakte Zusammenfassung der Verarbeitung aus (Basisverzeichnis, Zielbildgröße, Klassen, Anzahl verarbeiteter Datensätze/Bilder).  \n",
    "- Listet alle erzeugten TFRecord-Dateien mit Dateigröße auf.  \n",
    "- Erzeugt ein kurzes Codebeispiel, wie die TFRecords mit `tf.data.TFRecordDataset` geladen, geparst und gebatcht werden können.\n",
    "\n",
    "**Warum:**  \n",
    "- Bietet einen schnellen Überblick über das Ergebnis der Pipeline und erleichtert die Nachvollziehbarkeit.  \n",
    "- Das Nutzungsbeispiel dient als direkter Einstieg für nachgelagerte Trainings-Pipelines in TensorFlow und reduziert Einrichtungsaufwand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(\"📋 SUMMARY REPORT\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"📁 Base directory: {base_dataset_dir}\")\n",
    "print(f\"🎯 Target image size: {target_image_size}\")\n",
    "print(f\"🏷️  Classes: {trackbed_classes}\")\n",
    "print(f\"📊 Datasets processed: {overall_stats['datasets_processed']}\")\n",
    "print(f\"🖼️  Total images processed: {overall_stats['total_images']}\")\n",
    "\n",
    "print(f\"\\n💾 TFRecord files created:\")\n",
    "for tfrecord_path in overall_stats['tfrecord_files_created']:\n",
    "    file_size = os.path.getsize(tfrecord_path) / (1024 * 1024)  # MB\n",
    "    print(f\"  📄 {tfrecord_path} ({file_size:.1f} MB)\")\n",
    "\n",
    "print(f\"\\n🎉 TFRecord creation complete!\")\n",
    "print(f\"📝 All files are ready for TensorFlow training.\")\n",
    "\n",
    "# Create a simple usage example\n",
    "print(f\"\\n📖 Usage Example:\")\n",
    "print(f\"```python\")\n",
    "print(f\"import tensorflow as tf\")\n",
    "print(f\"\")\n",
    "print(f\"# Load dataset\")\n",
    "if overall_stats['tfrecord_files_created']:\n",
    "    example_path = overall_stats['tfrecord_files_created'][0]\n",
    "    print(f\"dataset = tf.data.TFRecordDataset('{example_path}')\")\n",
    "print(f\"\")\n",
    "print(f\"# Parse function\")\n",
    "print(f\"def parse_example(example):\")\n",
    "print(f\"    features = {{\")\n",
    "print(f\"        'image_raw': tf.io.FixedLenFeature([], tf.string),\")\n",
    "print(f\"        'label': tf.io.FixedLenFeature([], tf.int64),\")\n",
    "print(f\"    }}\")\n",
    "print(f\"    parsed = tf.io.parse_single_example(example, features)\")\n",
    "print(f\"    image = tf.io.decode_raw(parsed['image_raw'], tf.uint8)\")\n",
    "print(f\"    image = tf.reshape(image, [{target_image_size[1]}, {target_image_size[0]}, 3])\")\n",
    "print(f\"    image = tf.cast(image, tf.float32) / 255.0\")\n",
    "print(f\"    return image, parsed['label']\")\n",
    "print(f\"\")\n",
    "print(f\"# Apply parsing and batching\")\n",
    "print(f\"dataset = dataset.map(parse_example).batch(32)\")\n",
    "print(f\"```\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
