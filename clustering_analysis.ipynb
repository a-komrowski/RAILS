{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7db966c2",
   "metadata": {},
   "source": [
    "# RAILS — Railbed Analysis & Image Learning System\n",
    "\n",
    "\"RAILS“ ist ein fiktiver Projektname und steht in keiner Verbindung zu bestehenden Produkten, Marken oder Organisationen, etwaige Namensähnlichkeiten sind zufällig und nicht beabsichtigt.\n",
    "\n",
    "Dieses Notebook behandelt die Analyse und das Clustering von Schienenuntergrund-Bilddaten im Rahmen des Master Moduls *„Maschinelles Lernen“*. Grundlage sind rund 50.000 Graustufenbilder aus Messfahrten mehrerer europäischer Städte, die verschiedene Oberbautypen wie Schotter, Asphalt oder Rasen zeigen.  \n",
    " \n",
    "Ziel ist es, mit Hilfe von **Clustering- und Klassifikationsverfahren** Muster und Strukturen in den Daten zu erkennen und die Leistungsfähigkeit unterschiedlicher Ansätze zu vergleichen. Dazu werden die Bilder vorverarbeitet, mithilfe eines vortrainierten CNN in Embeddings überführt und anschließend mit Methoden wie KMeans und DBSCAN gruppiert.\n",
    " \n",
    "Das Notebook ist so strukturiert, dass es den gesamten Workflow von der technischen Vorbereitung bis zur Auswertung abbildet:  \n",
    "- Zunächst erfolgt das **Setup** der Umgebung sowie die **Konfiguration** der Pfade und Parameter.  \n",
    "- Anschließend werden **Datensatzstruktur und Metadaten** untersucht, bevor die **Feature-Extraktion** mit einem CNN durchgeführt wird.  \n",
    "- Die resultierenden Features werden **normalisiert und mittels PCA reduziert**, um sie für Clustering-Algorithmen vorzubereiten.  \n",
    "- Im Kernteil werden **KMeans** und **DBSCAN** angewendet, systematisch evaluiert und visuell miteinander verglichen.  \n",
    "- Schließlich werden die **Cluster-Ergebnisse gespeichert**, Reports erzeugt und eine detaillierte **Tenant-Analyse** erstellt.  \n",
    " \n",
    "Im Fokus steht die praktische Anwendung moderner Machine-Learning-Techniken auf reale Daten sowie eine transparente Dokumentation der Ergebnisse mit Metriken und Visualisierungen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e8d82b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8f2c149",
   "metadata": {},
   "source": [
    "# Inhaltsverzeichnis\n",
    "- [Einleitung](#rails--railbed-analysis--image-learning-system)\n",
    "- [1. Setup: Importe & Umgebung](#1-setup-importe--umgebung)\n",
    "- [2. Konfiguration: Pfade, Modellparameter](#2-konfiguration-pfade-modellparameter)\n",
    "- [3. Ergebnisse-Verzeichnis & Datensatz-Check](#3-ergebnisse-verzeichnis--datensatz-check)\n",
    "- [4. Dateiname-Parsing, Dataset-Metadaten & Tenant-Verteilung](#4-dateiname-parsing-dataset-metadaten--tenant-verteilung)\n",
    "- [5. Feature-Extraktion](#5-feature-extraktion)\n",
    "- [5.1 Feature-Extraktion vorbereiten: Funktionen & Pipeline](#51-feature-extraktion-vorbereiten-funktionen--pipeline)\n",
    "- [5.2 Feature-Extraktion ausführen (CPU-Only, Timing & Valid-Filter)](#52-feature-extraktion-ausführen-cpu-only-timing--valid-filter)\n",
    "- [6. Feature-Nachbearbeitung (Normalisierung & PCA → Vorbereitung fürs Clustering)](#6-feature-nachbearbeitung-normalisierung--pca--vorbereitung-fürs-clustering)\n",
    "- [7. K-Means](#7-k-means)\n",
    "- [7.1 K-Means: k-Sweep & Clusterbewertung (Inertia, Silhouette, Clustergrößen)](#71-k-means-k-sweep--clusterbewertung-inertia-silhouette-clustergrößen)\n",
    "- [7.2 K-Means Evaluation visualisieren & k bestimmen](#72-k-means-evaluation-visualisieren--k-bestimmen)\n",
    "- [7.3 Finales K-Means mit optimalem k & Clusteranalyse](#73-finales-k-means-mit-optimalem-k--clusteranalyse)\n",
    "- [7.4 K-Means-Clusterbeispiele: Visualisierung von Beispielbildern](#74-k-means-clusterbeispiele-visualisierung-von-beispielbildern)\n",
    "- [8. DBSCAN](#8-dbscan)\n",
    "- [8.1 DBSCAN: Parameter-Grid, Heatmaps & Best-Selection](#81-dbscan-parameter-grid-heatmaps--best-selection)\n",
    "- [9. Visualisierung: K-Means & DBSCAN (Side-by-Side) mit t-SNE](#9-visualisierung-k-means--dbscan-side-by-side-mit-t-sne)\n",
    "- [9.1 K-Nearest Neighbor Grafik](#91-k-nearest-neighbor-grafik)\n",
    "- [10. Cluster-Ergebnisse speichern](#10-cluster-ergebnisse-speichern)\n",
    "- [10.1 Speicher-Helfer definieren (Ordner/Bildkopie/Metadaten)](#101-speicher-helfer-definieren-ordnerbildkopiemetadaten)\n",
    "- [10.2 K-Means-Cluster speichern (Ausführung)](#102-k-means-cluster-speichern-ausführung)\n",
    "- [10.3 DBSCAN-Cluster speichern (Ausführung)](#103-dbscan-cluster-speichern-ausführung)\n",
    "- [11. Tenant-Cluster-Analyse (Heatmap & Detailstatistik)](#11-tenant-cluster-analyse-heatmap--detailstatistik)\n",
    "- [12. Clustering-Report (JSON) erstellen & Kernergebnisse ausgeben](#12-clustering-report-json-erstellen--kernergebnisse-ausgeben)\n",
    "- [13. Ergebnisse der Clustering Phase](#13-ergebnisse-der-clustering-phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa00d48",
   "metadata": {},
   "source": [
    "## 1. Setup: Importe & Umgebung\n",
    "\n",
    "**Was:**  \n",
    "- Import zentraler Bibliotheken (Datenhandling, Visualisierung, ML/DL).  \n",
    "\n",
    "**Warum:**  \n",
    "- Konsistente, reproduzierbare Läufe und Zentralisierung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c44f3ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "from collections import Counter, defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "# Deep Learning Libraries - Import AFTER setting environment variables\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Image Processing\n",
    "from img_preprocessing import ImagePreprocessor\n",
    "\n",
    "# Visualization\n",
    "from matplotlib.patches import Rectangle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97c1b32",
   "metadata": {},
   "source": [
    "## 2. Konfiguration: Pfade, Modellparameter\n",
    "\n",
    "**Was:**  \n",
    "- Lauf-zeitgestempelte Ergebnisordner anlegen (Analyse + Clusterbilder).  \n",
    "- Zentrale Hyperparameter für Feature-Extraktion und Clustering definieren.\n",
    "\n",
    "**Warum:**  \n",
    "- **`TIMESTAMP`**: Versioniert jeden Run → kein Überschreiben, einfache Nachverfolgung & Vergleichbarkeit.  \n",
    "- **`DATASET_PATH=...sample_100`**: Kleine Stichprobe zum schnellen Iterieren/Debuggen. Skaliert später auf größere Samples.  \n",
    "- **`BASE_RESULTS_PATH`/`RESULTS_PATH`/`CLUSTERS_PATH`**: Klare Trennung von Analyseartefakten und exportierten Cluster-Bildern.  \n",
    "- **`BATCH_SIZE=32`**: Bestimmt wie viele Bilder zeitgleich in den RAM geladen werden.\n",
    "- **`IMG_SIZE=(224,224)`**: Erwartete Eingabegröße für ResNet50 (ImageNet-Pretraining) → kompatible Modeleingabe.  \n",
    "- **`FEATURE_DIM=2048`**: Output-Dimensionalität von ResNet50 → korrektes Erwartungs-Shape für Downstream-Schritte.  \n",
    "- **`N_CLUSTERS_RANGE=range(3,16)`**: Typischer, kompakter k-Bereich für K-Means-Sweep (Balance aus Rechenzeit und Abdeckung kleiner/mittlerer k).  \n",
    "- **`PCA_COMPONENTS=50`**: Anzahl der Principal Componentes. Angewandt zur Dimensionsreduktion.\n",
    "- **`RANDOM_STATE=42`**: Reproduzierbarkeit über PCA/t-SNE/K-Means hinweg.\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- `TIMESTAMP` prägt alle Output-Pfade (kein Überschreiben alter Ergebnisse).  \n",
    "- `N_CLUSTERS_RANGE=3..15` für den k-Sweep (K-Means/MiniBatchKMeans).\n",
    "\n",
    "**Outputs:**  \n",
    "- Konsolenhinweis mit Zielpfaden (`RESULTS_PATH`, `CLUSTERS_PATH`).  \n",
    "- Keine Dateien an dieser Stelle – nur Konfiguration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7146102e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis timestamp: 20250831_210135\n",
      "Results will be saved to:\n",
      "  Analysis results: ./results_20250831_210135/clustering_analysis\n",
      "  Clustered images: ./results_20250831_210135/clustered_images\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "print(f\"Analysis timestamp: {TIMESTAMP}\")\n",
    "DATASET_PATH = \"./datasets/clustering_sample_10000\"\n",
    "BASE_RESULTS_PATH = f\"./results_{TIMESTAMP}\"\n",
    "RESULTS_PATH = f\"{BASE_RESULTS_PATH}/clustering_analysis\"\n",
    "CLUSTERS_PATH = f\"{BASE_RESULTS_PATH}/clustered_images\"\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "FEATURE_DIM = 2048\n",
    "N_CLUSTERS_RANGE = range(3, 16)\n",
    "PCA_COMPONENTS = 50\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print(f\"Results will be saved to:\")\n",
    "print(f\"  Analysis results: {RESULTS_PATH}\")\n",
    "print(f\"  Clustered images: {CLUSTERS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051fce4",
   "metadata": {},
   "source": [
    "## 3. Ergebnisse-Verzeichnis & Datensatz-Check\n",
    "\n",
    "**Was:**  \n",
    "- Anlage laufzeitgestempelter Ergebnisordner (Analyse, Clusterbilder), Ausgabe der Pfade.  \n",
    "- Sanity-Check des Datensatzpfads; Fallback: Auflistung vorhandener Datasets mit Bildanzahl.\n",
    "- Zählen aller `.png`-Dateien im gewählten Dataset.  \n",
    "- Persistieren einer `run_metadata.json` (Pfad- und Konfig-Snapshot).\n",
    "\n",
    "**Warum:**  \n",
    "- **Ordnererstellung** verhindert Fehler bei wiederholten Läufen.  \n",
    "- **Pfad-/Existenz-Check** reduziert Fehlersuche bei falschen Datasetangaben.  \n",
    "- **Bildzählung** schafft Transparenz (Basis für spätere Prozentangaben, Laufzeitabschätzungen).  \n",
    "- **`run_metadata.json`** dokumentiert Pfade & Konfiguration (Reproduzierbarkeit, Vergleichbarkeit zwischen Runs).\n",
    "\n",
    "**Outputs:**  \n",
    "- Verzeichnisse: `RESULTS_PATH`, `CLUSTERS_PATH`  \n",
    "- Datei: `RESULTS_PATH/run_metadata.json`  \n",
    "- Konsolen-Logs mit Pfaden und Bildanzahl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "790cbe75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created timestamped directories:\n",
      "Dataset path: ./datasets/clustering_sample_10000\n",
      "Analysis results path: ./results_20250831_210135/clustering_analysis\n",
      "Clustered images path: ./results_20250831_210135/clustered_images\n",
      "Error: Dataset path ./datasets/clustering_sample_10000 does not exist!\n",
      "Available dataset directories:\n",
      "  clustering_sample_5000: 5000 images\n",
      "  clustering_sample_10000_v2: 10000 images\n",
      "  clustering_sample_10000_v1: 10000 images\n",
      "  clustering_sample_1000: 1000 images\n",
      "  clustering_sample_100: 100 images\n",
      "  clustering_sample_50000: 50000 images\n",
      "\n",
      "Run metadata saved to: ./results_20250831_210135/clustering_analysis/run_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Create timestamped result roots (idempotent: no error if folders already exist)\n",
    "Path(RESULTS_PATH).mkdir(parents=True, exist_ok=True)\n",
    "Path(CLUSTERS_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Created timestamped directories:\")\n",
    "print(f\"Dataset path: {DATASET_PATH}\")\n",
    "print(f\"Analysis results path: {RESULTS_PATH}\")\n",
    "print(f\"Clustered images path: {CLUSTERS_PATH}\")\n",
    "\n",
    "# Check dataset existence; if missing, enumerate available subfolders under ./datasets\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    print(f\"Error: Dataset path {DATASET_PATH} does not exist!\")\n",
    "    print(\"Available dataset directories:\")\n",
    "    datasets_dir = Path(\"./datasets\")\n",
    "    if datasets_dir.exists():\n",
    "        for subdir in datasets_dir.iterdir():\n",
    "            if subdir.is_dir():\n",
    "                # Count only files ending with '.png' (case-sensitive)\n",
    "                img_count = len([f for f in subdir.iterdir() if f.suffix == '.png'])\n",
    "                print(f\"  {subdir.name}: {img_count} images\")\n",
    "else:\n",
    "    # Count .png files in the selected dataset (flat folder expected)\n",
    "    img_count = len([f for f in Path(DATASET_PATH).iterdir() if f.suffix == '.png'])\n",
    "    print(f\"Found {img_count} images in dataset\")\n",
    "\n",
    "# Build a metadata snapshot for this run (paths, counts, and core configuration)\n",
    "run_metadata = {\n",
    "    'timestamp': TIMESTAMP,  # run identifier\n",
    "    'dataset_path': str(Path(DATASET_PATH).resolve()),\n",
    "    'total_images_found': img_count if os.path.exists(DATASET_PATH) else 0,\n",
    "    'analysis_results_path': str(Path(RESULTS_PATH).resolve()),\n",
    "    'clustered_images_path': str(Path(CLUSTERS_PATH).resolve()),\n",
    "    'configuration': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'img_size': IMG_SIZE,\n",
    "        'feature_dim': FEATURE_DIM,\n",
    "        'n_clusters_range': list(N_CLUSTERS_RANGE),\n",
    "        'pca_components': PCA_COMPONENTS,\n",
    "        'random_state': RANDOM_STATE\n",
    "    }\n",
    "}\n",
    "\n",
    "# Persist metadata to JSON for reproducibility/audit\n",
    "with open(f\"{RESULTS_PATH}/run_metadata.json\", 'w') as f:\n",
    "    json.dump(run_metadata, f, indent=2)\n",
    "    \n",
    "print(f\"\\nRun metadata saved to: {RESULTS_PATH}/run_metadata.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838965c4",
   "metadata": {},
   "source": [
    "## 4. Dateiname-Parsing, Dataset-Metadaten & Tenant-Verteilung\n",
    "\n",
    "**Was:**  \n",
    "- Parsen der Dateinamen mit Suffix `_C.png`, um **tenant**, **SID** und **original_filename** zu extrahieren.  \n",
    "- Einlesen des Datasets zu einer **Dateiliste** und Aggregation der **Tenant-Verteilung**.\n",
    "- Ausgabe von **Gesamtzahl**, **#Tenants** und **Prozentanteilen** je Tenant.\n",
    "\n",
    "**Warum:**  \n",
    "- Die Metadaten aus dem Dateinamen erlauben **Slicing** (z. B. Auswertung pro Tenant) und **Qualitätskontrollen** (Ungleichgewichte erkennen).  \n",
    "- Die Fokussierung auf `_C.png` stellt sicher, dass nur **konforme, bereinigte** Bildvarianten verarbeitet werden (einheitliche Pipeline).\n",
    "\n",
    "**Outputs:**  \n",
    "- `image_files` (Liste mit Pfad + extrahierten Metadaten)  \n",
    "- `tenant_distribution` (Dict mit Zählungen)  \n",
    "- Konsolen-Logs (Totals, #Tenants, Verteilung in %)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2c45d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset information...\n",
      "\n",
      "Total images: 0\n",
      "Number of tenants: 0\n",
      "\n",
      "Tenant distribution:\n"
     ]
    }
   ],
   "source": [
    "def parse_filename(filename: str):\n",
    "    \"\"\"Parse filename to extract tenant, SID, and original filename.\"\"\"\n",
    "    # Expect filenames ending with '_C.png' (case-sensitive)\n",
    "    # Pattern convention: {tenant}_{sid}_{original}_C.png\n",
    "    if not filename.endswith('_C.png'):\n",
    "        return None, None, None\n",
    "    \n",
    "    name_without_ext = filename[:-6]  # Remove '_C.png' (6 characters)\n",
    "    parts = name_without_ext.split('_')\n",
    "    \n",
    "    # Require at least 3 parts: tenant, sid, and the remaining original name\n",
    "    if len(parts) >= 3:\n",
    "        tenant = parts[0]\n",
    "        sid = parts[1]\n",
    "        original_filename = '_'.join(parts[2:])\n",
    "        return tenant, sid, original_filename\n",
    "    \n",
    "    # Fallback if naming does not match the expected convention\n",
    "    return None, None, None\n",
    "\n",
    "def load_dataset_info(dataset_path: str):\n",
    "    \"\"\"Load and analyze dataset information.\"\"\"\n",
    "    # Build file index and aggregate tenant counts based on parsed filenames\n",
    "    image_files = []\n",
    "    tenant_distribution = defaultdict(int)\n",
    "    \n",
    "    # Non-recursive, case-sensitive pattern: only matches '*_C.png' in the given folder\n",
    "    for file_path in Path(dataset_path).glob('*_C.png'):\n",
    "        filename = file_path.name\n",
    "        tenant, sid, original_name = parse_filename(filename)\n",
    "        \n",
    "        # Keep only files that match the naming convention\n",
    "        if tenant:\n",
    "            image_files.append({\n",
    "                'filepath': str(file_path),\n",
    "                'filename': filename,\n",
    "                'tenant': tenant,\n",
    "                'sid': sid,\n",
    "                'original_name': original_name\n",
    "            })\n",
    "            tenant_distribution[tenant] += 1\n",
    "    \n",
    "    return image_files, dict(tenant_distribution)\n",
    "\n",
    "# Load dataset information (flat folder expected)\n",
    "print(\"Loading dataset information...\")\n",
    "image_files, tenant_distribution = load_dataset_info(DATASET_PATH)\n",
    "\n",
    "# Summary (assumes >=1 valid image; add guard if needed)\n",
    "print(f\"\\nTotal images: {len(image_files)}\")\n",
    "print(f\"Number of tenants: {len(tenant_distribution)}\")\n",
    "print(\"\\nTenant distribution:\")\n",
    "for tenant, count in sorted(tenant_distribution.items()):\n",
    "    percentage = (count / len(image_files)) * 100\n",
    "    print(f\"  {tenant}: {count} images ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ad44ed",
   "metadata": {},
   "source": [
    "### 5. Feature-Extraktion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f40cd",
   "metadata": {},
   "source": [
    "### 5.1 Feature-Extraktion vorbereiten: Funktionen & Pipeline\n",
    "\n",
    "**Was:**  \n",
    "- Hilfsfunktionen zum Laden und ggf. Vorverarbeiten einzelner Bilder, Erzeugen des ResNet50-Encoders und batchweises Ableiten der Feature-Embeddings (2048-D).\n",
    "\n",
    "**Warum:**  \n",
    "- Saubere Trennung von I/O, Modellkonstruktion und Batch-Verarbeitung erleichtert Debugging und spätere Modellaustausche (z. B. anderer Encoder).\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- 5 mögliche Vorverarbeitungsfunktionen (img_processing.py)\n",
    "\n",
    "**Outputs:**  \n",
    "- Keinerlei Dateien. Rückgaben sind In-Memory: Feature-Matrizen (N×2048) und gültige Pfade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "787cc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path: str, target_size: tuple = IMG_SIZE):\n",
    "    \"\"\"Load and preprocess image for ResNet50.\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, target_size)\n",
    "        # insert preprocessing here\n",
    "        # for exmaple:\n",
    "        #img = ImagePreprocessor.method_3_gamma_correction(img)\n",
    "        img_array = image.img_to_array(img)    \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_feature_extractor():\n",
    "    \"\"\"Create ResNet50 feature extractor (without top classification layer).\"\"\"\n",
    "    print(\"Loading ResNet50 model...\")\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "        pooling='avg'  # Global average pooling\n",
    "    )\n",
    "    \n",
    "    # The model output will be (batch_size, 2048) features\n",
    "    print(f\"Feature extractor output shape: {base_model.output_shape}\")\n",
    "    return base_model\n",
    "\n",
    "def extract_features_batch(model, image_paths: list, batch_size: int = BATCH_SIZE):\n",
    "    \"\"\"Extract features from images in batches.\"\"\"\n",
    "    features = []\n",
    "    valid_paths = []\n",
    "    \n",
    "    print(f\"Extracting features from {len(image_paths)} images...\")\n",
    "    \n",
    "    for i in range(0, len(image_paths), batch_size):\n",
    "        batch_paths = image_paths[i:i + batch_size]\n",
    "        batch_images = []\n",
    "        batch_valid_paths = []\n",
    "        \n",
    "        # Load batch images\n",
    "        for img_path in batch_paths:\n",
    "            img_array = load_and_preprocess_image(img_path)\n",
    "            if img_array is not None:\n",
    "                batch_images.append(img_array[0])  # Remove batch dimension\n",
    "                batch_valid_paths.append(img_path)\n",
    "        \n",
    "        if batch_images:\n",
    "            # Convert to numpy array and predict\n",
    "            batch_images = np.array(batch_images)\n",
    "            batch_features = model.predict(batch_images, verbose=0)\n",
    "            \n",
    "            features.extend(batch_features)\n",
    "            valid_paths.extend(batch_valid_paths)\n",
    "        \n",
    "        # Progress update\n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            print(f\"  Processed {min(i + batch_size, len(image_paths))}/{len(image_paths)} images\")\n",
    "    \n",
    "    return np.array(features), valid_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabd2971",
   "metadata": {},
   "source": [
    "### 5.2 Feature-Extraktion ausführen (CPU-Only, Timing & Valid-Filter)\n",
    "\n",
    "**Was:**  \n",
    "- Initialisieren des ResNet50-Feature-Extractors, Sammeln der `image_paths` und batchweise Extraktion der Embeddings.  \n",
    "- Messen der Laufzeit und Ausgeben von Kernwerten (Shape, Anzahl gültiger Bilder).  \n",
    "- Filtern nicht ladbarer Bilder und Aktualisieren von `image_files` auf die valide Teilmenge.\n",
    "\n",
    "**Warum:**  \n",
    "- Laufzeitmessung hilft bei der Abschätzung von Skalierung und Batchgrößen.  \n",
    "- Der Valid-Filter stellt sicher, dass nachfolgende Schritte (Clustering) nur konsistente Daten verarbeiten.\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- Erwartete Feature-Form: `(N, 2048)` (ResNet50 + GlobalAvgPooling).  \n",
    "- Die Reihenfolge der `valid_paths` bleibt mit `image_files` konsistent (wichtig für spätere Zuordnungen).\n",
    "\n",
    "**Outputs:**  \n",
    "- In-Memory: `features` (N×2048), `valid_paths`, bereinigtes `image_files`.  \n",
    "- Konsole: Laufzeit, Shape, Zählstatistik.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56acc538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE EXTRACTION\n",
      "================================================================================\n",
      "Loading ResNet50 model...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src.backend' has no attribute 'standardize_dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create feature extractor\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_feature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# builds ResNet50 backbone \u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Extract image paths\u001b[39;00m\n\u001b[1;32m     10\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m image_files]  \u001b[38;5;66;03m# preserve order for alignment with features\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 20\u001b[0m, in \u001b[0;36mcreate_feature_extractor\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create ResNet50 feature extractor (without top classification layer).\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading ResNet50 model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIMG_SIZE\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mavg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Global average pooling\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# The model output will be (batch_size, 2048) features\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature extractor output shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_model\u001b[38;5;241m.\u001b[39moutput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/andi/ssd2/dev/code/RAILS/.venv/lib/python3.10/site-packages/keras/src/applications/resnet.py:409\u001b[0m, in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[1;32m    406\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack_residual_blocks_v1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack_residual_blocks_v1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/andi/ssd2/dev/code/RAILS/.venv/lib/python3.10/site-packages/keras/src/applications/resnet.py:212\u001b[0m, in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name, weights_name)\u001b[0m\n\u001b[1;32m    205\u001b[0m         file_hash \u001b[38;5;241m=\u001b[39m WEIGHTS_HASHES[weights_name][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    206\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[1;32m    207\u001b[0m         file_name,\n\u001b[1;32m    208\u001b[0m         BASE_WEIGHTS_PATH \u001b[38;5;241m+\u001b[39m file_name,\n\u001b[1;32m    209\u001b[0m         cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    210\u001b[0m         file_hash\u001b[38;5;241m=\u001b[39mfile_hash,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights)\n",
      "File \u001b[0;32m/media/andi/ssd2/dev/code/RAILS/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/media/andi/ssd2/dev/code/RAILS/.venv/lib/python3.10/site-packages/keras/src/backend/common/variables.py:314\u001b[0m, in \u001b[0;36mVariable.dtype\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype\n\u001b[0;32m--> 314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstandardize_dtype\u001b[49m(dtype)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.src.backend' has no attribute 'standardize_dtype'"
     ]
    }
   ],
   "source": [
    "# Extract features using ResNet50\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE EXTRACTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create feature extractor\n",
    "feature_extractor = create_feature_extractor()  # builds ResNet50 backbone \n",
    "\n",
    "# Extract image paths\n",
    "image_paths = [item['filepath'] for item in image_files]  # preserve order for alignment with features\n",
    "\n",
    "# Extract features\n",
    "start_time = time.time()\n",
    "features, valid_paths = extract_features_batch(feature_extractor, image_paths)  # batched inference\n",
    "extraction_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nFeature extraction completed in {extraction_time:.2f} seconds\")\n",
    "print(f\"Extracted features shape: {features.shape}\")  # expect (N_valid, 2048)\n",
    "print(f\"Valid images: {len(valid_paths)}/{len(image_paths)}\")\n",
    "\n",
    "# Update image_files to only include valid images\n",
    "valid_image_files = []\n",
    "for img_file in image_files:\n",
    "    if img_file['filepath'] in valid_paths:  # keep only successfully processed paths\n",
    "        valid_image_files.append(img_file)\n",
    "\n",
    "image_files = valid_image_files  # downstream steps use the filtered metadata list\n",
    "print(f\"Updated image files: {len(image_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e92e21",
   "metadata": {},
   "source": [
    "## 6. Feature-Nachbearbeitung (Normalisierung & PCA → Vorbereitung fürs Clustering)\n",
    "\n",
    "**Was:**  \n",
    "- L2-Normierung der Embeddings (zeilenweise) und optionale PCA-Reduktion auf `PCA_COMPONENTS`.  \n",
    "- Ausgeben von Kennzahlen vor/nach Normalisierung sowie erklärter Gesamtvarianz der PCA.\n",
    "\n",
    "**Warum:**  \n",
    "- L2-Normierung macht Distanzen vergleichbar (≈ spherical K-Means) und stabilisiert Metriken.  \n",
    "- PCA reduziert Dimensionen, Rauschen und Rechenzeit. kann die Trennbarkeit für K-Means/DBSCAN verbessern.\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- PCA-Fit erfolgt auf **normalisierten** Features; `random_state` für Reproduzierbarkeit gesetzt.  \n",
    "- Default für das Clustering sind die **voll normalisierten** Features. PCA-Features optional testen/umschalten.\n",
    "\n",
    "**Outputs:**  \n",
    "- `features_normalized`, `features_pca`\n",
    "- Konsolen-Stats (vor/nach Normalisierung, PCA-Varianz, Shapes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f74fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features to unit length per sample (stabilizes distances for K-Means/DBSCAN)\n",
    "print(\"Normalizing features...\")\n",
    "features_normalized = normalize(features, norm='l2', axis=1)\n",
    "\n",
    "# Basic sanity statistics before/after normalization\n",
    "print(f\"Original feature statistics:\")\n",
    "print(f\"  Mean: {features.mean():.4f}\")\n",
    "print(f\"  Std: {features.std():.4f}\")\n",
    "print(f\"  Min: {features.min():.4f}\")\n",
    "print(f\"  Max: {features.max():.4f}\")\n",
    "\n",
    "print(f\"\\nNormalized feature statistics:\")\n",
    "print(f\"  Mean: {features_normalized.mean():.4f}\")\n",
    "print(f\"  Std: {features_normalized.std():.4f}\")\n",
    "print(f\"  L2 norm (first sample): {np.linalg.norm(features_normalized[0]):.4f}\")\n",
    "\n",
    "# Optional dimensionality reduction (denoising + speed-up for clustering/TSNE)\n",
    "print(f\"\\nApplying PCA to reduce dimensions from {FEATURE_DIM} to {PCA_COMPONENTS}...\")\n",
    "pca = PCA(n_components=PCA_COMPONENTS, random_state=RANDOM_STATE)\n",
    "features_pca = pca.fit_transform(features_normalized)\n",
    "\n",
    "# Report explained variance (sum) and resulting shape\n",
    "print(f\"PCA explained variance ratio: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"PCA features shape: {features_pca.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e5e076",
   "metadata": {},
   "source": [
    "## 7. K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaaa5af",
   "metadata": {},
   "source": [
    "### 7.1 K-Means: k-Sweep & Clusterbewertung (Inertia, Silhouette, Clustergrößen)\n",
    "\n",
    "**Was:**  \n",
    "- k-Sweep: systematisches Durchtesten mehrerer Clusterzahlen `k` (z. B. 3–15), um anhand von Metriken (Silhouette/Inertia) das sinnvollste `k` zu wählen\n",
    "- Systematischer k-Sweep über `N_CLUSTERS_RANGE` auf `features_pca` (standardmäßig **MiniBatchKMeans**).  \n",
    "- Für jedes k: Fit & Predict → **Inertia**, **Silhouette-Score** und **Clustergrößen** (min/max, Verteilung); Modell wird mitgespeichert.\n",
    "\n",
    "**Warum:**  \n",
    "- Der k-Sweep liefert eine **datengetriebene Wahl** der Clusterzahl \n",
    "  **Silhouette** bewertet Trennung/Kompaktheit (höher = besser), **Inertia** zeigt den „Elbow“ (abnehmender Grenznutzen).  \n",
    "- **MiniBatchKMeans** skaliert besser auf größere N, ist für Embeddings meist ausreichend präzise.\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- `n_init=10` reduziert die Chance auf schlechte lokale Minima. \n",
    "\n",
    "**Outputs:**  \n",
    "- `kmeans_results`: Liste von Dicts `{k, inertia, silhouette_score, min_cluster_size, max_cluster_size, cluster_sizes, model}`\n",
    "- Konsolen-Logs pro k (Inertia, Silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f8a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kmeans_clusters(features, k_range, use_minibatch=True):\n",
    "    # Assumes features are L2-normalized for stable distance geometry (spherical k-means behavior).\n",
    "    # Computes inertia, silhouette, and size diagnostics per k. stores the fitted model for later reuse.\n",
    "    \"\"\"Evaluate K-Means clustering for different k values.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    print(f\"Evaluating K-Means for k in {list(k_range)}...\")\n",
    "    \n",
    "    for k in k_range:\n",
    "        print(f\"  Testing k={k}...\")\n",
    "        \n",
    "        # Use MiniBatchKMeans for efficiency with large datasets\n",
    "        if use_minibatch:\n",
    "            kmeans = MiniBatchKMeans(\n",
    "                n_clusters=k,\n",
    "                random_state=RANDOM_STATE,\n",
    "                batch_size=100,\n",
    "                n_init=10\n",
    "            )\n",
    "        else:\n",
    "            kmeans = KMeans(\n",
    "                n_clusters=k,\n",
    "                random_state=RANDOM_STATE,\n",
    "                n_init=10\n",
    "            )\n",
    "        \n",
    "        # Fit and predict\n",
    "        cluster_labels = kmeans.fit_predict(features)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        inertia = kmeans.inertia_\n",
    "        silhouette_avg = silhouette_score(features, cluster_labels)\n",
    "        \n",
    "        # Cluster sizes\n",
    "        cluster_sizes = Counter(cluster_labels)\n",
    "        min_cluster_size = min(cluster_sizes.values())\n",
    "        max_cluster_size = max(cluster_sizes.values())\n",
    "        \n",
    "        results.append({\n",
    "            'k': k,\n",
    "            'inertia': inertia,\n",
    "            'silhouette_score': silhouette_avg,\n",
    "            'min_cluster_size': min_cluster_size,\n",
    "            'max_cluster_size': max_cluster_size,\n",
    "            'cluster_sizes': dict(cluster_sizes),\n",
    "            'model': kmeans\n",
    "        })\n",
    "        \n",
    "        print(f\"    Inertia: {inertia:.2f}, Silhouette: {silhouette_avg:.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Evaluate K-Means clustering\n",
    "print(\"=\" * 80)\n",
    "print(\"K-MEANS CLUSTERING EVALUATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Runs the k-sweep and collects metrics/models per k\n",
    "kmeans_results = evaluate_kmeans_clusters(features_pca, N_CLUSTERS_RANGE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee8ace",
   "metadata": {},
   "source": [
    "### 7.2 K-Means Evaluation visualisieren & k bestimmen\n",
    "\n",
    "**Was:**  \n",
    "- 2×2-Dashboard: Elbow (Inertia), Silhouette, Clustergrößen (min/max), kombinierte Metriken.  \n",
    "- Bestimmung von `optimal_k` über das Maximum des Silhouette-Scores.\n",
    "\n",
    "**Warum:**  \n",
    "- **Inertia** zeigt den „Knick“ (abnehmender Grenznutzen), **Silhouette** misst Trennung & Kompaktheit.  \n",
    "- **Kombination** (1−normierte Inertia & normierte Silhouette) hilft, widersprüchliche Signale zu balancieren.\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- `1 - norm_inertias` sorgt für gleiche Zielfunktion („höher ist besser“).  \n",
    "- Stabilität prüfen: keine Mini-Cluster, Domänensinn; Elbow nur als Plausibilisierung.\n",
    "\n",
    "**Outputs:**  \n",
    "- Plot `kmeans_evaluation.png`, `optimal_k`, bester Silhouette-Wert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c81cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization of k-sweep metrics & selection of k* ---\n",
    "\n",
    "# Plot K-Means evaluation results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('K-Means Clustering Evaluation', fontsize=16)\n",
    "\n",
    "# Extract data for plotting (one value per tested k)\n",
    "k_values = [r['k'] for r in kmeans_results]\n",
    "inertias = [r['inertia'] for r in kmeans_results]\n",
    "silhouette_scores = [r['silhouette_score'] for r in kmeans_results]\n",
    "min_cluster_sizes = [r['min_cluster_size'] for r in kmeans_results]\n",
    "max_cluster_sizes = [r['max_cluster_size'] for r in kmeans_results]\n",
    "\n",
    "# --- Elbow plot (Inertia vs k): look for the knee / diminishing returns ---\n",
    "axes[0, 0].plot(k_values, inertias, 'bo-')\n",
    "axes[0, 0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0, 0].set_ylabel('Inertia')\n",
    "axes[0, 0].set_title('Elbow Method')\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "# --- Silhouette score vs k: pick the maximum as primary criterion ---\n",
    "axes[0, 1].plot(k_values, silhouette_scores, 'ro-')\n",
    "axes[0, 1].set_xlabel('Number of Clusters (k)')\n",
    "axes[0, 1].set_ylabel('Silhouette Score')\n",
    "axes[0, 1].set_title('Silhouette Analysis')\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# --- Cluster size diagnostics: min/max sizes vs k (imbalances, tiny clusters) ---\n",
    "axes[1, 0].plot(k_values, min_cluster_sizes, 'go-', label='Min cluster size')\n",
    "axes[1, 0].plot(k_values, max_cluster_sizes, 'mo-', label='Max cluster size')\n",
    "axes[1, 0].set_xlabel('Number of Clusters (k)')\n",
    "axes[1, 0].set_ylabel('Cluster Size')\n",
    "axes[1, 0].set_title('Cluster Size Distribution')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# --- Combined metrics (normalized): align direction to \"higher is better\" ---\n",
    "norm_inertias = np.array(inertias) / max(inertias)            # scale to [0,1]\n",
    "norm_silhouettes = np.array(silhouette_scores) / max(silhouette_scores)  # scale to [0,1]\n",
    "axes[1, 1].plot(k_values, 1 - norm_inertias, 'b-', label='1 - Normalized Inertia')\n",
    "axes[1, 1].plot(k_values, norm_silhouettes, 'r-', label='Normalized Silhouette')\n",
    "axes[1, 1].set_xlabel('Number of Clusters (k)')\n",
    "axes[1, 1].set_ylabel('Normalized Score')\n",
    "axes[1, 1].set_title('Combined Metrics')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}/kmeans_evaluation.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# --- Select optimal k by maximum silhouette (primary criterion) ---\n",
    "best_silhouette_idx = np.argmax(silhouette_scores)\n",
    "optimal_k = k_values[best_silhouette_idx]\n",
    "print(f\"\\nOptimal k based on silhouette score: {optimal_k}\")\n",
    "print(f\"Best silhouette score: {silhouette_scores[best_silhouette_idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381f980",
   "metadata": {},
   "source": [
    "### 7.3 Finales K-Means mit optimalem k & Clusteranalyse\n",
    "\n",
    "**Was:**  \n",
    "- Finales Fitting von `MiniBatchKMeans` mit `k=optimal_k`. \n",
    "- Anreicherung von `image_files` um das Feld `cluster`.  \n",
    "- Aggregation einer Clusterübersicht inkl. **Tenant-Verteilung** je Cluster.\n",
    "\n",
    "**Warum:**  \n",
    "- Nach dem k-Sweep wird das beste k produktiv angewendet. Die resultierenden Labels bilden die Basis für Analyse, Export und Visualisierung.  \n",
    "- Tenant-Verteilungen helfen, **Bias/Imbalance** zu erkennen und Cluster zu interpretieren.\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- `n_init=20` senkt das Risiko schlechter lokaler Minima im finalen Fit.  \n",
    "- Die Reihenfolge von `image_files` muss den `cluster_labels` entsprechen (hier gegeben).  \n",
    "- Prozentanteile werden je Cluster relativ zu dessen Größe berechnet.\n",
    "\n",
    "**Outputs:**  \n",
    "- In-Memory: `cluster_labels`, angereichertes `image_files` (mit `cluster`).  \n",
    "- Konsole: Größe je Cluster und Tenant-Rangfolge pro Cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs MiniBatchKMeans once more with stronger n_init and assigns labels to all samples\n",
    "print(f\"\\nPerforming final K-Means clustering with k={optimal_k}...\")\n",
    "\n",
    "final_kmeans = MiniBatchKMeans(\n",
    "    n_clusters=optimal_k,\n",
    "    random_state=RANDOM_STATE,\n",
    "    batch_size=100,\n",
    "    n_init=20  # More initializations for final model\n",
    ")\n",
    "\n",
    "cluster_labels = final_kmeans.fit_predict(features_pca)\n",
    "\n",
    "# Enrich metadata: attach the integer cluster label to each image_file entry\n",
    "for i, img_file in enumerate(image_files):\n",
    "    img_file['cluster'] = int(cluster_labels[i])\n",
    "\n",
    "# Cluster composition analysis (counts per cluster and tenant distribution)\n",
    "print(f\"\\nCluster Analysis:\")\n",
    "cluster_stats = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for img_file in image_files:\n",
    "    cluster = img_file['cluster']\n",
    "    tenant = img_file['tenant']\n",
    "    cluster_stats[cluster]['total'] += 1\n",
    "    cluster_stats[cluster][tenant] += 1\n",
    "\n",
    "# Human-readable report per cluster (size + tenant ranking)\n",
    "for cluster_id in sorted(cluster_stats.keys()):\n",
    "    stats = cluster_stats[cluster_id]\n",
    "    total = stats['total']\n",
    "    print(f\"\\nCluster {cluster_id}: {total} images\")\n",
    "    \n",
    "    # Show tenant distribution in this cluster\n",
    "    tenant_counts = {k: v for k, v in stats.items() if k != 'total'}\n",
    "    for tenant, count in sorted(tenant_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        percentage = (count / total) * 100\n",
    "        print(f\"  {tenant}: {count} ({percentage:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0fe6c4",
   "metadata": {},
   "source": [
    "### 7.4 K-Means-Clusterbeispiele: Visualisierung von Beispielbildern\n",
    "\n",
    "**Was:**  \n",
    "- Zeigt pro Cluster eine Stichprobe zufälliger Bilder in einem Bildgrid (3 Spalten, mehrere Zeilen).  \n",
    "- Nutzt die finalen K-Means-Labels (`image_files[i]['cluster']`) als Grundlage.\n",
    "\n",
    "**Warum:**  \n",
    "- Schnelle, visuelle Qualitätsprüfung der Clusterinhalte (Plausibilität, Ausreißer, Muster).\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- Zufallsstichprobe ≠ „repräsentativste“ Beispiele. \n",
    "- Fehlerhafte oder fehlende Dateien werden textuell im Grid gekennzeichnet.  \n",
    "- Ergebnisse werden als `cluster_<id>_examples.png` gespeichert.\n",
    "\n",
    "**Outputs:**\n",
    "- PNG-Bildtafeln je Cluster unter `RESULTS_PATH`, Konsolenlogs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbba52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cluster_examples(image_files, cluster_id, n_examples=6):\n",
    "    \"\"\"Display example images from a specific cluster.\"\"\"\n",
    "    # Collect all images that belong to the requested cluster\n",
    "    cluster_images = [img for img in image_files if img['cluster'] == cluster_id]\n",
    "    \n",
    "    if not cluster_images:\n",
    "        print(f\"No images found for cluster {cluster_id}\")\n",
    "        return\n",
    "    \n",
    "    # Randomly sample examples (set np.random.seed(...) earlier for reproducibility)\n",
    "    examples = np.random.choice(cluster_images, min(n_examples, len(cluster_images)), replace=False)\n",
    "    \n",
    "    # Create subplot grid (3 columns; rows computed from sample size)\n",
    "    cols = 3\n",
    "    rows = (len(examples) + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    fig.suptitle(f'Cluster {cluster_id} Examples ({len(cluster_images)} total images)', fontsize=16)\n",
    "    \n",
    "    for i, img_info in enumerate(examples):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Load and display image; on failure, render a textual placeholder\n",
    "        try:\n",
    "            img = Image.open(img_info['filepath'])\n",
    "            axes[row, col].imshow(img)\n",
    "            axes[row, col].set_title(f\"{img_info['tenant']}_{img_info['sid']}\", fontsize=10)\n",
    "            axes[row, col].axis('off')\n",
    "        except Exception as e:\n",
    "            axes[row, col].text(0.5, 0.5, f\"Error loading\\n{img_info['filename']}\", \n",
    "                               ha='center', va='center', transform=axes[row, col].transAxes)\n",
    "            axes[row, col].axis('off')\n",
    "    \n",
    "    # Hide any empty subplot cells (if sample size not divisible by #cols)\n",
    "    for i in range(len(examples), rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # Save a PNG panel per cluster to RESULTS_PATH\n",
    "    plt.savefig(f\"{RESULTS_PATH}/cluster_{cluster_id}_examples.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Render example grids for all discovered clusters ---\n",
    "print(\"=\" * 80)\n",
    "print(\"CLUSTER EXAMPLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for cluster_id in sorted(set(cluster_labels)):\n",
    "    display_cluster_examples(image_files, cluster_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f56f7",
   "metadata": {},
   "source": [
    "## 8. DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777aff56",
   "metadata": {},
   "source": [
    "### 8.1 DBSCAN: Parameter-Grid, Heatmaps & Best-Selection\n",
    "\n",
    "**Was:**  \n",
    "- Dichte-basiertes Clustering auf **PCA-Features** mit einem Grid aus `eps × min_samples`.  \n",
    "- Pro Kombination: Fit/Predict, Metriken (Cluster ohne Noise, Noise-Quote, Silhouette ohne Noise) und anschließende **3 Heatmaps**.  \n",
    "- Auswahl des „besten“ Settings per **Silhouette** und **Balanced Score** `silhouette * (1 - noise_ratio)` (robuster).\n",
    "\n",
    "**Warum:**  \n",
    "- DBSCAN ist empfindlich gegenüber `eps`/`min_samples`. ein Grid liefert eine datengetriebene Auswahl. \n",
    "- Balanced Score verhindert triviale Lösungen mit hoher Silhouette aber extremer Noise-Quote.\n",
    "\n",
    "**Besonderheiten:**  \n",
    "- Silhouette wird nur berechnet, wenn >1 Cluster vorhanden; **Noise (-1)** wird bei Silhouette **ausgeschlossen**.  \n",
    "- Für Heatmaps werden negative Silhouetten als **0** visualisiert (bessere Lesbarkeit).  \n",
    "- Bei sehr hoher Noise-Quote: Parameterbereich erweitern oder **PCA-Komponenten** anpassen; optional **k-Distance-Plot** bzw. **HDBSCAN** prüfen.\n",
    "\n",
    "**Outputs:**  \n",
    "- `dbscan_parameter_optimization.png` (Heatmaps), Konsolen-Log der besten Parameter, Objekt `best_dbscan`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Clustering\n",
    "print(\"=\" * 80)\n",
    "print(\"DBSCAN CLUSTERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use PCA features for DBSCAN (better performance in lower dimensions)\n",
    "print(\"Applying DBSCAN on PCA-reduced features...\")\n",
    "\n",
    "# Create a grid of parameters to test\n",
    "eps_values = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.2, 1.5]\n",
    "min_samples_values = [3, 5, 7, 10, 15, 20]\n",
    "\n",
    "print(\"\\nTesting parameter combinations:\")\n",
    "print(f\"eps values: {eps_values}\")\n",
    "print(f\"min_samples values: {min_samples_values}\")\n",
    "print(f\"Total combinations to test: {len(eps_values) * len(min_samples_values)}\")\n",
    "\n",
    "dbscan_results = []\n",
    "\n",
    "# Test all combinations\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        print(f\"\\nTesting DBSCAN with eps={eps}, min_samples={min_samples}...\")\n",
    "        \n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)  # density params: neighborhood radius & min points\n",
    "        dbscan_labels = dbscan.fit_predict(features_pca)   # run on PCA-reduced features\n",
    "        \n",
    "        # Count clusters and noise points\n",
    "        n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)  # exclude noise from cluster count\n",
    "        n_noise = list(dbscan_labels).count(-1)\n",
    "        \n",
    "        # Calculate silhouette score (only if we have more than 1 cluster)\n",
    "        if n_clusters > 1:\n",
    "            # Filter out noise points for silhouette calculation\n",
    "            mask = dbscan_labels != -1\n",
    "            if mask.sum() > 1:  # Need at least 2 points\n",
    "                silhouette_avg = silhouette_score(features_pca[mask], dbscan_labels[mask])\n",
    "            else:\n",
    "                silhouette_avg = -1\n",
    "        else:\n",
    "            silhouette_avg = -1\n",
    "        \n",
    "        result = {\n",
    "            'eps': eps,\n",
    "            'min_samples': min_samples,\n",
    "            'n_clusters': n_clusters,\n",
    "            'n_noise': n_noise,\n",
    "            'noise_ratio': n_noise / len(dbscan_labels),\n",
    "            'silhouette_score': silhouette_avg,\n",
    "            'labels': dbscan_labels\n",
    "        }\n",
    "        dbscan_results.append(result)\n",
    "        \n",
    "        print(f\"  Clusters: {n_clusters}\")\n",
    "        print(f\"  Noise points: {n_noise} ({result['noise_ratio']*100:.1f}%)\")\n",
    "        print(f\"  Silhouette: {silhouette_avg:.4f}\")\n",
    "\n",
    "# Create results visualization\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create a matrix of results\n",
    "eps_grid, min_samples_grid = np.meshgrid(eps_values, min_samples_values)\n",
    "n_clusters_grid = np.zeros_like(eps_grid, dtype=float)\n",
    "silhouette_grid = np.zeros_like(eps_grid, dtype=float)\n",
    "noise_ratio_grid = np.zeros_like(eps_grid, dtype=float)\n",
    "\n",
    "# Fill heatmap matrices with metrics per (eps, min_samples)\n",
    "for result in dbscan_results:\n",
    "    i = min_samples_values.index(result['min_samples'])\n",
    "    j = eps_values.index(result['eps'])\n",
    "    n_clusters_grid[i, j] = result['n_clusters']\n",
    "    silhouette_grid[i, j] = max(result['silhouette_score'], 0)  # Replace negative scores with 0 (visual clarity)\n",
    "    noise_ratio_grid[i, j] = result['noise_ratio']\n",
    "\n",
    "# Plot number of clusters\n",
    "plt.subplot(221)\n",
    "plt.imshow(n_clusters_grid, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar(label='Number of Clusters')\n",
    "plt.ylabel('min_samples')\n",
    "plt.xlabel('eps')\n",
    "plt.title('Number of Clusters')\n",
    "plt.xticks(range(len(eps_values)), [f'{x:.1f}' for x in eps_values], rotation=45)\n",
    "plt.yticks(range(len(min_samples_values)), min_samples_values)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.subplot(222)\n",
    "plt.imshow(silhouette_grid, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar(label='Silhouette Score')\n",
    "plt.ylabel('min_samples')\n",
    "plt.xlabel('eps')\n",
    "plt.title('Silhouette Score')\n",
    "plt.xticks(range(len(eps_values)), [f'{x:.1f}' for x in eps_values], rotation=45)\n",
    "plt.yticks(range(len(min_samples_values)), min_samples_values)\n",
    "\n",
    "# Plot noise ratio\n",
    "plt.subplot(223)\n",
    "plt.imshow(noise_ratio_grid, aspect='auto', interpolation='nearest')\n",
    "plt.colorbar(label='Noise Ratio')\n",
    "plt.ylabel('min_samples')\n",
    "plt.xlabel('eps')\n",
    "plt.title('Noise Ratio')\n",
    "plt.xticks(range(len(eps_values)), [f'{x:.1f}' for x in eps_values], rotation=45)\n",
    "plt.yticks(range(len(min_samples_values)), min_samples_values)\n",
    "\n",
    "# Find best results\n",
    "valid_results = [r for r in dbscan_results if r['silhouette_score'] > 0]\n",
    "if valid_results:\n",
    "    # Sort by different metrics\n",
    "    best_silhouette = max(valid_results, key=lambda x: x['silhouette_score'])  # highest quality by silhouette\n",
    "    balanced_score = max(valid_results, key=lambda x: x['silhouette_score'] * (1 - x['noise_ratio']))  # quality vs. noise trade-off\n",
    "    \n",
    "    print(\"\\nBest results:\")\n",
    "    print(\"\\nBest by silhouette score:\")\n",
    "    print(f\"eps={best_silhouette['eps']}, min_samples={best_silhouette['min_samples']}\")\n",
    "    print(f\"Clusters: {best_silhouette['n_clusters']}\")\n",
    "    print(f\"Noise points: {best_silhouette['n_noise']} ({best_silhouette['noise_ratio']*100:.1f}%)\")\n",
    "    print(f\"Silhouette: {best_silhouette['silhouette_score']:.4f}\")\n",
    "    \n",
    "    print(\"\\nBest balanced (silhouette * (1 - noise_ratio)):\")\n",
    "    print(f\"eps={balanced_score['eps']}, min_samples={balanced_score['min_samples']}\")\n",
    "    print(f\"Clusters: {balanced_score['n_clusters']}\")\n",
    "    print(f\"Noise points: {balanced_score['n_noise']} ({balanced_score['noise_ratio']*100:.1f}%)\")\n",
    "    print(f\"Silhouette: {balanced_score['silhouette_score']:.4f}\")\n",
    "    \n",
    "    # Use balanced score as best result (more robust in practice)\n",
    "    best_dbscan = balanced_score\n",
    "else:\n",
    "    print(\"\\nNo valid DBSCAN results found. Consider adjusting parameters.\")\n",
    "    best_dbscan = dbscan_results[0]  # Use first result as fallback\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}/dbscan_parameter_optimization.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0668b09",
   "metadata": {},
   "source": [
    "# 9. Reporting und Visualisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425b015",
   "metadata": {},
   "source": [
    "### 9.1 Visualisierung: K-Means & DBSCAN (Side-by-Side) mit t-SNE\n",
    " \n",
    "**Was:**  \n",
    "- berechnet ein 2D-t-SNE auf den PCA-Features (`features_pca`) mit stabilen Parametern (`init='pca'`, `learning_rate='auto'`, `dynamische Perplexity`)\n",
    "- Erstellt Side-by-Side-Visualisierung der K-Means- und DBSCAN-Zuordnungen in separaten Panels\n",
    "- Verwendet diskrete Farbkarten mit `BoundaryNorm` für saubere Cluster-Trennung und eindeutige Legendenbeschriftung\n",
    " \n",
    "**Warum:**  \n",
    "- t-SNE wird genutzt, um die 50D-PCA-Features auf 2D zu reduzieren für eine intuitive Visualisierung der Cluster-Struktur\n",
    "- Side-by-Side Vergleich ermöglicht direkten Vergleich der beiden Methoden\n",
    "- stabile Parameter ermöglichen reproduzierbare Layouts für Vergleichbarkeit\n",
    " \n",
    "**Besonderheiten:**  \n",
    "- Noise-Behandlung bei DBSCAN: Noise-Punkte (`-1`) werden explizit in grau dargestellt, reguläre Cluster erhalten `tab10`-Farben\n",
    " \n",
    "**Outputs:**  \n",
    "- Side-by-Side Plot mit t-SNE-Projektion beider Cluster\n",
    "- Erstellung der Datei `clustering_tsne_visualization_fixed.png`, die den Plot enthält\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering results with t-SNE (Fixed Colors & Legends)\n",
    "print(\"=\" * 80)\n",
    "print(\"CLUSTER VISUALIZATION WITH t-SNE (IMPROVED)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"Computing t-SNE embedding with stable parameters...\")\n",
    "N = len(features_pca)\n",
    "# Use stable t-SNE parameters for reproducible and better results\n",
    "tsne = TSNE(\n",
    "    n_components=2,\n",
    "    init='pca',  # PCA initialization for better stability\n",
    "    learning_rate='auto',  # Adaptive learning rate\n",
    "    perplexity=min(50, max(5, int(N * 0.01))),  # Dynamic perplexity based on sample size\n",
    "    max_iter=1500,  # More iterations for convergence\n",
    "    random_state=RANDOM_STATE,\n",
    "    metric='euclidean',\n",
    "    early_exaggeration=12.0\n",
    ")\n",
    "\n",
    "tsne_features = tsne.fit_transform(features_pca)\n",
    "print(f\"t-SNE completed with perplexity={tsne.perplexity}\")\n",
    "\n",
    "# Create visualization with fixed discrete colors\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# === K-MEANS PLOT WITH DISCRETE COLORS ===\n",
    "# Remap K-Means labels to 0..C-1 for consistent coloring\n",
    "unique_kmeans = sorted(set(cluster_labels))\n",
    "kmeans_label_map = {old: new for new, old in enumerate(unique_kmeans)}\n",
    "kmeans_colors = np.array([kmeans_label_map[label] for label in cluster_labels])\n",
    "\n",
    "# Create discrete colormap for K-Means\n",
    "n_kmeans_clusters = len(unique_kmeans)\n",
    "kmeans_cmap = matplotlib.colors.ListedColormap(plt.cm.tab10(np.linspace(0, 1, n_kmeans_clusters)))\n",
    "kmeans_norm = matplotlib.colors.BoundaryNorm(\n",
    "    boundaries=np.arange(-0.5, n_kmeans_clusters, 1), \n",
    "    ncolors=n_kmeans_clusters\n",
    ")\n",
    "\n",
    "scatter1 = axes[0].scatter(\n",
    "    tsne_features[:, 0],\n",
    "    tsne_features[:, 1],\n",
    "    c=kmeans_colors,\n",
    "    cmap=kmeans_cmap,\n",
    "    norm=kmeans_norm,\n",
    "    alpha=0.7,\n",
    "    s=50\n",
    ")\n",
    "axes[0].set_title(f'K-Means Clustering (k={optimal_k})\\nt-SNE Visualization')\n",
    "axes[0].set_xlabel('t-SNE Component 1')\n",
    "axes[0].set_ylabel('t-SNE Component 2')\n",
    "\n",
    "# Discrete colorbar for K-Means\n",
    "cbar1 = plt.colorbar(scatter1, ax=axes[0], ticks=range(n_kmeans_clusters))\n",
    "cbar1.set_ticklabels([f'Cluster {unique_kmeans[i]}' for i in range(n_kmeans_clusters)])\n",
    "cbar1.set_label('K-Means Clusters')\n",
    "\n",
    "# === DBSCAN PLOT WITH NOISE IN GREY ===\n",
    "dbscan_colors = best_dbscan['labels'].copy()\n",
    "unique_dbscan = sorted(set(dbscan_colors))\n",
    "n_dbscan_clusters = len(unique_dbscan) - (1 if -1 in unique_dbscan else 0)\n",
    "\n",
    "# Create color mapping: noise (-1) -> 0 (grey), clusters -> 1,2,3...\n",
    "if -1 in unique_dbscan:\n",
    "    # Noise gets grey, clusters get tab10 colors\n",
    "    colors = ['#808080']  # Grey for noise\n",
    "    colors.extend(plt.cm.tab10(np.linspace(0, 1, n_dbscan_clusters)))\n",
    "    # Map -1 to 0, others to 1,2,3...\n",
    "    dbscan_label_map = {-1: 0}\n",
    "    cluster_idx = 1\n",
    "    for label in unique_dbscan:\n",
    "        if label != -1:\n",
    "            dbscan_label_map[label] = cluster_idx\n",
    "            cluster_idx += 1\n",
    "    total_colors = len(unique_dbscan)\n",
    "else:\n",
    "    # No noise, just use tab10 for all clusters\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, n_dbscan_clusters))\n",
    "    dbscan_label_map = {label: idx for idx, label in enumerate(unique_dbscan)}\n",
    "    total_colors = n_dbscan_clusters\n",
    "\n",
    "dbscan_colors_mapped = np.array([dbscan_label_map[label] for label in dbscan_colors])\n",
    "\n",
    "# Create discrete colormap for DBSCAN\n",
    "dbscan_cmap = matplotlib.colors.ListedColormap(colors)\n",
    "dbscan_norm = matplotlib.colors.BoundaryNorm(\n",
    "    boundaries=np.arange(-0.5, total_colors, 1), \n",
    "    ncolors=total_colors\n",
    ")\n",
    "\n",
    "scatter2 = axes[1].scatter(\n",
    "    tsne_features[:, 0],\n",
    "    tsne_features[:, 1],\n",
    "    c=dbscan_colors_mapped,\n",
    "    cmap=dbscan_cmap,\n",
    "    norm=dbscan_norm,\n",
    "    alpha=0.7,\n",
    "    s=50\n",
    ")\n",
    "axes[1].set_title(f'DBSCAN Clustering (eps={best_dbscan[\"eps\"]})\\nt-SNE Visualization\\n{n_dbscan_clusters} clusters, {best_dbscan[\"n_noise\"]} noise points')\n",
    "axes[1].set_xlabel('t-SNE Component 1')\n",
    "axes[1].set_ylabel('t-SNE Component 2')\n",
    "\n",
    "# Discrete colorbar for DBSCAN\n",
    "cbar2 = plt.colorbar(scatter2, ax=axes[1], ticks=range(total_colors))\n",
    "if -1 in unique_dbscan:\n",
    "    tick_labels = ['Noise'] + [f'Cluster {i}' for i in range(n_dbscan_clusters)]\n",
    "else:\n",
    "    tick_labels = [f'Cluster {unique_dbscan[i]}' for i in range(n_dbscan_clusters)]\n",
    "cbar2.set_ticklabels(tick_labels)\n",
    "cbar2.set_label('DBSCAN Clusters')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}/clustering_tsne_visualization_fixed.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed364d",
   "metadata": {},
   "source": [
    "### 9.2 K-Nearest Neighbor Grafik bei DBSCAN\n",
    " \n",
    "**Was:**  \n",
    "- Berechnet für jeden Datenpunkt die Distanz zum k-ten nächsten Nachbarn (k = `best_dbscan['min_samples']`) auf den PCA-Features\n",
    "- Sortiert diese k-Distanzen absteigend und visualisiert sie als Kurve (K-Distance Plot)\n",
    "- Überlagert horizontale Referenzlinien für das gewählte best_eps (rot) und andere getestete Epsilon-Werte (grau)\n",
    " \n",
    "**Warum:**  \n",
    "- Visuelle Epsilon-Validierung: Der Plot zeigt, ob das automatisch gewählte eps am \"Elbow\" (Knick) der Kurve liegt\n",
    "- Datengetriebene Parameter-Wahl: Ergänzt die Grid-Search um eine theoretisch fundierte Visualisierung der Dichteverteilung\n",
    "- Core-Point-Analyse: Punkte oberhalb der eps-Linie werden zu Core-Points → Einschätzung der Cluster-Dichte\n",
    " \n",
    "**Besonderheiten:**  \n",
    "- Gelber Bereich (5%-20% der sortierten Punkte) zeigt die typische Knick-Zone\n",
    "- Zählt Punkte oberhalb des gewählten eps als potentielle Core-Points zur quantitativen Analyse\n",
    "- Zeigt mehrere eps-Kandidaten zur Orientierung (0.3, 0.5, 0.7, 1.0)\n",
    " \n",
    "**Outputs:**\n",
    "- Plot: `dbscan_k_distance.png` mit sortierter k-Distanz-Kurve und eps-Referenzlinien\n",
    "- Konsolen-Analyse: Interpretation des gewählten eps und Anzahl potentieller Core-Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f769519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Distance Plot for DBSCAN Parameter Guidance\n",
    "print(\"=\" * 80)\n",
    "print(\"K-DISTANCE PLOT FOR DBSCAN EPS SELECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Use the min_samples from best DBSCAN result\n",
    "k = best_dbscan['min_samples']\n",
    "print(f\"Computing {k}-distance plot for eps guidance...\")\n",
    "\n",
    "# Fit NearestNeighbors on PCA features\n",
    "neighbors = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
    "neighbors.fit(features_pca)\n",
    "\n",
    "# Get distances to k-th nearest neighbor for each point\n",
    "distances, indices = neighbors.kneighbors(features_pca)\n",
    "k_distances = distances[:, k-1]  # k-th distance (0-indexed)\n",
    "\n",
    "# Sort distances in descending order\n",
    "k_distances_sorted = np.sort(k_distances)[::-1]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(k_distances_sorted)), k_distances_sorted, 'b-', linewidth=1)\n",
    "plt.axhline(y=best_dbscan['eps'], color='red', linestyle='--', \n",
    "           label=f'Best eps = {best_dbscan[\"eps\"]}')\n",
    "\n",
    "# Add some reference lines for other tested eps values\n",
    "for eps in [0.3, 0.5, 0.7, 1.0]:\n",
    "    if eps != best_dbscan['eps']:\n",
    "        plt.axhline(y=eps, color='grey', linestyle=':', alpha=0.5, \n",
    "                   label=f'eps = {eps}')\n",
    "\n",
    "plt.xlabel('Points sorted by distance')\n",
    "plt.ylabel(f'{k}-th Nearest Neighbor Distance')\n",
    "plt.title(f'K-Distance Plot (k={k}) for DBSCAN eps Selection')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Highlight the \"elbow\" region\n",
    "elbow_start = int(len(k_distances_sorted) * 0.05)\n",
    "elbow_end = int(len(k_distances_sorted) * 0.20)\n",
    "plt.axvspan(elbow_start, elbow_end, alpha=0.2, color='yellow', \n",
    "           label='Typical elbow region')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}/dbscan_k_distance.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nK-Distance Plot Analysis:\")\n",
    "print(f\"- Red line shows selected eps = {best_dbscan['eps']}\")\n",
    "print(f\"- Look for 'elbow' in the curve to find optimal eps\")\n",
    "print(f\"- Steep increase indicates good density separation\")\n",
    "print(f\"- Current eps captures {np.sum(k_distances_sorted >= best_dbscan['eps'])} points as potential core points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85c838f",
   "metadata": {},
   "source": [
    "### 10. Cluster-Ergebnisse speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8eea9e",
   "metadata": {},
   "source": [
    "#### 10.1 Speicher-Helfer definieren (Ordner/Bildkopie/Metadaten)\n",
    " \n",
    "**Was:**  \n",
    "- es werden drei Hilfsfunktionen für die Speicherung der Cluster-Ergebnisse definiert\n",
    "- `create_cluster_directories()`: Legt strukturierte Ordnerhierarchie an (`method_name/cluster_<id>/` bzw. `noise/` für DBSCAN)\n",
    "- `copy_images_to_clusters()`: Kopiert Originalbilder in ihre jeweiligen Cluster-Ordner mit Duplikatsvermeidung\n",
    "- `save_cluster_metadata()`: Erstellt detaillierte JSON-Metadaten pro Cluster mit Tenant-Statistiken und Bildlisten\n",
    " \n",
    "**Warum:**  \n",
    "- Clustering-Ergebnisse werden dauerhaft und strukturiert gespeichert für spätere Analyse\n",
    "- Bilder werden nach Clustern sortiert → vereinfacht manuelle Inspektion und Qualitätskontrolle der Clustering Verfahren\n",
    "- JSON-File dokumentiert Cluster-Zusammensetzung, Tenant-Verteilung und verwendete Methodik\n",
    "- Separierte Cluster ermöglichen gezielte Weiterverarbeitung einzelner Gruppen, hierdurch ist ein Labeln der Cluster einfach möglich, um eine spätere Klassifizierung von neuen Daten vornehmen zu können\n",
    " \n",
    "**Besonderheiten:**  \n",
    "- Ordner-Erstellung und Dateikopien überschreiben nicht bei identischen Dateien (Größenvergleich)\n",
    "- Noise-Punkte (`-1`) werden speziell im noise/-Ordner gesammelt, reguläre Cluster in `cluster_<id>/`\n",
    "- Unterstützt sowohl K-Means (`cluster_labels`) als auch DBSCAN (`dbscan_labels`) Parameter\n",
    " \n",
    "**Outputs:**  \n",
    "- Ordner mit kopierten Originalbildern im festgelegten Dateipfad: `{base_path}/{method_name}/cluster_<id>/`\n",
    "- Metadaten Dateien je Cluster mit Angabe der `cluster_id`, `total_images`, `tenant_distribution` und den Details der Bilder\n",
    "- Erstellung von Statistiken zur Anzahl der erfolgreichen Kopien, Anzahl der Fehler (wenn vorhanden) und die Größe der Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b38cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_directories(base_path, method_name, cluster_labels, dbscan_labels=None):\n",
    "    \"\"\"Create directory structure for clustered images.\"\"\"\n",
    "    method_path = Path(base_path) / method_name\n",
    "    method_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    if method_name == 'kmeans':\n",
    "        unique_clusters = sorted(set(cluster_labels))\n",
    "    else:  # dbscan\n",
    "        unique_clusters = sorted(set(dbscan_labels))\n",
    "        # Handle noise points (-1) separately\n",
    "        if -1 in unique_clusters:\n",
    "            unique_clusters = [c for c in unique_clusters if c != -1] + [-1]\n",
    "    \n",
    "    cluster_dirs = {}\n",
    "    for cluster_id in unique_clusters:\n",
    "        if cluster_id == -1:\n",
    "            cluster_dir = method_path / 'noise'\n",
    "        else:\n",
    "            cluster_dir = method_path / f'cluster_{cluster_id}'\n",
    "        cluster_dir.mkdir(exist_ok=True)\n",
    "        cluster_dirs[cluster_id] = cluster_dir\n",
    "    \n",
    "    return cluster_dirs\n",
    "\n",
    "def copy_images_to_clusters(image_files, cluster_dirs, cluster_labels, method_name='kmeans', dbscan_labels=None):\n",
    "    \"\"\"Copy images to their respective cluster directories.\"\"\"\n",
    "    print(f\"\\nCopying images to {method_name.upper()} cluster directories...\")\n",
    "    \n",
    "    if method_name == 'kmeans':\n",
    "        labels_to_use = cluster_labels\n",
    "    else:  # dbscan\n",
    "        labels_to_use = dbscan_labels\n",
    "    \n",
    "    copied_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for i, img_file in enumerate(image_files):\n",
    "        try:\n",
    "            cluster_id = labels_to_use[i]\n",
    "            source_path = Path(img_file['filepath'])\n",
    "            target_dir = cluster_dirs[cluster_id]\n",
    "            target_path = target_dir / source_path.name\n",
    "            \n",
    "            # Copy file if it doesn't exist or is different\n",
    "            if not target_path.exists() or target_path.stat().st_size != source_path.stat().st_size:\n",
    "                shutil.copy2(source_path, target_path)\n",
    "                copied_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error copying {img_file['filename']}: {e}\")\n",
    "            error_count += 1\n",
    "    \n",
    "    print(f\"Successfully copied {copied_count} images\")\n",
    "    if error_count > 0:\n",
    "        print(f\"Errors: {error_count}\")\n",
    "    \n",
    "    return copied_count, error_count\n",
    "\n",
    "def save_cluster_metadata(cluster_dirs, image_files, cluster_labels, method_name='kmeans', dbscan_labels=None):\n",
    "    \"\"\"Save metadata for each cluster.\"\"\"\n",
    "    print(f\"\\nSaving {method_name.upper()} cluster metadata...\")\n",
    "    \n",
    "    if method_name == 'kmeans':\n",
    "        labels_to_use = cluster_labels\n",
    "    else:  # dbscan\n",
    "        labels_to_use = dbscan_labels\n",
    "    \n",
    "    for cluster_id, cluster_dir in cluster_dirs.items():\n",
    "        # Get images for this cluster\n",
    "        cluster_images = []\n",
    "        for i, img_file in enumerate(image_files):\n",
    "            if int(labels_to_use[i]) == cluster_id:  # Convert numpy int32 to Python int\n",
    "                cluster_images.append({\n",
    "                    'filename': img_file['filename'],\n",
    "                    'tenant': img_file['tenant'],\n",
    "                    'sid': img_file['sid'],\n",
    "                    'original_name': img_file['original_name']\n",
    "                })\n",
    "        \n",
    "        # Calculate statistics\n",
    "        tenant_counts = Counter([img['tenant'] for img in cluster_images])\n",
    "        \n",
    "        metadata = {\n",
    "            'cluster_id': int(cluster_id) if isinstance(cluster_id, (np.integer, np.int32, np.int64)) else cluster_id,  # Ensure cluster_id is JSON serializable\n",
    "            'method': method_name,\n",
    "            'total_images': len(cluster_images),\n",
    "            'tenant_distribution': dict(tenant_counts),\n",
    "            'images': cluster_images\n",
    "        }\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_file = cluster_dir / 'cluster_metadata.json'\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"Metadata saved for {len(cluster_dirs)} clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92707b",
   "metadata": {},
   "source": [
    "#### 10.2 K-Means-Cluster speichern (Ausführung)\n",
    " \n",
    "**Was:**  \n",
    "- Führt die K-Means-Cluster-Speicherung mit den in Abschnitt 10.1 definierten Hilfsfunktionen aus\n",
    "- erstellt je gefundenem Cluster einen Ordner in der definierten Ordnerstruktur\n",
    "- generiert die zuvor definierten Statistiken als JSON-Datei\n",
    " \n",
    "**Warum:**  \n",
    "- vereinfachte visuelle Kontrolle\n",
    "- persistente Archivierung zur späteren Analyse\n",
    "- gezielte Weiterverarbeitung\n",
    "- direkte Vergleiche mit vorherigen Läufen durch Anlage der Ordnerstruktur inklusive Timestamp\n",
    " \n",
    "**Besonderheiten:**  \n",
    "- Zeitstempel-basierte Pfade für eindeutige Versionierung\n",
    "- Ausgabe von detaillierten Statistiken und Fehler-Tracking\n",
    " \n",
    "**Outputs:**  \n",
    "- kopierte Originalbilder in der gewählten Ordnerstruktur `{CLUSTERS_PATH}/kmeans/cluster_<0..k-1>/`\n",
    "- Metadaten Datei `cluster_metadata.json` für jedes Cluster\n",
    "- Anzeige der Anzahl erstellter Ordner, Cluster-Größen und Kopierstatistiken (Erfolg/Fehler)\n",
    "- Nennung des Speicherorts als Bestätigung `./results_{TIMESTAMP}/clustered_images/kmeans/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9463811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save K-Means clustering results to timestamped directories\n",
    "print(\"=\" * 80)\n",
    "print(\"SAVING K-MEANS CLUSTERS TO TIMESTAMPED DIRECTORIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Using timestamped cluster directory: {CLUSTERS_PATH}\")\n",
    "\n",
    "# Create K-Means cluster directories\n",
    "kmeans_dirs = create_cluster_directories(CLUSTERS_PATH, 'kmeans', cluster_labels)\n",
    "\n",
    "print(f\"Created K-Means cluster directories:\")\n",
    "for cluster_id, cluster_dir in sorted(kmeans_dirs.items()):\n",
    "    cluster_size = sum(1 for label in cluster_labels if label == cluster_id)\n",
    "    print(f\"  {cluster_dir.name}: {cluster_size} images\")\n",
    "\n",
    "# Copy images to K-Means clusters\n",
    "kmeans_copied, kmeans_errors = copy_images_to_clusters(\n",
    "    image_files, kmeans_dirs, cluster_labels, 'kmeans'\n",
    ")\n",
    "\n",
    "# Save K-Means cluster metadata\n",
    "save_cluster_metadata(kmeans_dirs, image_files, cluster_labels, 'kmeans')\n",
    "\n",
    "print(f\"\\nK-Means clustering results saved to: {Path(CLUSTERS_PATH) / 'kmeans'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebeb588",
   "metadata": {},
   "source": [
    "#### 10.3 DBSCAN-Cluster speichern (Ausführung)\n",
    " \n",
    "**Was:**  \n",
    "- Führt die DBSCAN-Cluster-Speicherung mit den in Abschnitt 10.1 definierten Hilfsfunktionen aus\n",
    "- erstellt je gefundenem Cluster einen Ordner in der definierten Ordnerstruktur, zusätzlich wird ein Ordner für die noise Punkte eingeführt\n",
    "- generiert die zuvor definierten Statistiken als JSON-Datei\n",
    " \n",
    "**Warum:**  \n",
    "- Ermöglichung der Analyse anomaler Bilder zur Identifizierung von Ausreißern\n",
    "- manuelle Überprüfung der dichtebasierten Gruppierung\n",
    "- direkter Vergleich beider Clustering Ansätze möglich\n",
    " \n",
    "**Besonderheiten:**  \n",
    "- Nutzt die \"balanced score\" Parameterwahl (`silhouette * (1 - noise_ratio)`) statt reiner Silhouette-Optimierung\n",
    " \n",
    "**Outputs:**  \n",
    "- kopierte Originalbilder in der gewählten Ordnerstruktur `{CLUSTERS_PATH}/dbscan/cluster_<0..n>/` + `noise/`\n",
    "- Metadaten Datei `cluster_metadata.json` für jedes Cluster\n",
    "- Anzeige der Anzahl erstellter Ordner, Cluster-Größen und Kopierstatistiken (Erfolg/Fehler)\n",
    "- Nennung des Speicherorts als Bestätigung `./results_{TIMESTAMP}/clustered_images/dbscan/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311dcbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DBSCAN clustering results to timestamped directories\n",
    "print(\"=\" * 80)\n",
    "print(\"SAVING DBSCAN CLUSTERS TO TIMESTAMPED DIRECTORIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"Using timestamped cluster directory: {CLUSTERS_PATH}\")\n",
    "\n",
    "# Add DBSCAN cluster labels to image files for consistency\n",
    "dbscan_labels = best_dbscan['labels']\n",
    "for i, img_file in enumerate(image_files):\n",
    "    img_file['dbscan_cluster'] = int(dbscan_labels[i])\n",
    "\n",
    "# Create DBSCAN cluster directories\n",
    "dbscan_dirs = create_cluster_directories(CLUSTERS_PATH, 'dbscan', None, dbscan_labels)\n",
    "\n",
    "print(f\"Created DBSCAN cluster directories:\")\n",
    "for cluster_id, cluster_dir in sorted(dbscan_dirs.items()):\n",
    "    cluster_size = sum(1 for label in dbscan_labels if label == cluster_id)\n",
    "    if cluster_id == -1:\n",
    "        print(f\"  {cluster_dir.name} (noise): {cluster_size} images\")\n",
    "    else:\n",
    "        print(f\"  {cluster_dir.name}: {cluster_size} images\")\n",
    "\n",
    "# Copy images to DBSCAN clusters\n",
    "dbscan_copied, dbscan_errors = copy_images_to_clusters(\n",
    "    image_files, dbscan_dirs, None, 'dbscan', dbscan_labels\n",
    ")\n",
    "\n",
    "# Save DBSCAN cluster metadata\n",
    "save_cluster_metadata(dbscan_dirs, image_files, None, 'dbscan', dbscan_labels)\n",
    "\n",
    "print(f\"\\nDBSCAN clustering results saved to: {Path(CLUSTERS_PATH) / 'dbscan'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde73ad7",
   "metadata": {},
   "source": [
    "### 11. Tenant-Cluster-Analyse (Heatmap & Detailstatistik)\n",
    "**Was:**  \n",
    "- Baut eine Tenant×Cluster-Matrix auf mit zeilenweiser Normalisierung und berechnet Prozentanteile je Tenant pro Cluster\n",
    "- Erstellt eine Seaborn-Heatmap (`sns.heatmap`) mit Zellbeschriftung und `YlOrRd`-Farbskala zur Visualisierung der Verteilungen\n",
    " \n",
    "**Warum:**  \n",
    "- Identifiziert tenant-spezifische Clustering-Muster. Zeigt an, ob bestimmte Verkehrsunternehmen charakteristische Untergrund-/Situationstypen aufweisen\n",
    "- Starke Ungleichverteilungen können auf systematische Bias oder domänenspezifische Besonderheiten hinweisen\n",
    "- Visualisiert, ob das Clustering echte visueller Muster oder nur tenant-basierte Artefakte erfasst hat\n",
    " \n",
    "**Outputs:**  \n",
    "- Heatmap-Grafik: `tenant_cluster_heatmap.png` in `RESULTS_PATH` mit prozentualer Tenant-Verteilung über alle Cluster\n",
    "- Konsolen-Report: Detaillierte Aufschlüsselung je Tenant mit Gesamtzahl und clusterspezifischen Prozent-/Absolutwerten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028b316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tenant distribution across clusters\n",
    "print(\"=\" * 80)\n",
    "print(\"TENANT DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create tenant-cluster matrix\n",
    "tenant_cluster_matrix = defaultdict(lambda: defaultdict(int))\n",
    "total_by_tenant = defaultdict(int)\n",
    "\n",
    "for img_file in image_files:\n",
    "    tenant = img_file['tenant']\n",
    "    cluster = img_file['cluster']\n",
    "    tenant_cluster_matrix[tenant][cluster] += 1\n",
    "    total_by_tenant[tenant] += 1\n",
    "\n",
    "# Convert to DataFrame for easier visualization\n",
    "tenants = sorted(total_by_tenant.keys())\n",
    "clusters = sorted(set(cluster_labels))\n",
    "\n",
    "matrix_data = []\n",
    "for tenant in tenants:\n",
    "    row = []\n",
    "    for cluster in clusters:\n",
    "        count = tenant_cluster_matrix[tenant][cluster]\n",
    "        percentage = (count / total_by_tenant[tenant]) * 100\n",
    "        row.append(percentage)\n",
    "    matrix_data.append(row)\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "heatmap_data = np.array(matrix_data)\n",
    "sns.heatmap(\n",
    "    heatmap_data,\n",
    "    xticklabels=[f'Cluster {c}' for c in clusters],\n",
    "    yticklabels=tenants,\n",
    "    annot=True,\n",
    "    fmt='.1f',\n",
    "    cmap='YlOrRd',\n",
    "    cbar_kws={'label': 'Percentage of Tenant Images'}\n",
    ")\n",
    "plt.title('Tenant Distribution Across Clusters (%)')\n",
    "plt.xlabel('Clusters')\n",
    "plt.ylabel('Tenants')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{RESULTS_PATH}/tenant_cluster_heatmap.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\nDetailed Tenant-Cluster Distribution:\")\n",
    "for tenant in tenants:\n",
    "    print(f\"\\n{tenant} ({total_by_tenant[tenant]} images):\")\n",
    "    for cluster in clusters:\n",
    "        count = tenant_cluster_matrix[tenant][cluster]\n",
    "        percentage = (count / total_by_tenant[tenant]) * 100\n",
    "        if count > 0:\n",
    "            print(f\"  Cluster {cluster}: {count} images ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965da81",
   "metadata": {},
   "source": [
    "### 12. Clustering-Report (JSON) erstellen & Kernergebnisse ausgeben\n",
    "**Was:**  \n",
    "- erstellt `clustering_report.json` mit Zeitstempel-Informationen, Run-Metadaten und vollständigen Clustering-Ergebnissen\n",
    "- Sammelt Dataset-Info (Bildanzahl, Feature-Dimension, PCA-Varianz), K-Means-Resultate (optimal_k, Silhouette-Scores, Evaluation-Historie) und DBSCAN-Parameter\n",
    "- Integriert Tenant-Cluster-Analyse mit detaillierter Verteilungsmatrix pro Tenant über alle Cluster\n",
    " \n",
    "**Warum:**  \n",
    "- Alle Parameter, Metriken und Ergebnisse werden zentral für Nachvollziehbarkeit und Vergleichbarkeit archiviert\n",
    "- Run-spezifische Metadaten ermöglichen systematische Analyse von Clustering-Stabilität über mehrere Läufe\n",
    "- Parallele Dokumentation von K-Means und DBSCAN erleichtert objektive Bewertung beider Ansätze\n",
    "- Geschäftsspezifische Analyse zeigt, ob Clustering domänenrelevante Muster (Verkehrsunternehmen) erfasst\n",
    " \n",
    "**Outputs:**  \n",
    "- JSON-Report `clustering_report.json` in `RESULTS_PATH` mit vollständiger Run-Dokumentation und Parametern\n",
    "- Kompakte Übersicht mit Timestamp, optimalen Parametern, Cluster-/Noise-Anzahlen und PCA-Varianz in der Ausgabe\n",
    "- Absolute Pfade zu Analysis- und Cluster-Verzeichnissen für einfache Navigation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c4e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive clustering report with timestamp info\n",
    "print(\"=\" * 80)\n",
    "print(\"TIMESTAMPED CLUSTERING ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Compile results with timestamp information\n",
    "clustering_report = {\n",
    "    'run_info': {\n",
    "        'timestamp': TIMESTAMP,\n",
    "        'run_date': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'analysis_results_path': str(Path(RESULTS_PATH).resolve()),\n",
    "        'clustered_images_path': str(Path(CLUSTERS_PATH).resolve())\n",
    "    },\n",
    "    'dataset_info': {\n",
    "        'total_images': int(len(image_files)),\n",
    "        'feature_dimension': int(FEATURE_DIM),\n",
    "        'pca_components': int(PCA_COMPONENTS),\n",
    "        'pca_explained_variance': float(pca.explained_variance_ratio_.sum()),\n",
    "        'tenant_distribution': {k: int(v) for k, v in tenant_distribution.items()}\n",
    "    },\n",
    "    'kmeans_results': {\n",
    "        'optimal_k': int(optimal_k),\n",
    "        'silhouette_score': float(silhouette_scores[best_silhouette_idx]),\n",
    "        'cluster_sizes': {int(k): int(v) for k, v in Counter(cluster_labels).items()},\n",
    "        'evaluation_results': [\n",
    "            {\n",
    "                'k': int(r['k']),\n",
    "                'inertia': float(r['inertia']),\n",
    "                'silhouette_score': float(r['silhouette_score'])\n",
    "            } for r in kmeans_results\n",
    "        ]\n",
    "    },\n",
    "    'dbscan_results': {\n",
    "        'best_eps': float(best_dbscan['eps']),\n",
    "        'min_samples': int(best_dbscan['min_samples']),\n",
    "        'n_clusters': int(best_dbscan['n_clusters']),\n",
    "        'n_noise': int(best_dbscan['n_noise']),\n",
    "        'silhouette_score': float(best_dbscan['silhouette_score'])\n",
    "    },\n",
    "    'tenant_cluster_analysis': {\n",
    "        tenant: {\n",
    "            'total_images': int(total_by_tenant[tenant]),\n",
    "            'cluster_distribution': {int(k): int(v) for k, v in tenant_cluster_matrix[tenant].items()}\n",
    "        } for tenant in tenants\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results to timestamped directory\n",
    "with open(f\"{RESULTS_PATH}/clustering_report.json\", 'w') as f:\n",
    "    json.dump(clustering_report, f, indent=2)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Analysis completed successfully!\")\n",
    "print(f\"\\nRun Information:\")\n",
    "print(f\"- Timestamp: {TIMESTAMP}\")\n",
    "print(f\"- Analysis results saved to: {RESULTS_PATH}\")\n",
    "print(f\"- Clustered images saved to: {CLUSTERS_PATH}\")\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"- Optimal number of clusters (K-Means): {optimal_k}\")\n",
    "print(f\"- Best silhouette score: {silhouette_scores[best_silhouette_idx]:.4f}\")\n",
    "print(f\"- DBSCAN found {best_dbscan['n_clusters']} clusters with {best_dbscan['n_noise']} noise points\")\n",
    "print(f\"- PCA captured {pca.explained_variance_ratio_.sum():.1%} of the variance\")\n",
    "\n",
    "print(f\"\\nCluster sizes (K-Means):\")\n",
    "cluster_sizes = Counter(cluster_labels)\n",
    "for cluster_id, size in sorted(cluster_sizes.items()):\n",
    "    percentage = (size / len(cluster_labels)) * 100\n",
    "    print(f\"  Cluster {cluster_id}: {size} images ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf527b3a",
   "metadata": {},
   "source": [
    "## 13. Ergebnisse der Clustering Phase\n",
    " \n",
    "- Das dichtebasierte Cluster mit DBSCAN konnte keinen zuverlässigen Erfolg liefern, trotz vielfacher Anpassung der Parameter.\n",
    "- Die Ergebnisse über die K-Means-Methode waren zufriedenstellend.\n",
    "- Die Ergebnisse der Cluster wurden mit drei unterschiedlichen Metriken bewertet. Neben den gezeigten Metriken wurden in einer separaten Analyse weitere Cluster-Gütemaße evaluiert, diese Ergebnisse sind in diesem Notebook noch nicht enthalten. Konkret kamen der Silhouette Score, der Davies–Bouldin Index und der Calinski–Harabasz Index zum Einsatz. Für Hintergrund und einen vergleichenden Überblick siehe: Arbelaitz et al. (2013).\n",
    "- Es wurde versucht mit Hilfe von einer Bildvorverarbeitung die Bilder vorzuverarbeiten, um z.B. dunkle Bilder aufzuhellen. Dies wurde im Schritt 5.1 optional in diesem Notebook eingebaut. Es konnte allerdings kein nennenswerter Effekt bzw. Verschlechterungen festgestellt werden, weshalb wir uns im folgenden dazu entschieden haben keine Bildvorverarbeitung vorzunehmen.\n",
    "- Zusätzlich wurden folgende Konfigurationen getestet. Diese Ergebnisse sind in diesem Notebook noch nicht enthalten.\n",
    "    - Feature-Extraction-Model: ResNet50,VGG16\n",
    "    - je Modell verschiedene Layer im Model:\n",
    "    `\n",
    "    'levels': {\n",
    "            'top': {'pooling': 'avg', 'layer': None},\n",
    "            'mid': {'layer': 'conv4_block6_out'/'block4_conv3'}\n",
    "            'low': {'layer': 'conv3_block4_out'/'block2_conv2'}\n",
    "        }\n",
    "    ` \n",
    "- Als beste Konfiguration hat sich das ResNet50 mit conv4_block6_out als Layer und keiner Bildvorverarbeitung herausgestellt.\n",
    "    - Die Ergebnisse aller Experimente sind in der mitgeschickten results.json.\n",
    "- Es wurden zwei Clustering Läufe mit jeweils 10.000 Bildern initialisiert (also insgesamt 20.000 unterschiedlichen Bildern). Ein Test mit 50.000 Bildern führte zu nicht plausiblen Clustern mit K-Means und wurde deshalb verworfen. Eine Analyse, weshalb der Lauf mit 50.000 Bildern nicht funktionierte wurde nicht angestrebt, da ein Clustering mit 20.000 Bildern für unsere Zwecke vollkommen ausreichend ist.\n",
    "- Die entstandenen 5 Cluster wurden anschließend manuell gesichtet und bereinigt. Es wurden folgende fünf Klassen identifiziert:\n",
    "    - Beton/Asphalt\n",
    "    - Gras/natürliche Untergründe (z.B. auch Laub)\n",
    "    - Schotter\n",
    "    - Stein (verschiedene Pflaster-Arten)\n",
    "    - Messfehler (zu dunkle Bilder, verrauschte Bilder)\n",
    "- Während der Bereinigung wurden fehlerhaft zugeordnete Bilder manuell entfernt, bevor ein Training des Klassifizierungsmodell stattfindet. Die entfernten Bilder wurden gesammelt und können somit später als Spezialfälle gesondert analysiert werden.\n",
    "- Das Ziel durch das Clustering die Daten zu sortieren und für das Labeling vorzubereiten konnte dadurch erreicht werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
