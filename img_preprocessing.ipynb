{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0b1f4f",
   "metadata": {},
   "source": [
    "# Railway Image Preprocessing Analysis\n",
    "\n",
    "This notebook applies 5 different preprocessing techniques to a folder of railway images and analyzes the results.\n",
    "\n",
    "## Analysis Goals:\n",
    "- **Batch Processing**: Apply preprocessing to multiple images from a folder\n",
    "- **Method Comparison**: Compare 5 different preprocessing techniques\n",
    "- **Visual Analysis**: Display example images and their preprocessing results\n",
    "- **Result Storage**: Save processed images for further analysis\n",
    "\n",
    "## Preprocessing Methods:\n",
    "1. **Histogram Equalization** - Enhances contrast\n",
    "2. **CLAHE** - Adaptive histogram equalization\n",
    "3. **Gamma Correction** - Brightens dark regions\n",
    "4. **Unsharp Masking** - Enhances edge details\n",
    "5. **Edge Enhancement** - Highlights structural boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc3a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom preprocessing class\n",
    "from img_preprocessing import ImagePreprocessor\n",
    "\n",
    "# Set matplotlib style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(\"ImagePreprocessor class imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ddd694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "INPUT_FOLDER = \"./datasets/clustering_sample_100\"  # Input folder with images\n",
    "OUTPUT_FOLDER = \"./results_img_pp\"                  # Output folder for processed images\n",
    "IMG_SIZE = (224, 224)                               # Standard image size\n",
    "RANDOM_SEED = 42\n",
    "EXAMPLE_COUNT = 4                                   # Number of example images to visualize\n",
    "\n",
    "# Set random seed\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"Input folder: {INPUT_FOLDER}\")\n",
    "print(f\"Output folder: {OUTPUT_FOLDER}\")\n",
    "print(f\"Target image size: {IMG_SIZE}\")\n",
    "print(f\"Example images to show: {EXAMPLE_COUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad51152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory structure\n",
    "def create_output_directories(base_output_path: str):\n",
    "    \"\"\"Create directory structure for processed images.\"\"\"\n",
    "    methods = ['original', 'hist_eq', 'clahe', 'gamma', 'unsharp', 'edge_enhanced']\n",
    "    \n",
    "    directories = {}\n",
    "    for method in methods:\n",
    "        method_dir = Path(base_output_path) / method\n",
    "        method_dir.mkdir(parents=True, exist_ok=True)\n",
    "        directories[method] = method_dir\n",
    "    \n",
    "    return directories\n",
    "\n",
    "# Create output directories\n",
    "output_dirs = create_output_directories(OUTPUT_FOLDER)\n",
    "print(\"Created output directories:\")\n",
    "for method, directory in output_dirs.items():\n",
    "    print(f\"  {method}: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee910b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_data(image_path: str, target_size: tuple = IMG_SIZE):\n",
    "    \"\"\"\n",
    "    Load and prepare image data.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "        target_size: Target size for resizing (width, height)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing image data and statistics\n",
    "    \"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Load original image\n",
    "        img_pil = Image.open(image_path)\n",
    "        img_original = np.array(img_pil)\n",
    "        \n",
    "        # Resize image\n",
    "        img_pil_resized = img_pil.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        img_resized = np.array(img_pil_resized)\n",
    "        \n",
    "        # Convert to grayscale for statistics\n",
    "        if len(img_resized.shape) == 3:\n",
    "            img_gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)\n",
    "        else:\n",
    "            img_gray = img_resized\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            'mean_intensity': np.mean(img_gray),\n",
    "            'std_intensity': np.std(img_gray),\n",
    "            'min_intensity': np.min(img_gray),\n",
    "            'max_intensity': np.max(img_gray),\n",
    "            'brightness_category': 'dark' if np.mean(img_gray) < 85 else 'medium' if np.mean(img_gray) < 170 else 'bright'\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'resized': img_resized,\n",
    "            'gray': img_gray,\n",
    "            'stats': stats,\n",
    "            'filename': Path(image_path).name, \n",
    "            'path': image_path\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all_preprocessing_methods(img_data):\n",
    "    \"\"\"\n",
    "    Apply all 5 preprocessing methods to the input image.\n",
    "    \n",
    "    Args:\n",
    "        img_data: Dictionary containing image data\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing all preprocessed versions\n",
    "    \"\"\"\n",
    "    if img_data is None:\n",
    "        return None\n",
    "        \n",
    "    img = img_data['resized']\n",
    "    \n",
    "    try:\n",
    "        methods = {\n",
    "            'original': img,\n",
    "            'hist_eq': ImagePreprocessor.method_1_histogram_equalization(img),\n",
    "            'clahe': ImagePreprocessor.method_2_clahe(img),\n",
    "            'gamma': ImagePreprocessor.method_3_gamma_correction(img, gamma=0.7),\n",
    "            'unsharp': ImagePreprocessor.method_4_unsharp_masking(img),\n",
    "            'edge_enhanced': ImagePreprocessor.method_5_edge_enhancement(img)\n",
    "        }\n",
    "        return methods\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_data['filename']}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c804006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_image(processed_img, output_path: str):\n",
    "    \"\"\"Save processed image to output path.\"\"\"\n",
    "    try:\n",
    "        if len(processed_img.shape) == 2:  # Grayscale\n",
    "            img_pil = Image.fromarray(processed_img, mode='L')\n",
    "        else:  # RGB\n",
    "            img_pil = Image.fromarray(processed_img, mode='RGB')\n",
    "        \n",
    "        img_pil.save(output_path, 'PNG')\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {output_path}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ed800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze input images\n",
    "print(\"=\" * 80)\n",
    "print(\"LOADING INPUT IMAGES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if not os.path.exists(INPUT_FOLDER):\n",
    "    print(f\"Error: Input folder {INPUT_FOLDER} does not exist!\")\n",
    "    print(\"Available dataset directories:\")\n",
    "    datasets_dir = Path(\"./datasets\")\n",
    "    if datasets_dir.exists():\n",
    "        for subdir in datasets_dir.iterdir():\n",
    "            if subdir.is_dir():\n",
    "                img_count = len([f for f in subdir.iterdir() if f.suffix == '.png'])\n",
    "                print(f\"  {subdir.name}: {img_count} images\")\n",
    "else:\n",
    "    # Get all image files\n",
    "    image_files = [f for f in Path(INPUT_FOLDER).iterdir() if f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n",
    "    print(f\"Found {len(image_files)} images in {INPUT_FOLDER}\")\n",
    "    \n",
    "    # Select random sample for examples\n",
    "    if len(image_files) > 0:\n",
    "        example_files = random.sample(image_files, min(EXAMPLE_COUNT, len(image_files)))\n",
    "        print(f\"Selected {len(example_files)} example images for visualization\")\n",
    "        \n",
    "        # Show selected examples\n",
    "        print(\"\\nExample images:\")\n",
    "        for i, img_file in enumerate(example_files, 1):\n",
    "            print(f\"  {i}. {img_file.name}\")\n",
    "    else:\n",
    "        print(\"No images found in input folder!\")\n",
    "        example_files = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5f5e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize example images with their statistics\n",
    "def visualize_example_images(image_files):\n",
    "    \"\"\"Visualize example images and their basic statistics.\"\"\"\n",
    "    if not image_files:\n",
    "        print(\"No images to visualize.\")\n",
    "        return\n",
    "    \n",
    "    n_images = len(image_files)\n",
    "    fig, axes = plt.subplots(2, n_images, figsize=(5*n_images, 10))\n",
    "    if n_images == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    for i, img_file in enumerate(image_files):\n",
    "        img_data = load_image_data(str(img_file))\n",
    "        if img_data is None:\n",
    "            continue\n",
    "            \n",
    "        stats = img_data['stats']\n",
    "        \n",
    "        # Show image\n",
    "        axes[0, i].imshow(img_data['resized'])\n",
    "        axes[0, i].set_title(f\"{img_data['filename']}\\nBrightness: {stats['brightness_category']}\")\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Show histogram\n",
    "        axes[1, i].hist(img_data['gray'].flatten(), bins=50, alpha=0.7, color='blue')\n",
    "        axes[1, i].axvline(stats['mean_intensity'], color='red', linestyle='--', \n",
    "                          label=f\"Mean: {stats['mean_intensity']:.1f}\")\n",
    "        axes[1, i].set_xlabel('Pixel Intensity')\n",
    "        axes[1, i].set_ylabel('Frequency')\n",
    "        axes[1, i].set_title(f'Histogram (Mean: {stats[\"mean_intensity\"]:.1f})')\n",
    "        axes[1, i].legend()\n",
    "        axes[1, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if example_files:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"VISUALIZING EXAMPLE IMAGES\")\n",
    "    print(\"=\" * 80)\n",
    "    visualize_example_images(example_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2bb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate preprocessing methods on one example\n",
    "def visualize_preprocessing_methods(img_data):\n",
    "    \"\"\"Visualize all preprocessing methods side by side.\"\"\"\n",
    "    if img_data is None:\n",
    "        return\n",
    "        \n",
    "    processed_images = apply_all_preprocessing_methods(img_data)\n",
    "    if processed_images is None:\n",
    "        return\n",
    "    \n",
    "    method_names = [\n",
    "        'Original',\n",
    "        'Histogram Equalization', \n",
    "        'CLAHE',\n",
    "        'Gamma Correction (γ=0.7)',\n",
    "        'Unsharp Masking',\n",
    "        'Edge Enhancement'\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, (key, name) in enumerate(zip(processed_images.keys(), method_names)):\n",
    "        img = processed_images[key]\n",
    "        axes[i].imshow(img, cmap='gray' if len(img.shape) == 2 else None)\n",
    "        axes[i].set_title(f\"{name}\\nMean: {np.mean(img):.1f}\")\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"Preprocessing Methods Comparison - {img_data['filename']}\", y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "    \n",
    "    return processed_images\n",
    "\n",
    "if example_files:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"DEMONSTRATING PREPROCESSING METHODS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show preprocessing on the first example\n",
    "    first_example = load_image_data(str(example_files[0]))\n",
    "    if first_example:\n",
    "        demo_processed = visualize_preprocessing_methods(first_example)\n",
    "        print(f\"\\nPreprocessing demonstrated on: {first_example['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3822f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all images in the folder\n",
    "def process_image_folder(input_folder: str, output_dirs: dict):\n",
    "    \"\"\"Process all images in the input folder and save results.\"\"\"\n",
    "    image_files = [f for f in Path(input_folder).iterdir() \n",
    "                   if f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No images found to process.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing {len(image_files)} images...\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    stats = {\n",
    "        'total_processed': 0,\n",
    "        'total_failed': 0,\n",
    "        'brightness_distribution': defaultdict(int),\n",
    "        'method_stats': defaultdict(lambda: {'saved': 0, 'failed': 0})\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, img_file in enumerate(image_files, 1):\n",
    "        # Load image\n",
    "        img_data = load_image_data(str(img_file))\n",
    "        if img_data is None:\n",
    "            stats['total_failed'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Track brightness distribution\n",
    "        stats['brightness_distribution'][img_data['stats']['brightness_category']] += 1\n",
    "        \n",
    "        # Apply preprocessing methods\n",
    "        processed_images = apply_all_preprocessing_methods(img_data)\n",
    "        if processed_images is None:\n",
    "            stats['total_failed'] += 1\n",
    "            continue\n",
    "        \n",
    "        # Save processed images\n",
    "        filename = img_data['filename']\n",
    "        for method, processed_img in processed_images.items():\n",
    "            output_path = output_dirs[method] / filename\n",
    "            if save_processed_image(processed_img, str(output_path)):\n",
    "                stats['method_stats'][method]['saved'] += 1\n",
    "            else:\n",
    "                stats['method_stats'][method]['failed'] += 1\n",
    "        \n",
    "        stats['total_processed'] += 1\n",
    "        \n",
    "        # Progress update\n",
    "        if i % 100 == 0 or i == len(image_files):\n",
    "            print(f\"Processed {i}/{len(image_files)} images ({(i/len(image_files)*100):.1f}%)\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    return stats, duration\n",
    "\n",
    "# Execute processing\n",
    "if image_files:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PROCESSING ALL IMAGES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    processing_stats, processing_duration = process_image_folder(INPUT_FOLDER, output_dirs)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"Processing time: {processing_duration:.2f} seconds\")\n",
    "    print(f\"Images processed: {processing_stats['total_processed']}\")\n",
    "    print(f\"Failed images: {processing_stats['total_failed']}\")\n",
    "    print(f\"Processing rate: {processing_stats['total_processed']/processing_duration:.2f} images/second\")\n",
    "    \n",
    "    print(\"\\nBrightness distribution:\")\n",
    "    for category, count in processing_stats['brightness_distribution'].items():\n",
    "        percentage = (count / processing_stats['total_processed']) * 100\n",
    "        print(f\"  {category}: {count} images ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nMethod processing statistics:\")\n",
    "    for method, method_stats in processing_stats['method_stats'].items():\n",
    "        saved = method_stats['saved']\n",
    "        failed = method_stats['failed']\n",
    "        total = saved + failed\n",
    "        success_rate = (saved / total * 100) if total > 0 else 0\n",
    "        print(f\"  {method}: {saved} saved, {failed} failed ({success_rate:.1f}% success)\")\n",
    "    \n",
    "    print(f\"\\nResults saved to: {OUTPUT_FOLDER}/\")\n",
    "    for method, directory in output_dirs.items():\n",
    "        file_count = len([f for f in directory.iterdir() if f.is_file()])\n",
    "        print(f\"  {method}: {file_count} images\")\n",
    "else:\n",
    "    print(\"No images to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cebfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparison visualization for different brightness categories\n",
    "def analyze_brightness_categories(input_folder: str, max_per_category: int = 2):\n",
    "    \"\"\"Analyze and visualize images from different brightness categories.\"\"\"\n",
    "    image_files = [f for f in Path(input_folder).iterdir() \n",
    "                   if f.suffix.lower() in ['.png', '.jpg', '.jpeg']]\n",
    "    \n",
    "    if not image_files:\n",
    "        return\n",
    "    \n",
    "    # Categorize images by brightness\n",
    "    brightness_categories = {'dark': [], 'medium': [], 'bright': []}\n",
    "    \n",
    "    for img_file in image_files:\n",
    "        img_data = load_image_data(str(img_file))\n",
    "        if img_data:\n",
    "            category = img_data['stats']['brightness_category']\n",
    "            if len(brightness_categories[category]) < max_per_category:\n",
    "                brightness_categories[category].append((img_file, img_data))\n",
    "    \n",
    "    # Visualize examples from each category\n",
    "    categories_with_data = {k: v for k, v in brightness_categories.items() if v}\n",
    "    \n",
    "    if not categories_with_data:\n",
    "        print(\"No categorized images found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nBrightness category analysis:\")\n",
    "    for category, images in categories_with_data.items():\n",
    "        print(f\"  {category}: {len(images)} example(s)\")\n",
    "    \n",
    "    # Create visualization\n",
    "    n_categories = len(categories_with_data)\n",
    "    n_cols = max_per_category\n",
    "    \n",
    "    fig, axes = plt.subplots(n_categories, n_cols, figsize=(n_cols*5, n_categories*4))\n",
    "    if n_categories == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if n_cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for row, (category, images) in enumerate(categories_with_data.items()):\n",
    "        for col in range(n_cols):\n",
    "            if col < len(images):\n",
    "                img_file, img_data = images[col]\n",
    "                axes[row, col].imshow(img_data['resized'])\n",
    "                axes[row, col].set_title(f\"{category.upper()}\\n{img_data['filename']}\\nMean: {img_data['stats']['mean_intensity']:.1f}\")\n",
    "            else:\n",
    "                axes[row, col].text(0.5, 0.5, 'No image', ha='center', va='center',\n",
    "                                   transform=axes[row, col].transAxes)\n",
    "            axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Brightness Category Examples', y=1.02, fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "if image_files:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"BRIGHTNESS CATEGORY ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    analyze_brightness_categories(INPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb26b65",
   "metadata": {},
   "source": [
    "## 7. Interpretation Guide\n",
    "\n",
    "### Understanding the Results:\n",
    "\n",
    "**1. Preprocessing Effects:**\n",
    "- **Histogram Equalization**: Good for very dark images, but may over-enhance noise\n",
    "- **CLAHE**: More balanced enhancement, preserves local details\n",
    "- **Gamma Correction**: Specifically targets dark regions\n",
    "- **Unsharp Masking**: Enhances edges and fine details\n",
    "- **Edge Enhancement**: Highlights structural boundaries\n",
    "\n",
    "**2. Feature Map Insights:**\n",
    "- **Early layers** (block1, conv1): Detect basic edges and textures\n",
    "- **Middle layers** (block3, conv3): Detect patterns and shapes\n",
    "- **Late layers** (block5, conv5): Detect complex object parts\n",
    "\n",
    "**3. Why Dark Images May Cluster Differently:**\n",
    "- **Noise sensitivity**: Dark images may have different noise patterns\n",
    "- **Feature extraction**: CNNs may struggle with low-contrast regions\n",
    "- **Preprocessing dependency**: Different enhancement methods reveal different features\n",
    "- **Infrastructure visibility**: Track details may be more/less visible in darkness\n",
    "\n",
    "**4. Clustering Factors to Consider:**\n",
    "- **Lighting conditions**: Time of day, artificial lighting\n",
    "- **Track type**: Ballasted vs embedded tracks\n",
    "- **Infrastructure age**: Newer vs older installations\n",
    "- **Environmental factors**: Weather, season, maintenance level\n",
    "- **Camera settings**: Exposure, ISO, white balance\n",
    "\n",
    "### Recommendations:\n",
    "1. **Compare multiple dark images** to identify common patterns\n",
    "2. **Test different preprocessing** methods in your clustering pipeline\n",
    "3. **Consider ensemble features** from multiple preprocessing methods\n",
    "4. **Analyze misclassified examples** to understand failure modes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
